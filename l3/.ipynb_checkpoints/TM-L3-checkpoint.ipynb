{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3: Text clustering and topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text clustering groups documents in such a way that documents within a group are more &lsquo;similar&rsquo; to other documents in the cluster than to documents not in the cluster. The exact definition of what &lsquo;similar&rsquo; means in this context varies across applications and clustering algorithms.\n",
    "\n",
    "In this lab you will experiment with both hard and soft clustering techniques. More specifically, in the first part you will be using the $k$-means algorithm, and in the second part you will be using a topic model based on the Latent Dirichlet Allocation (LDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A quick reminder about our [Rules for hand-in assignments](https://www.ida.liu.se/~TDDE16/exam.en.shtml#handins) and the [Policy on cheating and plagiarism](https://www.ida.liu.se/~TDDE16/exam.en.shtml#cheating)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard clustering data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data for the hard clustering part of this lab is a collection of product reviews. We have preprocessed the data by tokenization and lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open('reviews.json.bz2') as source:\n",
    "    df = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you inspect the data frame, you can see that there are three labelled columns: `category` (the product category), `sentiment` (whether the product review was classified as &lsquo;positive&rsquo; or &lsquo;negative&rsquo; towards the product), and `text` (the space-separated text of the review)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>music</td>\n",
       "      <td>neg</td>\n",
       "      <td>i bought this album because i loved the title ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>music</td>\n",
       "      <td>neg</td>\n",
       "      <td>i was misled and thought i was buying the enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>books</td>\n",
       "      <td>neg</td>\n",
       "      <td>i have introduced many of my ell , high school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>books</td>\n",
       "      <td>pos</td>\n",
       "      <td>anything you purchase in the left behind serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dvd</td>\n",
       "      <td>pos</td>\n",
       "      <td>i loved these movies , and i cant wiat for the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category sentiment                                               text\n",
       "0    music       neg  i bought this album because i loved the title ...\n",
       "1    music       neg  i was misled and thought i was buying the enti...\n",
       "2    books       neg  i have introduced many of my ell , high school...\n",
       "3    books       pos  anything you purchase in the left behind serie...\n",
       "4      dvd       pos  i loved these movies , and i cant wiat for the..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to cluster the product review data using a tf–idf vectorizer and a $k$-means clusterer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by doing the vectorization. In connection with vectorization, you should also filter out standard English stop words. While you could use [spaCy](https://spacy.io/) for this task, here it suffices to use the word list implemented in [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter code here to vectorize the data and store it in a variable `reviews`\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "reviews = vectorizer.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your vectorization by running the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11914, 46619)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used the English stop word list from scikit-learn, then the resulting vocabulary should have 46,619 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, cluster the vectorized data. Before doing so, you should read the documentation of the [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) class, which is scikit-learn&rsquo;s implementation of the $k$-means algorithm. As you can see, this class has several parameters that you can tweak. For now, the only parameter that you will have to set is the number of clusters. Start with $k=3$.\n",
    "\n",
    "**Tip:** Training $k$-means models will take some time. To speed things up, you can use the `n_init` parameter to control the number of times that the clustering is re-computed with different initial values. The default value for this parameter is 10; here and in the rest of this lab, you may want to set this to a lower value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter code here to cluster the vectorized data\n",
    "from sklearn.cluster import KMeans\n",
    "KM_cluster = KMeans(n_clusters = 3, \n",
    "                    n_init = 5, \n",
    "                    random_state = 999,\n",
    "                    algorithm = 'elkan').fit(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sanity-check your clustering, create a bar plot with the number of documents per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Enter code here to produce a bar plot of the cluster size\n",
    "\n",
    "pd.value_counts(KM_cluster.labels_).plot(kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that sizes may vary considerable between clusters and among different random seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Summarize clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a clustering, you can try to see whether it is meaningful. One useful technique in that context is to generate a **summary** for each cluster by extracting the $n$ highest-weighted terms from the centroid of each cluster. Your next task is to implement this approach.\n",
    "\n",
    "**Hint:** You will need to construct an &lsquo;inverted vocabulary&rsquo; that allows you to map from the index of a term back to the original term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ['really', 'software', 'work', 'did', 'music', 'does', 'time', 'good', 'use', 'album', 'just', 'great', 'cd', 'like', 'product']\n",
      "1 : ['characters', 'people', 'really', 'quot', 'did', 'great', 'books', 'good', 'just', 'like', 'story', 'read', 'film', 'movie', 'book']\n",
      "2 : ['zoom', 'picture', 'cameras', 'good', 'case', 'great', 'quality', 'battery', 'flash', 'use', 'digital', 'canon', 'pictures', 'lens', 'camera']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter code here to compute the cluster summaries and print them\n",
    "import numpy as np\n",
    "\n",
    "n = 15\n",
    "\n",
    "centroids = KM_cluster.cluster_centers_\n",
    "vocabulary = {value:key for key,value in vectorizer.vocabulary_.items()}\n",
    "\n",
    "for i in range(len(centroids)):\n",
    "    index = np.argsort(centroids[i])[-n:]\n",
    "    print(f\"{i} : {[vocabulary[j] for j in index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have computed the cluster summaries, take a minute to reflect on their quality. Is it clear what the reviews in a given cluster are about? Do the cluster summaries contain any unexpected terms?\n",
    "\n",
    "*We saw earlier that cluster0 was the most \"dense\" and it is also reflected in the summary that the clustering is not very good for this cluster. There are some words that indicate a cluster about music with words like - album, cd, music. But then there are some common english words like - like, really, did. The second cluster is also a bit confusing because there are 2 themes - books & movies. It can be reasoned that common words can be used in reviews about movies & books like - story, characters, people, which is what the summary reflects. The third cluster is the smallest & most clearest. It seems to be about reviews for different camera models.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Compare clusterings using the Rand index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some scenarios, you may have gold-standard class labels available for at least a subset of your documents. In these cases you can compute the **Rand index** of a clustering, and use this measure to compare the quality of different clusterings.\n",
    "\n",
    "To compute the Rand index, we view a clustering as a binary classifier on (unordered) pairs of documents. The classifier predicts &lsquo;positive&rsquo; if and only if the two documents belong to the same cluster. The (non-normalized) Rand index of the clustering is the accuracy of this classifier relative to a reference in which a document pair belongs to the &lsquo;positive&rsquo; class if and only if the two documents in the pair have the same gold-standard class label. You are supposed to implement the procedure yourselves, not import an external function.\n",
    "\n",
    "Compare clusterings with $k \\in \\{1,3,5,7\\}$ clusters. As your evaluation data, use the first 500 documents from the original data set along with their gold-standard categories (from the `category` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index for Clustering with k = 1 : 0.1663\n",
      "Rand Index for Clustering with k = 3 : 0.5572\n",
      "Rand Index for Clustering with k = 5 : 0.6834\n",
      "Rand Index for Clustering with k = 7 : 0.764\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter code here to (manually) compute the Rand indices for the two clusterings\n",
    "\n",
    "from scipy.special import comb\n",
    "\n",
    "k = [1,3,5,7]\n",
    "eval_data = df[:500]\n",
    "eval_labels = pd.factorize(eval_data.category)[0]\n",
    "eval_reviews = reviews[:500]\n",
    "\n",
    "def rand_index(cluster_labels, goldstandard_labels):\n",
    "    \n",
    "    # TP+FP = sum(nC2 for each cluster)\n",
    "    tp_fp = sum(comb(pd.value_counts(cluster_labels), 2))\n",
    "    \n",
    "    # TP+FN = sum(nC2 for goldstandard labels)\n",
    "    tp_fn = sum(comb(pd.value_counts(goldstandard_labels), 2))\n",
    "    \n",
    "    # create ordered pairs of cluster labels & goldstandard labels\n",
    "    ord_pairs = np.r_['1,2,0', cluster_labels, goldstandard_labels]\n",
    "    \n",
    "    # TP = sum(For each cluster sum(number_matching_labels CHOOSE 2))\n",
    "    tp = sum(sum(comb(pd.value_counts(ord_pairs[ord_pairs[:, 0] == i, 1]), 2)) for i in np.unique(cluster_labels))\n",
    "    \n",
    "    # FP = TP+FP - TP\n",
    "    fp = tp_fp - tp\n",
    "    \n",
    "    # FN = TP+FN - TP\n",
    "    fn = tp_fn - tp\n",
    "    \n",
    "    # TN = nC2 - TP - FP - FN\n",
    "    tn = comb(len(ord_pairs), 2) - tp - fp - fn\n",
    "    \n",
    "    # return rand_index\n",
    "    return (tp + tn)/(tp + fp + fn + tn)\n",
    "\n",
    "\n",
    "for i in k:\n",
    "    KM = KMeans(n_clusters = i,\n",
    "                n_init = 5, \n",
    "                random_state = 999).fit(reviews)\n",
    "    \n",
    "    cluster_labels = KM.labels_[:500]\n",
    "    \n",
    "    print(f\"Rand Index for Clustering with k = {i} : {round(rand_index(cluster_labels, eval_labels),4)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As we kept increasing the allowed clusters, the higher RI values we see. Which implies that the dataset has multiple categories. In the previous step we saw that with k=3, we were getting a very large meaningless cluster0, but the second cluster seemed to be a mix of 2 topics. The third cluster had a clear theme. This exercise shows that going as high as k=7 only gives about 76% accuracy for the data clustering.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set for the topic modelling part of this lab is the collection of all [State of the Union](https://en.wikipedia.org/wiki/State_of_the_Union) addresses from the years 1975–2000. These speeches come as a single text file with one sentence per line. The following code cell prints the first 5 lines from the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr speaker mr vice president members of the 94th congress and distinguished guests\n",
      "twenty six years ago a freshman congressman a young fellow with lots of idealism who was out to change the world stood before sam rayburn in the well of the house and solemnly swore to the same oath that all of you took yesterday an unforgettable experience and i congratulate you all\n",
      "two days later that same freshman stood at the back of this great chamber over there someplace as president truman all charged up by his single handed election victory reported as the constitution requires on the state of the union\n",
      "when the bipartisan applause stopped president truman said i am happy to report to this 81st congress that the state of the union is good our nation is better able than ever before to meet the needs of the american people and to give them their fair chance in the pursuit of happiness it is foremost among the nations of the world in the search for peace\n",
      "today that freshman member from michigan stands where mr truman stood and i must say to you that the state of the union is not good\n",
      "millions of americans are out of work\n"
     ]
    }
   ],
   "source": [
    "with open('sotu_1975_2000.txt') as source:\n",
    "    for i, line in enumerate(source):\n",
    "        print(line.rstrip())\n",
    "        if i >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a few minutes to think about what topics you would expect in this data set.\n",
    "\n",
    "*Possible topics: political speech, unemployment, ceremony, agenda*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Train a topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task on the topic modelling data is to train an LDA model. For this task you will be using [spaCy](https://spacy.io/) and the [gensim](https://radimrehurek.com/gensim/) topic modelling library.\n",
    "\n",
    "Start by preprocessing the data using spaCy. Given that the data set for this problem is rather small, you do not have to exclude any components from the standard pipeline. Filter out stop words, non-alphabetic tokens, and tokens less than 3 characters in length. Store the documents as a nested list where the first level of nesting corresponds to the sentences and the second level corresponds to the tokens in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\spacy\\language.py:1895: UserWarning: [W123] Argument disable with value ['senter'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace the following lines with your own code for preprocessing the documents\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['senter'])\n",
    "def preprocess(text):\n",
    "    doc_list = []\n",
    "    for token in nlp(text):\n",
    "        if token.is_stop is False and token.is_alpha is True and len(token) >= 3:\n",
    "            doc_list.append(token.text)\n",
    "    return doc_list\n",
    "\n",
    "with open('sotu_1975_2000.txt') as source:\n",
    "    documents = [preprocess(line) for line in source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your preprocessing by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reduce oil imports million barrels day end year million barrels day end'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(documents[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'reduce oil imports million barrels day end year million barrels day end'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the list of documents, skim the section [Pre-process and vectorize the documents](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#pre-process-and-vectorize-the-documents) of the gensim documentation to learn how to create the dictionary and the vectorized corpus representation required by gensim. (Note that you cannot use the standard scikit-learn pipeline in this case.) Then, write code to train an [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html) for $k=10$ topics, and using default values for all other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 8496\n",
      "Number of documents: 2898\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter code here to train an LDA model and store it in a variable `model`\n",
    "# most of the code in this section is taken from the gensim documentation\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(documents)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "#chunksize = 2000\n",
    "#passes = 20\n",
    "#iterations = 400\n",
    "#eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    #chunksize=chunksize,\n",
    "    #alpha='auto',\n",
    "    #eta='auto',\n",
    "    #iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    #passes=passes,\n",
    "    #eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a trained model, run the following cell to print the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"world\" + 0.015*\"america\" + 0.009*\"people\" + 0.007*\"american\" + 0.006*\"economy\" + 0.006*\"years\" + 0.006*\"peace\" + 0.006*\"nation\" + 0.006*\"work\" + 0.006*\"tonight\"'),\n",
       " (1,\n",
       "  '0.017*\"america\" + 0.014*\"people\" + 0.011*\"new\" + 0.008*\"know\" + 0.007*\"work\" + 0.007*\"trade\" + 0.007*\"american\" + 0.006*\"thank\" + 0.006*\"help\" + 0.006*\"way\"'),\n",
       " (2,\n",
       "  '0.008*\"covenant\" + 0.007*\"grade\" + 0.007*\"new\" + 0.006*\"energy\" + 0.006*\"people\" + 0.006*\"year\" + 0.005*\"world\" + 0.005*\"know\" + 0.005*\"surplus\" + 0.005*\"challenge\"'),\n",
       " (3,\n",
       "  '0.010*\"years\" + 0.006*\"social\" + 0.006*\"million\" + 0.006*\"tonight\" + 0.006*\"children\" + 0.005*\"lowest\" + 0.005*\"people\" + 0.005*\"schools\" + 0.005*\"security\" + 0.005*\"toxic\"'),\n",
       " (4,\n",
       "  '0.006*\"years\" + 0.006*\"congress\" + 0.006*\"partnerships\" + 0.005*\"community\" + 0.005*\"support\" + 0.005*\"united\" + 0.005*\"states\" + 0.005*\"grades\" + 0.005*\"world\" + 0.004*\"punish\"'),\n",
       " (5,\n",
       "  '0.014*\"children\" + 0.013*\"people\" + 0.011*\"work\" + 0.010*\"new\" + 0.009*\"year\" + 0.008*\"america\" + 0.008*\"let\" + 0.007*\"american\" + 0.007*\"years\" + 0.007*\"century\"'),\n",
       " (6,\n",
       "  '0.012*\"americans\" + 0.012*\"security\" + 0.009*\"years\" + 0.008*\"congress\" + 0.008*\"care\" + 0.006*\"social\" + 0.006*\"year\" + 0.006*\"government\" + 0.006*\"nuclear\" + 0.005*\"world\"'),\n",
       " (7,\n",
       "  '0.016*\"new\" + 0.014*\"year\" + 0.008*\"congress\" + 0.007*\"america\" + 0.007*\"people\" + 0.007*\"work\" + 0.006*\"years\" + 0.006*\"american\" + 0.006*\"government\" + 0.005*\"nuclear\"'),\n",
       " (8,\n",
       "  '0.010*\"government\" + 0.009*\"new\" + 0.008*\"nation\" + 0.008*\"country\" + 0.008*\"america\" + 0.007*\"peace\" + 0.007*\"support\" + 0.006*\"americans\" + 0.006*\"states\" + 0.006*\"years\"'),\n",
       " (9,\n",
       "  '0.010*\"america\" + 0.009*\"help\" + 0.009*\"year\" + 0.007*\"years\" + 0.007*\"congress\" + 0.006*\"government\" + 0.005*\"nation\" + 0.005*\"new\" + 0.005*\"bosnia\" + 0.004*\"support\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the topics. Can you &lsquo;label&rsquo; each topic with a short description of what it is about? Do the topics match your expectations?\n",
    "\n",
    "*Mostly the topics seem to be incoherent. Following are some far fetched guesses on our part*\n",
    "\n",
    "- Topic 0: How America is the big brother to the world.\n",
    "- Topic 1: US budget\n",
    "- Topic 2: Health care and employment in the budget\n",
    "- Topic 3: national security, education & budget cuts\n",
    "- Topic 4: workforce related issues (maybe?)\n",
    "- Topic 5: welfare, health & care for american people through budget policies\n",
    "- Topic 6: Crime and how it affects working Americans\n",
    "- Topic 7: Defence budget\n",
    "- Topic 8: Education and Youth\n",
    "- Topic 9: Higher education (maybe scholarships, loans etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Monitor a topic model for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When learning an LDA model, it is important to make sure that the training algorithm has converged to a stable posterior distribution. One way to do so is to plot, after each training epochs (or &lsquo;pass&rsquo;, in gensim parlance) the log likelihood of the training data under the posterior. Your last task in this lab is to create such a plot and, based on this, to suggest an appropriate number of epochs.\n",
    "\n",
    "To collect information about the posterior likelihood after each pass, we need to enable the logging facilities of gensim. Once this is done, gensim will add various diagnostics to a log file `gensim.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='gensim.log', format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will parse the generated logfile and return the list of log likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_logfile():\n",
    "    matcher = re.compile('(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity')\n",
    "    likelihoods = []\n",
    "    with open('gensim.log') as source:\n",
    "        for line in source:\n",
    "            match = matcher.search(line)\n",
    "            if match:\n",
    "                likelihoods.append(float(match.group(1)))\n",
    "    return likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task now is to re-train your LDA model for 50&nbsp;passes, retrieve the list of log likelihoods, and create a plot from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter code here to generate the convergence plot\n",
    "with open('gensim.log', 'w'):\n",
    "    pass\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    #chunksize=chunksize,\n",
    "    #alpha='auto',\n",
    "    #eta='auto',\n",
    "    #iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=50,\n",
    "    #eval_every=eval_every\n",
    ")\n",
    "\n",
    "loglikelihoods = parse_logfile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a704aa50d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loglikelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.702, -9.012, -8.669, -8.37, -8.214, -8.147, -8.115, -8.095, -8.08, -8.069, -8.06, -8.053, -8.047, -8.041, -8.036, -8.032, -8.028, -8.024, -8.021, -8.019, -8.016, -8.014, -8.012, -8.01, -8.008, -8.007, -8.005, -8.004, -8.002, -8.001, -8.0, -7.999, -7.998, -7.997, -7.996, -7.995, -7.994, -7.993, -7.992, -7.991, -7.991, -7.99, -7.989, -7.988, -7.988, -7.987, -7.986, -7.986, -7.985, -7.985]\n"
     ]
    }
   ],
   "source": [
    "print(loglikelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.016"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglikelihoods[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you interpret your plot? Based on the plot, what would be a reasonable choice for the number of passes? Retrain your LDA model with that number and re-inspect the topics it finds. Do you consider the new topics to be &lsquo;better&rsquo; than the ones that you got from the 1-pass model in Problem&nbsp;4?\n",
    "\n",
    "*Upon inspection the plot reflects that log-likelihood starts to converge to max value somewhere near 10 passes (elbow). This means that thee is not a lot of incremental benefit in terms of computational expenses beyond choosing a value beyond, say 20. Considering this graph shows convergence, we can pick a value higher than 50 too for more coherence. Since there is no one correct solution, we can test for different passes and compare. But the elbow plot, gives us a reference point to start from. So, we test for 20, 30, 40 & 80 passes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_20 = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=num_topics,\n",
    "    passes=20\n",
    "    )\n",
    "\n",
    "model_30 = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=num_topics,\n",
    "    passes=30\n",
    "    )\n",
    "\n",
    "model_40 = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=num_topics,\n",
    "    passes=40\n",
    "    )\n",
    "\n",
    "model_80 = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=num_topics,\n",
    "    passes=80\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"world\" + 0.017*\"america\" + 0.015*\"peace\" + 0.010*\"people\" + 0.009*\"nations\" + 0.008*\"freedom\" + 0.008*\"american\" + 0.007*\"united\" + 0.006*\"security\" + 0.006*\"states\"'),\n",
       " (1,\n",
       "  '0.016*\"america\" + 0.014*\"years\" + 0.011*\"people\" + 0.011*\"year\" + 0.009*\"children\" + 0.009*\"world\" + 0.008*\"great\" + 0.008*\"century\" + 0.007*\"americans\" + 0.007*\"tonight\"'),\n",
       " (2,\n",
       "  '0.015*\"congress\" + 0.015*\"children\" + 0.011*\"new\" + 0.009*\"teachers\" + 0.009*\"help\" + 0.008*\"federal\" + 0.007*\"schools\" + 0.007*\"year\" + 0.007*\"national\" + 0.007*\"standards\"'),\n",
       " (3,\n",
       "  '0.015*\"people\" + 0.015*\"work\" + 0.014*\"new\" + 0.013*\"year\" + 0.012*\"tax\" + 0.012*\"years\" + 0.012*\"children\" + 0.010*\"families\" + 0.009*\"help\" + 0.009*\"care\"'),\n",
       " (4,\n",
       "  '0.013*\"new\" + 0.010*\"energy\" + 0.010*\"congress\" + 0.008*\"trade\" + 0.007*\"policy\" + 0.007*\"economic\" + 0.007*\"administration\" + 0.006*\"nation\" + 0.005*\"development\" + 0.005*\"program\"'),\n",
       " (5,\n",
       "  '0.022*\"health\" + 0.017*\"care\" + 0.011*\"federal\" + 0.011*\"women\" + 0.011*\"medical\" + 0.010*\"year\" + 0.010*\"rights\" + 0.009*\"medicare\" + 0.007*\"laws\" + 0.007*\"law\"'),\n",
       " (6,\n",
       "  '0.022*\"people\" + 0.021*\"welfare\" + 0.015*\"work\" + 0.012*\"country\" + 0.011*\"right\" + 0.011*\"responsibility\" + 0.010*\"crime\" + 0.009*\"want\" + 0.009*\"americans\" + 0.009*\"god\"'),\n",
       " (7,\n",
       "  '0.014*\"security\" + 0.013*\"social\" + 0.009*\"percent\" + 0.009*\"let\" + 0.008*\"gun\" + 0.007*\"surplus\" + 0.007*\"tonight\" + 0.006*\"days\" + 0.006*\"increase\" + 0.006*\"work\"'),\n",
       " (8,\n",
       "  '0.017*\"america\" + 0.013*\"union\" + 0.012*\"world\" + 0.010*\"government\" + 0.009*\"nation\" + 0.008*\"people\" + 0.008*\"state\" + 0.007*\"new\" + 0.007*\"century\" + 0.007*\"national\"'),\n",
       " (9,\n",
       "  '0.025*\"budget\" + 0.025*\"spending\" + 0.017*\"federal\" + 0.016*\"deficit\" + 0.014*\"government\" + 0.012*\"congress\" + 0.011*\"growth\" + 0.011*\"americans\" + 0.010*\"cut\" + 0.010*\"billion\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_20.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We see some coherent topics:*\n",
    "\n",
    "- 0: world peace and freedom\n",
    "- 1: American greatness over the years ?? (mostly incoherent)\n",
    "- 2: Education standards\n",
    "- 3: maybe about families, tax regime in the new year (mostly incoherent)\n",
    "- 4: New trade policies focussed on national development\n",
    "- 5: Healthcare with some ascpect of specific laws pertaining to women\n",
    "- 6: Work & welfare rights (mostly incoherent)\n",
    "- 7: Another (mostly incoherent) mixed topic with some aspect of work related policies\n",
    "- 8: (mostly incoherent)\n",
    "- 9: Might be a high level summary topic of the SOTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"america\" + 0.009*\"thank\" + 0.007*\"congress\" + 0.007*\"states\" + 0.006*\"united\" + 0.006*\"east\" + 0.006*\"international\" + 0.005*\"world\" + 0.005*\"africa\" + 0.005*\"peace\"'),\n",
       " (1,\n",
       "  '0.021*\"health\" + 0.017*\"years\" + 0.015*\"care\" + 0.014*\"americans\" + 0.012*\"america\" + 0.011*\"people\" + 0.009*\"crime\" + 0.008*\"insurance\" + 0.007*\"medicare\" + 0.007*\"work\"'),\n",
       " (2,\n",
       "  '0.028*\"federal\" + 0.020*\"administration\" + 0.018*\"government\" + 0.015*\"programs\" + 0.013*\"policy\" + 0.009*\"congress\" + 0.008*\"years\" + 0.007*\"president\" + 0.006*\"regulations\" + 0.006*\"agencies\"'),\n",
       " (3,\n",
       "  '0.027*\"tax\" + 0.027*\"budget\" + 0.016*\"year\" + 0.014*\"government\" + 0.013*\"growth\" + 0.013*\"billion\" + 0.012*\"federal\" + 0.011*\"inflation\" + 0.011*\"economic\" + 0.011*\"deficit\"'),\n",
       " (4,\n",
       "  '0.020*\"let\" + 0.019*\"people\" + 0.017*\"know\" + 0.015*\"america\" + 0.013*\"work\" + 0.013*\"children\" + 0.012*\"american\" + 0.008*\"family\" + 0.008*\"americans\" + 0.008*\"country\"'),\n",
       " (5,\n",
       "  '0.017*\"soviet\" + 0.016*\"nuclear\" + 0.009*\"forces\" + 0.008*\"europe\" + 0.008*\"military\" + 0.008*\"states\" + 0.007*\"strategic\" + 0.007*\"agreement\" + 0.007*\"continue\" + 0.006*\"united\"'),\n",
       " (6,\n",
       "  '0.013*\"security\" + 0.012*\"energy\" + 0.011*\"nation\" + 0.011*\"new\" + 0.011*\"state\" + 0.010*\"years\" + 0.009*\"world\" + 0.009*\"social\" + 0.008*\"union\" + 0.008*\"tonight\"'),\n",
       " (7,\n",
       "  '0.028*\"world\" + 0.018*\"america\" + 0.012*\"peace\" + 0.012*\"american\" + 0.011*\"people\" + 0.010*\"new\" + 0.010*\"freedom\" + 0.009*\"trade\" + 0.009*\"economy\" + 0.008*\"nations\"'),\n",
       " (8,\n",
       "  '0.015*\"congress\" + 0.013*\"new\" + 0.009*\"year\" + 0.009*\"ask\" + 0.008*\"women\" + 0.008*\"americans\" + 0.007*\"citizens\" + 0.007*\"crime\" + 0.007*\"laws\" + 0.007*\"community\"'),\n",
       " (9,\n",
       "  '0.012*\"work\" + 0.012*\"help\" + 0.012*\"children\" + 0.012*\"new\" + 0.011*\"congress\" + 0.010*\"child\" + 0.010*\"people\" + 0.010*\"school\" + 0.010*\"year\" + 0.010*\"schools\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_30.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We noted some improved coherence in the topics with 30 passes*\n",
    "\n",
    "- 0: Foreign Policy with focus on East & Africa\n",
    "- 1: Healthcare insurance with some overlap with crime\n",
    "- 2: Federal regulations\n",
    "- 3: Economic summary of the country\n",
    "- 4: Importance of American family values and children\n",
    "- 5: Foreign Military policy with Europe\n",
    "- 6: mostly incoherent, but maybe national security or energy policy?\n",
    "- 7: Peace keeping efforts, but some overlap with trade policies\n",
    "- 8: Law & Order in the country with focus on women??\n",
    "- 9: Policies for children & schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"grade\" + 0.010*\"row\" + 0.007*\"buying\" + 0.006*\"dropped\" + 0.006*\"spend\" + 0.005*\"assault\" + 0.005*\"proposal\" + 0.004*\"sensible\" + 0.004*\"threats\" + 0.004*\"government\"'),\n",
       " (1,\n",
       "  '0.033*\"tax\" + 0.018*\"new\" + 0.009*\"credit\" + 0.009*\"investment\" + 0.008*\"development\" + 0.008*\"incentives\" + 0.007*\"class\" + 0.007*\"propose\" + 0.007*\"middle\" + 0.007*\"businesses\"'),\n",
       " (2,\n",
       "  '0.026*\"america\" + 0.019*\"world\" + 0.013*\"people\" + 0.010*\"nation\" + 0.010*\"century\" + 0.010*\"new\" + 0.009*\"years\" + 0.009*\"tonight\" + 0.008*\"americans\" + 0.008*\"time\"'),\n",
       " (3,\n",
       "  '0.017*\"crime\" + 0.013*\"america\" + 0.012*\"community\" + 0.010*\"people\" + 0.010*\"peace\" + 0.008*\"new\" + 0.007*\"congress\" + 0.007*\"american\" + 0.006*\"year\" + 0.006*\"police\"'),\n",
       " (4,\n",
       "  '0.018*\"federal\" + 0.016*\"security\" + 0.015*\"budget\" + 0.013*\"social\" + 0.012*\"years\" + 0.012*\"year\" + 0.011*\"spending\" + 0.010*\"programs\" + 0.009*\"billion\" + 0.009*\"congress\"'),\n",
       " (5,\n",
       "  '0.020*\"speaker\" + 0.013*\"president\" + 0.013*\"weapons\" + 0.012*\"fellow\" + 0.011*\"congress\" + 0.011*\"nuclear\" + 0.011*\"ban\" + 0.010*\"treaty\" + 0.009*\"members\" + 0.008*\"guests\"'),\n",
       " (6,\n",
       "  '0.024*\"energy\" + 0.018*\"thank\" + 0.009*\"oil\" + 0.008*\"god\" + 0.008*\"drugs\" + 0.007*\"bless\" + 0.007*\"percent\" + 0.007*\"production\" + 0.006*\"legislation\" + 0.006*\"drug\"'),\n",
       " (7,\n",
       "  '0.014*\"people\" + 0.012*\"new\" + 0.012*\"american\" + 0.011*\"government\" + 0.009*\"help\" + 0.009*\"year\" + 0.009*\"work\" + 0.009*\"america\" + 0.008*\"congress\" + 0.007*\"know\"'),\n",
       " (8,\n",
       "  '0.021*\"care\" + 0.020*\"health\" + 0.019*\"work\" + 0.019*\"children\" + 0.016*\"welfare\" + 0.015*\"people\" + 0.014*\"child\" + 0.012*\"families\" + 0.011*\"americans\" + 0.011*\"family\"'),\n",
       " (9,\n",
       "  '0.014*\"world\" + 0.011*\"states\" + 0.010*\"nations\" + 0.009*\"soviet\" + 0.009*\"united\" + 0.009*\"nuclear\" + 0.008*\"economic\" + 0.007*\"policy\" + 0.007*\"international\" + 0.006*\"forces\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_40.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not detailing this out, but we noted a similar coherence level of topics with 40 passes as with 30 passes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"space\" + 0.013*\"new\" + 0.006*\"history\" + 0.006*\"second\" + 0.006*\"meet\" + 0.006*\"world\" + 0.005*\"teacher\" + 0.005*\"imports\" + 0.005*\"rewards\" + 0.004*\"fuels\"'),\n",
       " (1,\n",
       "  '0.012*\"gun\" + 0.009*\"guns\" + 0.008*\"chemical\" + 0.008*\"new\" + 0.007*\"row\" + 0.007*\"science\" + 0.006*\"cancer\" + 0.006*\"organized\" + 0.005*\"frontiers\" + 0.005*\"leading\"'),\n",
       " (2,\n",
       "  '0.023*\"america\" + 0.015*\"new\" + 0.013*\"children\" + 0.011*\"work\" + 0.011*\"people\" + 0.010*\"world\" + 0.010*\"americans\" + 0.009*\"community\" + 0.009*\"century\" + 0.009*\"nation\"'),\n",
       " (3,\n",
       "  '0.013*\"new\" + 0.011*\"economic\" + 0.009*\"energy\" + 0.008*\"policy\" + 0.008*\"administration\" + 0.007*\"federal\" + 0.007*\"program\" + 0.007*\"congress\" + 0.007*\"trade\" + 0.007*\"growth\"'),\n",
       " (4,\n",
       "  '0.015*\"congress\" + 0.014*\"college\" + 0.013*\"people\" + 0.011*\"education\" + 0.009*\"pass\" + 0.009*\"children\" + 0.008*\"young\" + 0.008*\"ask\" + 0.007*\"new\" + 0.007*\"bill\"'),\n",
       " (5,\n",
       "  '0.022*\"health\" + 0.022*\"care\" + 0.020*\"work\" + 0.017*\"children\" + 0.016*\"welfare\" + 0.014*\"child\" + 0.012*\"families\" + 0.011*\"help\" + 0.010*\"schools\" + 0.009*\"people\"'),\n",
       " (6,\n",
       "  '0.021*\"budget\" + 0.018*\"year\" + 0.016*\"security\" + 0.014*\"government\" + 0.012*\"social\" + 0.010*\"tax\" + 0.010*\"spending\" + 0.010*\"years\" + 0.010*\"federal\" + 0.008*\"congress\"'),\n",
       " (7,\n",
       "  '0.031*\"nuclear\" + 0.025*\"soviet\" + 0.017*\"weapons\" + 0.013*\"world\" + 0.013*\"nations\" + 0.013*\"security\" + 0.012*\"war\" + 0.011*\"agreement\" + 0.010*\"china\" + 0.010*\"strategic\"'),\n",
       " (8,\n",
       "  '0.021*\"crime\" + 0.015*\"years\" + 0.009*\"house\" + 0.008*\"police\" + 0.007*\"rate\" + 0.007*\"city\" + 0.007*\"year\" + 0.007*\"percent\" + 0.006*\"lowest\" + 0.006*\"women\"'),\n",
       " (9,\n",
       "  '0.023*\"america\" + 0.019*\"people\" + 0.018*\"world\" + 0.012*\"american\" + 0.010*\"years\" + 0.009*\"tonight\" + 0.008*\"nation\" + 0.008*\"country\" + 0.008*\"time\" + 0.008*\"let\"')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_80.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With 80 passes we some topics come out very clearly - gun ownership policy, Economic & Trade policies, Healthcare, Schools & Education, Foreign policy wrt China & Russia, Crime & Women Safety.*\n",
    "\n",
    "**Overall Summary of findings: As we saw in the elbow shaped plot, convergence is seen after 10 passes, so we keep seeing improvement in topic coherence as we choose higher number of passes. But since the exercise is subjective interpretation, out choice should be motivated by keeping in mind computational complexity and also diminishing coherence benefit with increasing passes. We think, the optimal choice would be to use 40 passes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following reflection questions will help you prepare for the diagnostic test. Answer each of them in the form of a short text and put your answers in the cell below. You will get feedback on your answers from your lab assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RQ 3.1:** Based on your experiments in Problem&nbsp;2 and Problem&nbsp;3, what is the relation between the quality of a clustering and the number of clusters? What happens when the number of clusters is too low, or too high? For this particular data set, what would a &lsquo;good&rsquo; number of clusters be?\n",
    "\n",
    "*From the RI values we computed for k = 1,3,5 and 7, we saw the quality of clustering went up each time. But since, with this limited test we did not check if, at current or higher k values, the RI plateau or peak, so, based on what we found with the given experiment design, we can expect better clustering performance with higher values of k. To tune the 'k' hyperparameter, we would need to plot the inertia for each subsequent clustering and find the 'elbow' in the  inertia plot. Considering, that the full data contains 6 categories (which served as gold standard labels for evaluation), intuitively, 6 clusters is what we would expect. But we have to keep in mind the limitations of the KMeans clustering i.e. KMeans finds clusters with convex shapes and it doesn't handle outliers well. Its merely conjecture on our part, but reviews on books and dvds can utilize a lot of common words and thus be act as outliers for each others clusters and pull the centroids of each cluster towards them. This can be a reason why the qualit of clusters for this dataset maybe limited using KMeans.*\n",
    "\n",
    "**RQ 3.2:** Explain why it is important to monitor an LDA model for convergence and not simply use, say, 1000&nbsp;passes. How is the log likelihood used in this context? Were the topics from the multi-pass model &lsquo;better&rsquo; than the topics from the 1-pass model?\n",
    "\n",
    "*We reasoned this earlier in the report as well, but to recap, since we see convergence after a certain number of passes, the plot suggests we can keep improving our topic quality results with higher passes, but this obviously comes at a higher training cost and we also saw diminishing returns on quality of topics with increasing number of passes. The log-likelihood is the marginal probability $p(word|topic)$ drawn from the unigram model. With each pass, as with weights propagating through hidden layers in a neural network, we expect convergence. Hence, here we use the log-likelihood values to determine where convergence takes place and expect the number of topics in our data. The topics discovered during the experiments were explained earlier.*\n",
    "\n",
    "**RQ 3.3:** What are the differences between $k$-means and LDA? When would you use one, when the other?\n",
    "\n",
    "*The difference between k-means and LDA is their clustering type. k-means is a hard clustering technique while LDA is a soft clustering approach. The clearest way to understand how they differ from each other is how they group documents. k-means will assign each document to a particular cluster while LDA would assign a document to multiple topics or a mixture of topics. k-means is more suitable as an exploratory tool to understand the data better and how its distributed. To get a sense of context and structure within the text data we should use LDA which lets us find more realistic and contextual results in topic identification. In other words, use k-means when the objective is to find high level grouping and pre-processing; use LDA when the objective is gain knowledge of context in text data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camera      99\n",
       "music       83\n",
       "software    82\n",
       "dvd         80\n",
       "books       78\n",
       "health      78\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(eval_data['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Enter your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing L3! 👍**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
