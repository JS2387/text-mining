{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L5: Information extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information extraction (IE) is the task of identifying named entities and semantic relations between these entities in text data. In this lab we will focus on two sub-tasks in IE, **named entity recognition** (identifying mentions of entities) and **entity linking** (matching these mentions to entities in a knowledge base)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder about our [Rules for hand-in assignments](https://www.ida.liu.se/~TDDE16/exam.en.shtml#handins) and the [Policy on cheating and plagiarism](https://www.ida.liu.se/~TDDE16/exam.en.shtml#cheating)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we will be using has been tokenized following the conventions of the [Penn Treebank](ftp://ftp.cis.upenn.edu/pub/treebank/public_html/tokenization.html), and we need to prevent spaCy from using its own tokenizer on top of this. We therefore override spaCy&rsquo;s tokenizer with one that simply splits on space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "\n",
    "class WhitespaceTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return Doc(self.vocab, words=text.split(' '))\n",
    "\n",
    "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main data set for this lab is a collection of news wire articles in which mentions of named entities have been annotated with page names from the [English Wikipedia](https://en.wikipedia.org/wiki/). The next code cell loads the training and the development parts of the data into Pandas data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with bz2.open('ner-train.tsv.bz2', 'rt', encoding = 'utf8') as source:\n",
    "    df_train = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)\n",
    "\n",
    "with bz2.open('ner-dev.tsv.bz2', 'rt', encoding = 'utf8') as source:\n",
    "    df_dev = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in these two data frames corresponds to one mention of a named entity and has five columns:\n",
    "\n",
    "1. a unique identifier for the sentence containing the entity mention\n",
    "2. the pre-tokenized sentence, with tokens separated by spaces\n",
    "3. the start position of the token span containing the entity mention\n",
    "4. the end position of the token span (exclusive, as in Python list indexing)\n",
    "5. the entity label; either a Wikipedia page name or the generic label `--NME--`\n",
    "\n",
    "The following cell prints the first five samples from the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000-000</td>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000-000</td>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000-000</td>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>United_Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000-001</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000-002</td>\n",
       "      <td>BRUSSELS 1996-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brussels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                          sentence  beg  end  \\\n",
       "0    0000-000  EU rejects German call to boycott British lamb .    0    1   \n",
       "1    0000-000  EU rejects German call to boycott British lamb .    2    3   \n",
       "2    0000-000  EU rejects German call to boycott British lamb .    6    7   \n",
       "3    0000-001                                   Peter Blackburn    0    2   \n",
       "4    0000-002                               BRUSSELS 1996-08-22    0    1   \n",
       "\n",
       "            label  \n",
       "0         --NME--  \n",
       "1         Germany  \n",
       "2  United_Kingdom  \n",
       "3         --NME--  \n",
       "4        Brussels  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample, we see that the first sentence is annotated with three entity mentions:\n",
    "\n",
    "* the span 0–1 &lsquo;EU&rsquo; is annotated as a mention but only labelled with the generic `--NME--`\n",
    "* the span 2–3 &lsquo;German&rsquo; is annotated with the page [Germany](http://en.wikipedia.org/wiki/Germany)\n",
    "* the span 6–7 &lsquo;British&rsquo; is annotated with the page [United_Kingdom](http://en.wikipedia.org/wiki/United_Kingdom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Evaluation measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To warm up, we ask you to write code to print the three measures that you will be using for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_report(gold, pred):\n",
    "    \"\"\"Print precision, recall, and F1 score.\n",
    "    \n",
    "    Args:\n",
    "        gold: The set with the gold-standard values.\n",
    "        pred: The set with the predicted values.\n",
    "    \n",
    "    Returns:\n",
    "        Nothing, but prints the precision, recall, and F1 values computed\n",
    "        based on the specified sets.\n",
    "    \"\"\"\n",
    "    # TODO: Replace the next line with your own code\n",
    "    precision = len(set.intersection(gold, pred)) / len(pred)\n",
    "    \n",
    "    recall = len(set.intersection(gold, pred)) / len(gold)\n",
    "    \n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    print(f\"Precision: {round(precision*100,2)}%, Recall: {round(recall*100,2)}%, F1 score: {round(F1*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your code, you can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 60.0%, Recall: 100.0%, F1 score: 75.0%\n"
     ]
    }
   ],
   "source": [
    "evaluation_report(set(range(3)), set(range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give you a precision of 60%, a recall of 100%, and an F1-value of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Span recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first tasks that an information extraction system has to solve is to locate and classify (mentions of) named entities, such as persons and organizations. Here we will tackle the simpler task of recognizing **spans** of tokens that contain an entity mention, without the actual entity label.\n",
    "\n",
    "The English language model in spaCy features a full-fledged [named entity recognizer](https://spacy.io/usage/linguistic-features#named-entities) that identifies a variety of entities, and can be updated with new entity types by the user. Your task in this problem is to evaluate the performance of this component when predicting entity spans in the development data.\n",
    "\n",
    "Start by implementing a generator function that yields the gold-standard spans in a given data frame.\n",
    "\n",
    "**Hint:** The Pandas method [`itertuples()`](https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.itertuples.html) is useful when iterating over the rows in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_spans(df):\n",
    "    \"\"\"Yield the gold-standard mention spans in a data frame.\n",
    "\n",
    "    Args:\n",
    "        df: A data frame.\n",
    "\n",
    "    Yields:\n",
    "        The gold-standard mention spans in the specified data frame as\n",
    "        triples consisting of the sentence id, start position, and end\n",
    "        position of each span.\n",
    "    \"\"\"\n",
    "    # TODO: Replace the next line with your own code\n",
    "    for rows in df.itertuples():\n",
    "        yield (rows.sentence_id, rows.beg, rows.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your code, you can count the spans yielded by your function. When called on the development data, you should get a total of 5,917 unique triples. The first triple and the last triple should be\n",
    "\n",
    "    ('0946-000', 2, 3)\n",
    "    ('1161-010', 1, 3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5917\n"
     ]
    }
   ],
   "source": [
    "spans_dev_gold = set(gold_spans(df_dev))\n",
    "print(len(spans_dev_gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0956-019', 0, 1)\n",
      "('0999-003', 31, 32)\n"
     ]
    }
   ],
   "source": [
    "print(list(spans_dev_gold)[0])\n",
    "print(list(spans_dev_gold)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0946-000</td>\n",
       "      <td>CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTE...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Leicestershire_County_Cricket_Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0946-001</td>\n",
       "      <td>LONDON 1996-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>West_Indies_cricket_team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Phil_Simmons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Leicestershire_County_Cricket_Club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                           sentence  beg  end  \\\n",
       "0    0946-000  CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTE...    2    3   \n",
       "1    0946-001                                  LONDON 1996-08-30    0    1   \n",
       "2    0946-002  West Indian all-rounder Phil Simmons took four...    0    2   \n",
       "3    0946-002  West Indian all-rounder Phil Simmons took four...    3    5   \n",
       "4    0946-002  West Indian all-rounder Phil Simmons took four...   12   13   \n",
       "\n",
       "                                label  \n",
       "0  Leicestershire_County_Cricket_Club  \n",
       "1                              London  \n",
       "2            West_Indies_cricket_team  \n",
       "3                        Phil_Simmons  \n",
       "4  Leicestershire_County_Cricket_Club  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0946-000', 2, 3)\n",
      "('1161-010', 1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(list(gold_spans(df_dev))[0])\n",
    "print(list(gold_spans(df_dev))[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to write code that calls spaCy to predict the named entities in the development data, and to evaluate the accuracy of these predictions in terms of precision, recall, and F1. Print these scores using the function that you wrote for Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 52.14%, Recall: 70.22%, F1 score: 59.84%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write code here to run and evaluate the spaCy NER on the development data\n",
    "\n",
    "def spans(df):\n",
    "    for row_id in df.sentence_id.unique():\n",
    "        sent_doc = nlp(df.sentence[df.sentence_id == row_id].values[0])\n",
    "        for entity in sent_doc.ents:\n",
    "            yield (row_id, entity.start, entity.end)\n",
    "        \n",
    "evaluation_report(spans_dev_gold, set(spans(df_dev)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('0991-007', 29, 30),\n",
       " ('0948-015', 0, 3),\n",
       " ('0980-002', 0, 1),\n",
       " ('0968-002', 20, 23),\n",
       " ('1044-007', 11, 12),\n",
       " ('1069-003', 7, 8),\n",
       " ('1112-002', 16, 17),\n",
       " ('1112-008', 16, 17),\n",
       " ('0957-019', 7, 9),\n",
       " ('0979-012', 4, 5),\n",
       " ('0963-023', 8, 11),\n",
       " ('0966-070', 0, 1),\n",
       " ('0958-007', 2, 4),\n",
       " ('1083-002', 2, 3),\n",
       " ('1082-002', 13, 14),\n",
       " ('1157-002', 19, 20),\n",
       " ('1075-002', 13, 14),\n",
       " ('0966-164', 22, 23),\n",
       " ('0966-021', 0, 1),\n",
       " ('1060-021', 3, 4),\n",
       " ('1072-014', 18, 19),\n",
       " ('1159-003', 19, 20),\n",
       " ('1060-004', 0, 1),\n",
       " ('1097-007', 3, 6),\n",
       " ('1096-015', 3, 4),\n",
       " ('0958-010', 4, 6),\n",
       " ('0954-002', 29, 31),\n",
       " ('1058-030', 3, 4),\n",
       " ('1103-015', 68, 69),\n",
       " ('1078-005', 7, 8),\n",
       " ('1009-018', 31, 32),\n",
       " ('1022-001', 0, 1),\n",
       " ('1135-029', 6, 7),\n",
       " ('0980-006', 33, 34),\n",
       " ('0989-002', 26, 28),\n",
       " ('0957-006', 15, 16),\n",
       " ('0978-003', 6, 8),\n",
       " ('1018-003', 18, 19),\n",
       " ('0966-119', 0, 1),\n",
       " ('1064-007', 34, 35),\n",
       " ('0960-003', 5, 6),\n",
       " ('1033-002', 22, 23),\n",
       " ('1148-005', 13, 14),\n",
       " ('1006-007', 0, 1),\n",
       " ('1126-004', 1, 4),\n",
       " ('1025-011', 2, 3),\n",
       " ('1084-001', 0, 1),\n",
       " ('1060-001', 1, 2),\n",
       " ('1072-006', 0, 1),\n",
       " ('0946-005', 2, 3),\n",
       " ('1111-006', 1, 2),\n",
       " ('1043-002', 14, 18),\n",
       " ('1058-025', 4, 5),\n",
       " ('1059-005', 33, 34),\n",
       " ('1029-017', 7, 8),\n",
       " ('0957-019', 13, 15),\n",
       " ('1133-004', 38, 39),\n",
       " ('1137-008', 7, 9),\n",
       " ('1066-063', 1, 7),\n",
       " ('1037-002', 8, 9),\n",
       " ('1060-016', 4, 6),\n",
       " ('1053-002', 14, 15),\n",
       " ('1126-008', 10, 12),\n",
       " ('1069-012', 1, 5),\n",
       " ('1000-000', 0, 1),\n",
       " ('1013-000', 0, 2),\n",
       " ('1130-005', 41, 42),\n",
       " ('1022-010', 10, 11),\n",
       " ('1073-005', 2, 4),\n",
       " ('1143-002', 25, 26),\n",
       " ('1011-013', 10, 12),\n",
       " ('0995-019', 20, 21),\n",
       " ('1138-011', 0, 1),\n",
       " ('1060-017', 1, 3),\n",
       " ('0965-004', 23, 25),\n",
       " ('0947-011', 19, 21),\n",
       " ('1101-002', 3, 5),\n",
       " ('0946-012', 11, 12),\n",
       " ('1057-007', 28, 30),\n",
       " ('1091-004', 4, 5),\n",
       " ('0966-119', 6, 7),\n",
       " ('0977-002', 9, 15),\n",
       " ('1035-010', 23, 24),\n",
       " ('1081-002', 4, 5),\n",
       " ('1099-018', 2, 4),\n",
       " ('0966-135', 4, 5),\n",
       " ('0953-004', 10, 12),\n",
       " ('0992-000', 1, 2),\n",
       " ('1064-004', 21, 22),\n",
       " ('0954-001', 0, 2),\n",
       " ('0957-026', 3, 4),\n",
       " ('0984-016', 38, 39),\n",
       " ('1073-002', 8, 9),\n",
       " ('1109-001', 0, 1),\n",
       " ('0956-016', 3, 4),\n",
       " ('1056-001', 0, 1),\n",
       " ('1096-025', 28, 30),\n",
       " ('0952-002', 18, 20),\n",
       " ('1056-024', 1, 3),\n",
       " ('1051-009', 20, 24),\n",
       " ('1108-003', 15, 16),\n",
       " ('0981-003', 28, 31),\n",
       " ('1090-016', 5, 8),\n",
       " ('0966-161', 10, 11),\n",
       " ('0946-009', 24, 25),\n",
       " ('0974-007', 2, 4),\n",
       " ('1001-002', 0, 5),\n",
       " ('1000-016', 0, 1),\n",
       " ('1011-020', 33, 34),\n",
       " ('0995-007', 2, 4),\n",
       " ('1117-000', 1, 2),\n",
       " ('0966-075', 4, 5),\n",
       " ('1054-009', 4, 5),\n",
       " ('0980-016', 13, 14),\n",
       " ('1051-011', 18, 19),\n",
       " ('1055-007', 0, 2),\n",
       " ('1156-000', 0, 1),\n",
       " ('1152-010', 1, 2),\n",
       " ('1117-005', 27, 28),\n",
       " ('0966-018', 6, 7),\n",
       " ('1046-003', 21, 23),\n",
       " ('0966-073', 0, 1),\n",
       " ('0966-096', 1, 3),\n",
       " ('1124-009', 28, 29),\n",
       " ('0966-058', 6, 7),\n",
       " ('1143-003', 14, 15),\n",
       " ('1016-005', 3, 5),\n",
       " ('0946-003', 17, 18),\n",
       " ('1146-005', 48, 49),\n",
       " ('1032-003', 4, 5),\n",
       " ('1142-001', 1, 2),\n",
       " ('0960-014', 34, 35),\n",
       " ('0953-003', 20, 22),\n",
       " ('1001-006', 4, 5),\n",
       " ('1069-015', 15, 18),\n",
       " ('1006-012', 12, 13),\n",
       " ('1011-014', 0, 1),\n",
       " ('1036-034', 10, 11),\n",
       " ('0991-006', 0, 1),\n",
       " ('1066-020', 1, 8),\n",
       " ('1135-004', 37, 39),\n",
       " ('1009-011', 0, 1),\n",
       " ('1058-027', 28, 29),\n",
       " ('1076-035', 0, 1),\n",
       " ('1118-007', 0, 1),\n",
       " ('1105-003', 4, 5),\n",
       " ('1152-015', 7, 9),\n",
       " ('1091-003', 36, 38),\n",
       " ('0959-006', 1, 2),\n",
       " ('1058-039', 4, 6),\n",
       " ('1047-002', 9, 10),\n",
       " ('1069-006', 7, 8),\n",
       " ('1130-001', 1, 2),\n",
       " ('1101-003', 37, 39),\n",
       " ('0972-023', 0, 2),\n",
       " ('1117-003', 24, 25),\n",
       " ('1091-001', 2, 3),\n",
       " ('1064-007', 37, 38),\n",
       " ('0972-008', 6, 7),\n",
       " ('1066-043', 1, 8),\n",
       " ('1028-000', 0, 6),\n",
       " ('1094-040', 5, 7),\n",
       " ('1059-006', 18, 19),\n",
       " ('1155-011', 16, 18),\n",
       " ('1060-018', 6, 7),\n",
       " ('1055-029', 0, 2),\n",
       " ('0984-009', 9, 10),\n",
       " ('1046-008', 4, 6),\n",
       " ('1003-007', 15, 18),\n",
       " ('1069-008', 1, 2),\n",
       " ('1099-003', 0, 1),\n",
       " ('1155-010', 31, 32),\n",
       " ('1142-008', 0, 1),\n",
       " ('1016-009', 5, 7),\n",
       " ('1006-011', 6, 7),\n",
       " ('1061-005', 3, 4),\n",
       " ('0966-041', 0, 1),\n",
       " ('0966-164', 16, 17),\n",
       " ('0980-002', 24, 25),\n",
       " ('0976-005', 1, 3),\n",
       " ('1064-003', 17, 18),\n",
       " ('1154-003', 29, 30),\n",
       " ('0966-064', 1, 3),\n",
       " ('1119-005', 11, 12),\n",
       " ('1032-003', 10, 11),\n",
       " ('1101-008', 1, 3),\n",
       " ('1094-048', 0, 2),\n",
       " ('0971-003', 8, 10),\n",
       " ('1135-027', 16, 17),\n",
       " ('0946-014', 18, 19),\n",
       " ('0966-035', 6, 7),\n",
       " ('1005-008', 12, 13),\n",
       " ('1123-009', 0, 1),\n",
       " ('0947-009', 18, 20),\n",
       " ('1000-004', 14, 15),\n",
       " ('1089-010', 19, 20),\n",
       " ('1006-003', 10, 14),\n",
       " ('1027-020', 12, 13),\n",
       " ('1089-004', 23, 25),\n",
       " ('0957-020', 35, 36),\n",
       " ('1019-002', 11, 13),\n",
       " ('1099-018', 5, 7),\n",
       " ('1152-014', 49, 52),\n",
       " ('0966-026', 4, 5),\n",
       " ('1059-004', 29, 31),\n",
       " ('0966-012', 6, 10),\n",
       " ('0972-012', 3, 4),\n",
       " ('1116-014', 3, 7),\n",
       " ('1115-008', 30, 31),\n",
       " ('1125-008', 41, 42),\n",
       " ('0946-005', 11, 12),\n",
       " ('0966-033', 4, 5),\n",
       " ('1005-004', 1, 3),\n",
       " ('1014-009', 6, 7),\n",
       " ('0991-008', 0, 3),\n",
       " ('0959-012', 3, 4),\n",
       " ('1017-006', 23, 24),\n",
       " ('1046-003', 1, 2),\n",
       " ('1000-015', 38, 39),\n",
       " ('1043-004', 23, 26),\n",
       " ('1022-005', 1, 2),\n",
       " ('1066-076', 1, 4),\n",
       " ('1069-010', 15, 18),\n",
       " ('0966-149', 6, 7),\n",
       " ('1090-014', 10, 12),\n",
       " ('1036-017', 9, 10),\n",
       " ('0957-012', 11, 12),\n",
       " ('0953-003', 0, 1),\n",
       " ('1118-001', 2, 3),\n",
       " ('1011-006', 11, 14),\n",
       " ('1051-004', 6, 7),\n",
       " ('1125-006', 0, 1),\n",
       " ('1057-007', 22, 24),\n",
       " ('1036-020', 8, 9),\n",
       " ('1032-009', 1, 2),\n",
       " ('1075-002', 7, 10),\n",
       " ('1097-020', 10, 11),\n",
       " ('1072-011', 9, 13),\n",
       " ('1160-004', 24, 25),\n",
       " ('1058-009', 17, 19),\n",
       " ('0972-037', 3, 5),\n",
       " ('0966-120', 1, 3),\n",
       " ('1070-015', 4, 5),\n",
       " ('1155-014', 17, 18),\n",
       " ('1101-011', 61, 64),\n",
       " ('0975-004', 6, 8),\n",
       " ('1103-012', 15, 17),\n",
       " ('1016-013', 7, 8),\n",
       " ('1095-020', 4, 5),\n",
       " ('1130-006', 0, 1),\n",
       " ('1160-010', 24, 25),\n",
       " ('1099-018', 11, 13),\n",
       " ('1097-016', 0, 1),\n",
       " ('1025-009', 18, 19),\n",
       " ('1073-010', 5, 6),\n",
       " ('1152-016', 14, 15),\n",
       " ('1139-006', 21, 23),\n",
       " ('0980-019', 46, 47),\n",
       " ('1046-002', 21, 22),\n",
       " ('1144-003', 7, 8),\n",
       " ('1030-036', 11, 12),\n",
       " ('0966-110', 4, 5),\n",
       " ('1128-001', 0, 1),\n",
       " ('1029-013', 17, 18),\n",
       " ('1070-012', 1, 3),\n",
       " ('1094-041', 1, 6),\n",
       " ('0994-011', 18, 19),\n",
       " ('1007-025', 24, 25),\n",
       " ('1054-011', 0, 1),\n",
       " ('1051-010', 0, 1),\n",
       " ('0974-007', 11, 13),\n",
       " ('1051-007', 4, 5),\n",
       " ('1016-010', 5, 6),\n",
       " ('1033-010', 10, 11),\n",
       " ('0966-018', 0, 1),\n",
       " ('1087-004', 4, 5),\n",
       " ('0957-013', 0, 2),\n",
       " ('1155-010', 34, 35),\n",
       " ('1073-004', 10, 11),\n",
       " ('1089-011', 0, 1),\n",
       " ('1131-006', 27, 28),\n",
       " ('1098-002', 22, 26),\n",
       " ('0966-164', 19, 20),\n",
       " ('1054-017', 4, 5),\n",
       " ('1011-012', 18, 20),\n",
       " ('0980-014', 8, 9),\n",
       " ('0984-017', 17, 18),\n",
       " ('1055-020', 2, 3),\n",
       " ('1083-002', 14, 15),\n",
       " ('0966-014', 4, 5),\n",
       " ('1064-002', 16, 17),\n",
       " ('0966-129', 4, 5),\n",
       " ('0981-005', 4, 6),\n",
       " ('0980-003', 16, 18),\n",
       " ('1055-025', 3, 5),\n",
       " ('0990-001', 0, 1),\n",
       " ('1092-004', 7, 8),\n",
       " ('0966-081', 0, 1),\n",
       " ('1046-001', 0, 2),\n",
       " ('1012-004', 5, 6),\n",
       " ('0966-047', 4, 5),\n",
       " ('1054-012', 0, 1),\n",
       " ('1073-002', 23, 24),\n",
       " ('1088-001', 0, 2),\n",
       " ('1091-003', 45, 47),\n",
       " ('1097-003', 31, 32),\n",
       " ('0997-001', 0, 1),\n",
       " ('1070-012', 7, 9),\n",
       " ('0987-001', 1, 2),\n",
       " ('1055-028', 0, 2),\n",
       " ('1076-023', 0, 1),\n",
       " ('1135-005', 0, 2),\n",
       " ('1121-000', 3, 4),\n",
       " ('0958-051', 2, 3),\n",
       " ('1117-001', 0, 1),\n",
       " ('1094-008', 0, 2),\n",
       " ('1096-018', 7, 9),\n",
       " ('0981-008', 11, 14),\n",
       " ('0957-013', 6, 8),\n",
       " ('1099-003', 9, 10),\n",
       " ('1032-002', 35, 36),\n",
       " ('0990-000', 0, 1),\n",
       " ('0981-008', 23, 24),\n",
       " ('1025-008', 1, 2),\n",
       " ('1030-037', 14, 16),\n",
       " ('1057-007', 2, 3),\n",
       " ('0966-078', 4, 5),\n",
       " ('1083-002', 20, 21),\n",
       " ('1028-011', 7, 8),\n",
       " ('1121-001', 0, 1),\n",
       " ('1072-003', 32, 33),\n",
       " ('1145-003', 22, 24),\n",
       " ('1076-006', 6, 7),\n",
       " ('1005-009', 9, 12),\n",
       " ('1094-009', 0, 2),\n",
       " ('1127-008', 21, 23),\n",
       " ('1121-008', 33, 34),\n",
       " ('1038-003', 51, 53),\n",
       " ('0977-002', 16, 20),\n",
       " ('0957-020', 29, 30),\n",
       " ('1116-027', 0, 6),\n",
       " ('1057-007', 25, 27),\n",
       " ('1103-015', 60, 61),\n",
       " ('1116-018', 6, 8),\n",
       " ('0966-134', 1, 3),\n",
       " ('0959-011', 3, 4),\n",
       " ('0966-157', 4, 5),\n",
       " ('1090-007', 33, 35),\n",
       " ('0966-121', 4, 5),\n",
       " ('0952-006', 6, 7),\n",
       " ('1126-002', 9, 11),\n",
       " ('1003-002', 2, 3),\n",
       " ('1135-006', 1, 2),\n",
       " ('1154-006', 22, 24),\n",
       " ('1151-006', 20, 21),\n",
       " ('0966-076', 1, 3),\n",
       " ('0994-008', 21, 22),\n",
       " ('1099-018', 14, 16),\n",
       " ('1128-001', 1, 2),\n",
       " ('1124-006', 40, 43),\n",
       " ('1054-025', 0, 1),\n",
       " ('0957-018', 37, 38),\n",
       " ('0946-007', 32, 33),\n",
       " ('1029-009', 25, 26),\n",
       " ('1067-014', 0, 4),\n",
       " ('1004-007', 11, 12),\n",
       " ('1044-004', 1, 2),\n",
       " ('0958-020', 1, 3),\n",
       " ('0948-033', 7, 8),\n",
       " ('0958-021', 0, 3),\n",
       " ('1025-008', 7, 8),\n",
       " ('1004-003', 1, 2),\n",
       " ('1103-006', 14, 15),\n",
       " ('1063-002', 2, 4),\n",
       " ('1072-008', 12, 14),\n",
       " ('1054-019', 0, 1),\n",
       " ('0995-010', 0, 1),\n",
       " ('0958-007', 0, 2),\n",
       " ('1123-007', 1, 4),\n",
       " ('1045-004', 32, 33),\n",
       " ('1089-011', 23, 27),\n",
       " ('0963-023', 0, 2),\n",
       " ('1067-015', 3, 4),\n",
       " ('1051-004', 0, 1),\n",
       " ('0966-141', 0, 1),\n",
       " ('1061-013', 1, 2),\n",
       " ('0947-007', 0, 2),\n",
       " ('0949-005', 22, 23),\n",
       " ('1045-006', 29, 34),\n",
       " ('0966-160', 2, 3),\n",
       " ('1103-004', 0, 1),\n",
       " ('1035-009', 15, 16),\n",
       " ('1050-003', 8, 10),\n",
       " ('1101-011', 65, 66),\n",
       " ('1089-025', 21, 22),\n",
       " ('1161-007', 10, 12),\n",
       " ('1072-015', 29, 30),\n",
       " ('0966-091', 6, 7),\n",
       " ('1062-003', 22, 23),\n",
       " ('0946-014', 7, 8),\n",
       " ('1101-002', 6, 8),\n",
       " ('0985-009', 2, 3),\n",
       " ('0989-002', 3, 4),\n",
       " ('1057-007', 31, 33),\n",
       " ('1103-010', 16, 18),\n",
       " ('0954-002', 21, 22),\n",
       " ('0956-001', 0, 2),\n",
       " ('0966-024', 0, 1),\n",
       " ('1139-002', 0, 1),\n",
       " ('0957-006', 13, 14),\n",
       " ('1159-004', 33, 34),\n",
       " ('0984-016', 41, 42),\n",
       " ('1052-004', 0, 6),\n",
       " ('0961-004', 6, 7),\n",
       " ('0966-156', 1, 3),\n",
       " ('0994-008', 27, 28),\n",
       " ('1099-018', 20, 22),\n",
       " ('0997-001', 1, 2),\n",
       " ('0991-009', 1, 2),\n",
       " ('1087-020', 19, 20),\n",
       " ('0984-004', 5, 13),\n",
       " ('0995-012', 0, 1),\n",
       " ('0963-001', 2, 3),\n",
       " ('1094-040', 0, 2),\n",
       " ('1025-011', 0, 1),\n",
       " ('0966-050', 0, 1),\n",
       " ('0976-001', 1, 2),\n",
       " ('1108-000', 0, 4),\n",
       " ('0990-003', 5, 6),\n",
       " ('1009-015', 0, 4),\n",
       " ('0980-009', 3, 6),\n",
       " ('1033-006', 3, 4),\n",
       " ('0981-003', 2, 6),\n",
       " ('1001-002', 25, 26),\n",
       " ('1043-003', 14, 15),\n",
       " ('1054-009', 7, 8),\n",
       " ('0995-010', 6, 7),\n",
       " ('1094-029', 2, 3),\n",
       " ('0974-007', 20, 22),\n",
       " ('0954-005', 5, 6),\n",
       " ('0956-002', 2, 4),\n",
       " ('1050-003', 14, 16),\n",
       " ('1090-010', 0, 3),\n",
       " ('1103-007', 17, 20),\n",
       " ('0963-023', 17, 22),\n",
       " ('1089-025', 27, 28),\n",
       " ('0958-043', 1, 3),\n",
       " ('1017-004', 4, 5),\n",
       " ('0984-013', 2, 3),\n",
       " ('0954-002', 27, 28),\n",
       " ('0966-024', 6, 7),\n",
       " ('1096-037', 5, 6),\n",
       " ('1142-013', 6, 7),\n",
       " ('1142-009', 32, 33),\n",
       " ('1152-013', 5, 6),\n",
       " ('1085-001', 1, 2),\n",
       " ('1152-014', 23, 25),\n",
       " ('1096-032', 9, 10),\n",
       " ('1116-035', 0, 1),\n",
       " ('1005-010', 28, 29),\n",
       " ('1116-027', 10, 12),\n",
       " ('0990-009', 0, 1),\n",
       " ('1121-008', 36, 37),\n",
       " ('1031-012', 2, 3),\n",
       " ('1101-003', 6, 7),\n",
       " ('1121-008', 39, 42),\n",
       " ('1128-013', 7, 8),\n",
       " ('0984-006', 4, 5),\n",
       " ('1005-010', 18, 21),\n",
       " ('1096-035', 4, 5),\n",
       " ('1089-017', 22, 24),\n",
       " ('0966-050', 6, 7),\n",
       " ('1035-010', 36, 37),\n",
       " ('0980-000', 8, 10),\n",
       " ('0960-025', 13, 14),\n",
       " ('0972-025', 3, 6),\n",
       " ('0957-010', 11, 12),\n",
       " ('0984-009', 12, 13),\n",
       " ('0966-126', 1, 3),\n",
       " ('1065-007', 1, 4),\n",
       " ('0960-010', 0, 1),\n",
       " ('1056-025', 0, 1),\n",
       " ('0948-021', 0, 1),\n",
       " ('1069-013', 9, 12),\n",
       " ('1060-024', 1, 3),\n",
       " ('0966-162', 0, 1),\n",
       " ('1058-011', 10, 11),\n",
       " ('1143-002', 29, 30),\n",
       " ('0958-037', 4, 5),\n",
       " ('0968-003', 0, 5),\n",
       " ('0998-002', 5, 6),\n",
       " ('1030-037', 23, 25),\n",
       " ('0983-004', 1, 2),\n",
       " ('1068-008', 2, 4),\n",
       " ('1013-002', 16, 17),\n",
       " ('1124-009', 26, 27),\n",
       " ('1060-020', 7, 8),\n",
       " ('0972-015', 4, 5),\n",
       " ('1096-032', 15, 16),\n",
       " ('1150-001', 2, 4),\n",
       " ('0960-014', 32, 33),\n",
       " ('0946-008', 33, 34),\n",
       " ('1101-011', 68, 69),\n",
       " ('0972-037', 0, 2),\n",
       " ('1089-026', 23, 24),\n",
       " ('0946-012', 17, 18),\n",
       " ('0982-005', 9, 10),\n",
       " ('1137-002', 18, 19),\n",
       " ('1152-005', 34, 36),\n",
       " ('1081-002', 10, 11),\n",
       " ('0962-010', 19, 21),\n",
       " ('1033-003', 19, 20),\n",
       " ('1076-014', 0, 1),\n",
       " ('1029-002', 0, 1),\n",
       " ('1090-018', 17, 18),\n",
       " ('1012-007', 5, 8),\n",
       " ('1154-008', 20, 21),\n",
       " ('1044-005', 2, 3),\n",
       " ('0972-012', 6, 7),\n",
       " ('1014-002', 27, 28),\n",
       " ('1135-006', 21, 25),\n",
       " ('0997-004', 1, 2),\n",
       " ('1096-020', 5, 7),\n",
       " ('0999-000', 0, 1),\n",
       " ('0966-161', 16, 17),\n",
       " ('1000-015', 41, 42),\n",
       " ('1119-001', 0, 1),\n",
       " ('1063-002', 11, 13),\n",
       " ('1072-008', 21, 23),\n",
       " ('1137-003', 36, 37),\n",
       " ('1065-012', 1, 8),\n",
       " ('1139-008', 20, 21),\n",
       " ('1007-004', 1, 2),\n",
       " ('1142-011', 15, 16),\n",
       " ('1019-004', 17, 18),\n",
       " ('1000-019', 1, 2),\n",
       " ('1033-013', 17, 18),\n",
       " ('0960-007', 22, 23),\n",
       " ('1072-018', 71, 72),\n",
       " ('0996-002', 27, 28),\n",
       " ('1158-001', 1, 2),\n",
       " ('1058-012', 3, 4),\n",
       " ('0985-002', 14, 15),\n",
       " ('0980-003', 5, 6),\n",
       " ('0991-006', 4, 5),\n",
       " ('0966-035', 4, 5),\n",
       " ('1061-003', 5, 6),\n",
       " ('1084-002', 2, 3),\n",
       " ('1135-008', 18, 19),\n",
       " ('1087-002', 25, 26),\n",
       " ('0948-037', 0, 2),\n",
       " ('1089-026', 0, 2),\n",
       " ('0957-020', 15, 17),\n",
       " ('1116-032', 7, 10),\n",
       " ('1000-014', 10, 13),\n",
       " ('1012-003', 19, 21),\n",
       " ('1096-025', 6, 7),\n",
       " ('1159-005', 26, 27),\n",
       " ('1118-007', 6, 7),\n",
       " ('1139-006', 5, 6),\n",
       " ('1116-008', 14, 15),\n",
       " ('1158-005', 1, 2),\n",
       " ('1065-013', 1, 2),\n",
       " ('1006-007', 7, 8),\n",
       " ('1121-003', 9, 10),\n",
       " ('0966-144', 1, 3),\n",
       " ('1052-002', 2, 5),\n",
       " ('0972-005', 6, 7),\n",
       " ('1004-007', 0, 1),\n",
       " ('1033-005', 7, 8),\n",
       " ('1051-010', 3, 4),\n",
       " ('1076-024', 0, 4),\n",
       " ('0966-055', 1, 3),\n",
       " ('1060-005', 0, 1),\n",
       " ('0956-005', 3, 4),\n",
       " ('1059-006', 24, 25),\n",
       " ('1033-005', 22, 23),\n",
       " ('0969-003', 7, 8),\n",
       " ('1030-039', 24, 25),\n",
       " ('0984-009', 15, 16),\n",
       " ('1066-039', 0, 1),\n",
       " ('1007-014', 23, 25),\n",
       " ('1094-010', 4, 6),\n",
       " ('1012-008', 0, 3),\n",
       " ('1033-007', 24, 26),\n",
       " ('1011-013', 2, 4),\n",
       " ('1025-006', 16, 17),\n",
       " ('0979-003', 17, 18),\n",
       " ('0995-019', 12, 13),\n",
       " ('1066-021', 1, 8),\n",
       " ('1093-001', 0, 2),\n",
       " ('1096-023', 9, 10),\n",
       " ('0948-022', 0, 3),\n",
       " ('0983-005', 20, 21),\n",
       " ('1093-002', 4, 6),\n",
       " ('1090-010', 6, 7),\n",
       " ('1026-002', 7, 8),\n",
       " ('0957-012', 9, 10),\n",
       " ('1096-041', 3, 5),\n",
       " ('1029-014', 2, 4),\n",
       " ('0992-002', 7, 8),\n",
       " ('1013-002', 7, 10),\n",
       " ('1072-015', 21, 24),\n",
       " ('1160-004', 4, 6),\n",
       " ('1121-004', 20, 21),\n",
       " ('1008-018', 27, 30),\n",
       " ('1050-001', 1, 2),\n",
       " ('1101-004', 3, 5),\n",
       " ('1046-010', 11, 12),\n",
       " ('1058-043', 0, 2),\n",
       " ('0999-002', 1, 2),\n",
       " ('0959-011', 0, 1),\n",
       " ('0997-002', 14, 15),\n",
       " ('1039-007', 2, 3),\n",
       " ('1125-006', 3, 6),\n",
       " ('1090-007', 30, 32),\n",
       " ('1133-006', 22, 24),\n",
       " ('1019-003', 4, 5),\n",
       " ('0984-006', 13, 14),\n",
       " ('1128-003', 10, 11),\n",
       " ('1089-026', 26, 27),\n",
       " ('0966-153', 6, 7),\n",
       " ('1133-014', 21, 22),\n",
       " ('1097-003', 5, 7),\n",
       " ('1008-004', 9, 11),\n",
       " ('1017-012', 16, 17),\n",
       " ('1036-018', 11, 13),\n",
       " ('1112-000', 7, 9),\n",
       " ('1043-003', 3, 4),\n",
       " ('1044-004', 11, 12),\n",
       " ('0957-016', 5, 6),\n",
       " ('0966-082', 0, 1),\n",
       " ('1017-006', 17, 20),\n",
       " ('1022-005', 5, 6),\n",
       " ('1133-001', 1, 2),\n",
       " ('1051-010', 32, 34),\n",
       " ('0950-004', 8, 9),\n",
       " ('0972-011', 2, 4),\n",
       " ('1014-001', 0, 1),\n",
       " ('0948-036', 9, 10),\n",
       " ('0975-001', 1, 2),\n",
       " ('1004-005', 9, 10),\n",
       " ('1058-011', 19, 20),\n",
       " ('1007-029', 4, 6),\n",
       " ('1061-015', 0, 2),\n",
       " ('0963-021', 6, 7),\n",
       " ('0957-021', 13, 15),\n",
       " ('1007-018', 40, 45),\n",
       " ('1005-005', 30, 32),\n",
       " ('1068-021', 2, 3),\n",
       " ('1066-028', 1, 2),\n",
       " ('0954-002', 16, 17),\n",
       " ('1055-020', 0, 1),\n",
       " ('1160-004', 28, 29),\n",
       " ('1094-055', 0, 1),\n",
       " ('1147-002', 0, 2),\n",
       " ('0995-011', 22, 23),\n",
       " ('0946-003', 24, 25),\n",
       " ('1051-002', 13, 14),\n",
       " ('1122-004', 0, 3),\n",
       " ('1028-001', 2, 3),\n",
       " ('0947-011', 0, 1),\n",
       " ('1054-005', 1, 3),\n",
       " ('1103-002', 1, 2),\n",
       " ('0982-002', 21, 22),\n",
       " ('0959-002', 2, 4),\n",
       " ('1123-009', 1, 2),\n",
       " ('1131-001', 1, 2),\n",
       " ('1033-008', 2, 4),\n",
       " ('1054-010', 4, 5),\n",
       " ('1161-002', 2, 6),\n",
       " ('1042-000', 0, 1),\n",
       " ('1076-021', 0, 1),\n",
       " ('1003-005', 5, 6),\n",
       " ('1128-010', 4, 7),\n",
       " ('1015-003', 26, 27),\n",
       " ('1096-026', 2, 3),\n",
       " ('0966-019', 0, 1),\n",
       " ('0966-067', 6, 7),\n",
       " ('1089-002', 0, 2),\n",
       " ('0966-043', 0, 1),\n",
       " ('1008-010', 35, 36),\n",
       " ('0981-017', 2, 4),\n",
       " ('1011-003', 7, 11),\n",
       " ('1132-003', 13, 15),\n",
       " ('1006-009', 20, 23),\n",
       " ('1116-006', 31, 32),\n",
       " ('1058-037', 19, 21),\n",
       " ('1090-003', 22, 23),\n",
       " ('1126-001', 0, 1),\n",
       " ('1055-010', 4, 5),\n",
       " ('1031-008', 25, 26),\n",
       " ('1061-006', 0, 1),\n",
       " ('1072-018', 80, 81),\n",
       " ('1127-002', 2, 3),\n",
       " ('1005-014', 31, 36),\n",
       " ('1117-002', 9, 11),\n",
       " ('1022-010', 20, 21),\n",
       " ('1135-015', 1, 2),\n",
       " ('1059-003', 18, 20),\n",
       " ('1143-003', 38, 42),\n",
       " ('1094-036', 0, 2),\n",
       " ('1017-003', 21, 23),\n",
       " ('1060-020', 1, 4),\n",
       " ('0946-012', 6, 7),\n",
       " ('0970-006', 24, 25),\n",
       " ('0959-011', 1, 2),\n",
       " ('0966-145', 1, 3),\n",
       " ('1005-010', 25, 26),\n",
       " ('1138-008', 13, 15),\n",
       " ('1006-007', 1, 2),\n",
       " ('0972-006', 0, 2),\n",
       " ('1066-015', 1, 3),\n",
       " ('1130-002', 25, 26),\n",
       " ('1004-004', 10, 13),\n",
       " ('0966-019', 6, 7),\n",
       " ('1121-000', 7, 8),\n",
       " ('0966-043', 6, 7),\n",
       " ('1058-004', 0, 1),\n",
       " ('1097-003', 37, 38),\n",
       " ('1126-004', 14, 15),\n",
       " ('1000-014', 30, 36),\n",
       " ('1029-009', 5, 7),\n",
       " ('0957-018', 35, 36),\n",
       " ('1128-004', 19, 21),\n",
       " ('0975-002', 17, 19),\n",
       " ('1007-033', 20, 22),\n",
       " ('1033-005', 16, 17),\n",
       " ('1047-003', 1, 2),\n",
       " ('1149-001', 1, 2),\n",
       " ('1039-010', 2, 7),\n",
       " ('1080-001', 1, 2),\n",
       " ('0983-000', 0, 1),\n",
       " ('1112-002', 12, 13),\n",
       " ('0972-014', 5, 6),\n",
       " ('0948-036', 0, 3),\n",
       " ('0946-009', 34, 35),\n",
       " ('0960-010', 12, 13),\n",
       " ('1005-006', 28, 30),\n",
       " ('0966-028', 0, 1),\n",
       " ('1133-003', 39, 40),\n",
       " ('0967-006', 9, 10),\n",
       " ('1096-014', 0, 2),\n",
       " ('0966-051', 1, 3),\n",
       " ('0957-012', 18, 19),\n",
       " ('1009-000', 5, 6),\n",
       " ('1076-006', 0, 3),\n",
       " ('1122-001', 1, 2),\n",
       " ('1139-000', 0, 1),\n",
       " ('0953-003', 7, 8),\n",
       " ('1135-001', 0, 2),\n",
       " ('0966-091', 4, 5),\n",
       " ('0946-002', 0, 2),\n",
       " ('1096-006', 5, 7),\n",
       " ('1059-001', 0, 1),\n",
       " ('1140-005', 25, 27),\n",
       " ('1160-003', 31, 32),\n",
       " ('0959-005', 0, 1),\n",
       " ('1004-002', 0, 1),\n",
       " ('0965-007', 2, 3),\n",
       " ('0966-010', 6, 7),\n",
       " ('0946-011', 7, 8),\n",
       " ('1101-011', 24, 28),\n",
       " ('0966-108', 6, 7),\n",
       " ('0958-039', 3, 5),\n",
       " ('1090-011', 6, 7),\n",
       " ('0966-153', 0, 1),\n",
       " ('0994-007', 0, 1),\n",
       " ('1153-006', 14, 16),\n",
       " ('1031-006', 26, 27),\n",
       " ('1066-009', 1, 7),\n",
       " ('0962-010', 16, 18),\n",
       " ('0948-020', 0, 4),\n",
       " ('1124-002', 5, 6),\n",
       " ('1006-014', 0, 1),\n",
       " ('1057-003', 25, 26),\n",
       " ('1070-013', 8, 10),\n",
       " ('1099-008', 0, 1),\n",
       " ('0963-001', 0, 1),\n",
       " ('1127-006', 10, 12),\n",
       " ('0985-011', 15, 17),\n",
       " ('1059-004', 10, 11),\n",
       " ('1155-011', 3, 4),\n",
       " ('1155-012', 12, 13),\n",
       " ('1072-008', 16, 18),\n",
       " ('0968-004', 43, 44),\n",
       " ('1069-016', 4, 5),\n",
       " ('0995-010', 4, 5),\n",
       " ('1094-029', 0, 1),\n",
       " ('1012-008', 33, 35),\n",
       " ('1016-010', 12, 13),\n",
       " ('0960-007', 17, 18),\n",
       " ('1068-013', 2, 5),\n",
       " ('1097-007', 2, 3),\n",
       " ('1038-002', 8, 9),\n",
       " ('1055-008', 0, 2),\n",
       " ('1006-013', 0, 3),\n",
       " ('0990-002', 10, 12),\n",
       " ('1093-004', 8, 9),\n",
       " ('1126-010', 16, 17),\n",
       " ('1143-003', 18, 21),\n",
       " ('1017-003', 1, 2),\n",
       " ('0953-002', 0, 1),\n",
       " ('0966-024', 4, 5),\n",
       " ('0958-048', 2, 4),\n",
       " ('0963-021', 26, 30),\n",
       " ('1083-002', 21, 22),\n",
       " ('1094-011', 4, 6),\n",
       " ('0994-010', 31, 34),\n",
       " ('1070-015', 7, 10),\n",
       " ('1058-040', 7, 9),\n",
       " ('0962-010', 22, 24),\n",
       " ('1058-040', 25, 26),\n",
       " ('1066-057', 0, 1),\n",
       " ('1107-001', 1, 2),\n",
       " ('1054-004', 3, 4),\n",
       " ('1141-003', 2, 3),\n",
       " ('0966-050', 4, 5),\n",
       " ('0961-004', 12, 13),\n",
       " ('1056-011', 6, 7),\n",
       " ('1116-009', 6, 7),\n",
       " ('1070-008', 1, 3),\n",
       " ('0991-002', 27, 31),\n",
       " ('1051-009', 39, 41),\n",
       " ('1061-018', 3, 4),\n",
       " ('1058-026', 10, 12),\n",
       " ('1065-002', 0, 1),\n",
       " ('1006-009', 24, 25),\n",
       " ('1056-023', 4, 5),\n",
       " ('1031-014', 32, 35),\n",
       " ('0992-009', 1, 2),\n",
       " ('0965-012', 13, 14),\n",
       " ('1116-016', 3, 4),\n",
       " ('0947-010', 3, 4),\n",
       " ('1135-021', 8, 10),\n",
       " ('0954-000', 0, 5),\n",
       " ('1096-013', 3, 6),\n",
       " ('0961-007', 10, 11),\n",
       " ('1000-015', 15, 17),\n",
       " ('1045-006', 4, 6),\n",
       " ('0985-001', 0, 1),\n",
       " ('1009-003', 17, 19),\n",
       " ('1096-002', 0, 3),\n",
       " ('1076-042', 0, 1),\n",
       " ('1098-002', 0, 1),\n",
       " ('0974-010', 0, 2),\n",
       " ('1030-039', 36, 37),\n",
       " ('1117-008', 8, 9),\n",
       " ('1129-004', 8, 9),\n",
       " ('1101-012', 19, 20),\n",
       " ('1006-003', 0, 1),\n",
       " ('1111-008', 3, 4),\n",
       " ('1031-004', 15, 21),\n",
       " ('1005-003', 0, 2),\n",
       " ('0960-011', 34, 35),\n",
       " ('1130-004', 8, 9),\n",
       " ('1060-006', 0, 1),\n",
       " ('1031-012', 6, 7),\n",
       " ('0957-020', 18, 20),\n",
       " ('1156-004', 30, 32),\n",
       " ('1089-017', 26, 28),\n",
       " ('1091-003', 11, 12),\n",
       " ('1096-025', 9, 10),\n",
       " ('1140-005', 28, 30),\n",
       " ('1116-005', 14, 15),\n",
       " ('0960-009', 15, 16),\n",
       " ('0965-007', 8, 11),\n",
       " ('0965-008', 10, 11),\n",
       " ('0958-035', 0, 1),\n",
       " ('0966-009', 6, 7),\n",
       " ('1155-003', 29, 30),\n",
       " ('0966-146', 1, 3),\n",
       " ('1052-002', 17, 18),\n",
       " ('1156-008', 11, 12),\n",
       " ('1141-007', 19, 23),\n",
       " ('1036-023', 0, 1),\n",
       " ('0967-005', 30, 31),\n",
       " ('1097-012', 27, 28),\n",
       " ('1129-001', 0, 1),\n",
       " ('0978-002', 18, 19),\n",
       " ('1046-002', 31, 32),\n",
       " ('0966-093', 0, 1),\n",
       " ('0966-065', 0, 1),\n",
       " ('0966-086', 0, 1),\n",
       " ('1098-002', 6, 7),\n",
       " ('1059-002', 2, 3),\n",
       " ('1066-066', 1, 8),\n",
       " ('1130-005', 51, 52),\n",
       " ('1116-011', 14, 15),\n",
       " ('1097-011', 0, 1),\n",
       " ('0966-037', 1, 3),\n",
       " ('0958-036', 5, 6),\n",
       " ('1076-044', 2, 3),\n",
       " ('1127-003', 20, 21),\n",
       " ('1156-000', 4, 5),\n",
       " ('1075-002', 18, 19),\n",
       " ('1005-008', 19, 20),\n",
       " ('0972-027', 1, 2),\n",
       " ('1096-034', 13, 14),\n",
       " ('1103-015', 8, 9),\n",
       " ('1065-020', 1, 8),\n",
       " ('1072-015', 36, 37),\n",
       " ('0952-004', 18, 19),\n",
       " ('1101-002', 13, 15),\n",
       " ('1149-005', 31, 33),\n",
       " ('0981-011', 8, 11),\n",
       " ('1096-032', 21, 22),\n",
       " ('1057-002', 20, 21),\n",
       " ('1097-020', 26, 27),\n",
       " ('1089-017', 0, 1),\n",
       " ('1036-002', 0, 1),\n",
       " ('1064-005', 12, 14),\n",
       " ('1143-005', 11, 12),\n",
       " ('1022-007', 3, 4),\n",
       " ('1153-006', 8, 10),\n",
       " ('0946-011', 16, 17),\n",
       " ('1069-011', 1, 2),\n",
       " ('1090-000', 11, 13),\n",
       " ('1128-006', 13, 18),\n",
       " ('1096-040', 10, 11),\n",
       " ('1097-003', 8, 10),\n",
       " ('1058-004', 15, 16),\n",
       " ('1064-004', 2, 4),\n",
       " ('1010-002', 0, 1),\n",
       " ('1031-014', 30, 31),\n",
       " ('1025-011', 7, 8),\n",
       " ('0998-001', 2, 3),\n",
       " ('0966-087', 0, 1),\n",
       " ('0957-004', 11, 12),\n",
       " ('0981-003', 38, 41),\n",
       " ('1049-003', 22, 23),\n",
       " ('0966-123', 6, 7),\n",
       " ('1066-025', 0, 1),\n",
       " ('1119-004', 14, 16),\n",
       " ('1058-016', 23, 27),\n",
       " ('1086-003', 12, 13),\n",
       " ('0963-003', 12, 14),\n",
       " ('0966-060', 6, 7),\n",
       " ('1059-002', 8, 9),\n",
       " ('1006-009', 27, 28),\n",
       " ('0969-003', 5, 6),\n",
       " ('1036-013', 6, 7),\n",
       " ('0955-001', 0, 2),\n",
       " ('1043-004', 42, 43),\n",
       " ('1133-003', 10, 12),\n",
       " ('1056-047', 9, 11),\n",
       " ('0966-084', 1, 3),\n",
       " ('0960-007', 26, 27),\n",
       " ('0969-003', 20, 21),\n",
       " ('1078-007', 4, 5),\n",
       " ('1072-003', 15, 18),\n",
       " ('1093-004', 17, 18),\n",
       " ('1020-004', 19, 21),\n",
       " ('1008-018', 4, 6),\n",
       " ('1096-001', 0, 1),\n",
       " ('1160-003', 2, 4),\n",
       " ('1039-019', 13, 15),\n",
       " ('1088-002', 38, 39),\n",
       " ('0966-139', 1, 3),\n",
       " ('0962-006', 0, 1),\n",
       " ('1060-017', 0, 1),\n",
       " ('1092-004', 8, 9),\n",
       " ('1058-013', 0, 2),\n",
       " ('0961-008', 7, 8),\n",
       " ('0957-000', 7, 8),\n",
       " ('1000-004', 0, 2),\n",
       " ('1140-005', 8, 9),\n",
       " ('1024-001', 0, 1),\n",
       " ('1064-001', 0, 1),\n",
       " ('1099-015', 2, 4),\n",
       " ('1062-002', 11, 13),\n",
       " ('1103-016', 20, 21),\n",
       " ('1058-003', 6, 8),\n",
       " ('0966-048', 6, 7),\n",
       " ('1025-003', 31, 33),\n",
       " ('1076-023', 4, 7),\n",
       " ('0957-033', 20, 21),\n",
       " ('0966-039', 0, 1),\n",
       " ('1035-010', 14, 23),\n",
       " ('0958-028', 0, 2),\n",
       " ('1009-015', 25, 27),\n",
       " ('0970-004', 5, 6),\n",
       " ('1000-005', 25, 26),\n",
       " ('1069-007', 0, 3),\n",
       " ('1137-000', 0, 2),\n",
       " ('1050-002', 5, 7),\n",
       " ('1106-001', 1, 2),\n",
       " ('1096-041', 1, 2),\n",
       " ('1096-034', 14, 15),\n",
       " ('1002-003', 10, 13),\n",
       " ('1088-002', 3, 7),\n",
       " ('1008-027', 23, 24),\n",
       " ('1060-017', 6, 7),\n",
       " ('1100-002', 1, 3),\n",
       " ('1096-005', 2, 3),\n",
       " ('1146-005', 35, 37),\n",
       " ('0975-012', 7, 8),\n",
       " ('0961-010', 0, 1),\n",
       " ('0972-027', 4, 5),\n",
       " ('1051-008', 16, 17),\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(spans(df_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you were able to see in Problem&nbsp;2, the span accuracy of the named entity recognizer is far from perfect. In particular, only slightly more than half of the predicted spans are correct according to the gold standard. Your next task is to analyse this result in more detail.\n",
    "\n",
    "Here is a function that prints the false positives as well as the false negatives spans for a data frame, given a reference set of gold-standard spans and a candidate set of predicted spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def error_report(df, spans_gold, spans_pred):\n",
    "    false_pos = defaultdict(list)\n",
    "    for s, b, e in spans_pred - spans_gold:\n",
    "        false_pos[s].append((b, e))\n",
    "    false_neg = defaultdict(list)\n",
    "    for s, b, e in spans_gold - spans_pred:\n",
    "        false_neg[s].append((b, e))\n",
    "    for row in df.drop_duplicates('sentence_id').itertuples():\n",
    "        if row.sentence_id in false_pos or row.sentence_id in false_neg:\n",
    "            print('Sentence:', row.sentence)\n",
    "            for b, e in false_pos[row.sentence_id]:\n",
    "                print('  FP:', ' '.join(row.sentence.split()[b:e]))\n",
    "            for b, e in false_neg[row.sentence_id]:\n",
    "                print('  FN:', ' '.join(row.sentence.split()[b:e]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to inspect and analyse the errors that the automated prediction makes. Can you see any patterns? Base your analysis on the first 500 rows of the training data. Summarize your observations in a short text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: BRUSSELS 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep .\n",
      "  FP: The European Commission\n",
      "  FP: Thursday\n",
      "  FN: European Commission\n",
      "Sentence: Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .\n",
      "  FP: Wednesday\n",
      "  FP: the European Union 's\n",
      "  FN: European Union\n",
      "Sentence: He said further scientific study was required and if it was found that action was needed it should be taken by the European Union .\n",
      "  FP: the European Union\n",
      "  FN: European Union\n",
      "Sentence: He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health .\n",
      "  FP: last month\n",
      "  FP: EU Farm\n",
      "  FN: EU\n",
      "Sentence: Fischler proposed EU-wide measures after reports from Britain and France that under laboratory conditions sheep could contract Bovine Spongiform Encephalopathy ( BSE ) -- mad cow disease .\n",
      "  FN: EU-wide\n",
      "Sentence: Spanish Farm Minister Loyola de Palacio had earlier accused Fischler at an EU farm ministers ' meeting of causing unjustified alarm through \" dangerous generalisation . \"\n",
      "  FP: Spanish Farm\n",
      "  FN: Spanish\n",
      "Sentence: The EU 's scientific veterinary and multidisciplinary committees are due to re-examine the issue early next month and make recommendations to the senior veterinary officials .\n",
      "  FP: early next month\n",
      "Sentence: British farmers denied on Thursday there was any danger to human health from their sheep , but expressed concern that German government advice to consumers to avoid British lamb might influence consumers across Europe .\n",
      "  FP: Thursday\n",
      "Sentence: \" What we have to be extremely careful of is how other countries are going to take Germany 's lead , \" Welsh National Farmers ' Union ( NFU ) chairman John Lloyd Jones said on BBC radio .\n",
      "  FP: BBC\n",
      "  FN: Welsh National Farmers ' Union\n",
      "  FN: BBC radio\n",
      "  FN: NFU\n",
      "Sentence: Bonn has led efforts to protect public health after consumer confidence collapsed in March after a British report suggested humans could contract an illness similar to mad cow disease by eating contaminated beef .\n",
      "  FP: March\n",
      "Sentence: Germany imported 47,600 sheep from Britain last year , nearly half of total imports .\n",
      "  FP: 47,600\n",
      "  FP: nearly half\n",
      "  FP: last year\n",
      "Sentence: It brought in 4,275 tonnes of British mutton , some 10 percent of overall imports .\n",
      "  FP: some 10 percent\n",
      "  FP: 4,275 tonnes\n",
      "Sentence: Rare Hendrix song draft sells for almost $ 17,000 .\n",
      "  FP: Rare Hendrix\n",
      "  FP: almost $ 17,000\n",
      "  FN: Hendrix\n",
      "Sentence: LONDON 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: A rare early handwritten draft of a song by U.S. guitar legend Jimi Hendrix was sold for almost $ 17,000 on Thursday at an auction of some of the late musician 's favourite possessions .\n",
      "  FP: Thursday\n",
      "  FP: almost $ 17,000\n",
      "Sentence: A Florida restaurant paid 10,925 pounds ( $ 16,935 ) for the draft of \" Ai n't no telling \" , which Hendrix penned on a piece of London hotel stationery in late 1966 .\n",
      "  FP: 10,925 pounds\n",
      "  FP: 16,935\n",
      "  FP: late 1966\n",
      "  FN: Ai n't no telling\n",
      "Sentence: At the end of a January 1967 concert in the English city of Nottingham he threw the sheet of paper into the audience , where it was retrieved by a fan .\n",
      "  FP: January 1967\n",
      "  FP: the end of a\n",
      "Sentence: Buyers also snapped up 16 other items that were put up for auction by Hendrix 's former girlfriend Kathy Etchingham , who lived with him from 1966 to 1969 .\n",
      "  FP: 1966\n",
      "  FP: 16\n",
      "Sentence: They included a black lacquer and mother of pearl inlaid box used by Hendrix to store his drugs , which an anonymous Australian purchaser bought for 5,060 pounds ( $ 7,845 ) .\n",
      "  FP: 5,060 pounds\n",
      "  FP: 7,845\n",
      "Sentence: BEIJING 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "  FN: BEIJING\n",
      "Sentence: China on Thursday accused Taipei of spoiling the atmosphere for a resumption of talks across the Taiwan Strait with a visit to Ukraine by Taiwanese Vice President Lien Chan this week that infuriated Beijing .\n",
      "  FP: the Taiwan Strait\n",
      "  FP: Thursday\n",
      "  FP: this week\n",
      "  FN: Taiwan Strait\n",
      "Sentence: Speaking only hours after Chinese state media said the time was right to engage in political talks with Taiwan , Foreign Ministry spokesman Shen Guofang told Reuters : \" The necessary atmosphere for the opening of the talks has been disrupted by the Taiwan authorities . \"\n",
      "  FP: only hours\n",
      "Sentence: State media quoted China 's top negotiator with Taipei , Tang Shubei , as telling a visiting group from Taiwan on Wednesday that it was time for the rivals to hold political talks .\n",
      "  FP: Wednesday\n",
      "Sentence: that is to end the state of hostility , \" Thursday 's overseas edition of the People 's Daily quoted Tang as saying .\n",
      "  FP: Thursday\n",
      "  FP: the People 's Daily\n",
      "  FN: People 's Daily\n",
      "Sentence: The foreign ministry 's Shen told Reuters Television in an interview he had read reports of Tang 's comments but gave no details of why the negotiator had considered the time right for talks with Taiwan , which Beijing considers a renegade province .\n",
      "  FN: Shen\n",
      "Sentence: China , which has long opposed all Taipei efforts to gain greater international recognition , was infuriated by a visit to Ukraine this week by Taiwanese Vice President Lien .\n",
      "  FP: this week\n",
      "Sentence: BEIJING 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "  FN: BEIJING\n",
      "Sentence: Consultations should be held to set the time and format of the talks , the official Xinhua news agency quoted Tang Shubei , executive vice chairman of the Association for Relations Across the Taiwan Straits , as saying late on Wednesday .\n",
      "  FP: Wednesday\n",
      "  FP: Xinhua news agency\n",
      "  FP: the Association for Relations Across\n",
      "  FP: the Taiwan Straits\n",
      "  FN: Association for Relations Across the Taiwan Straits\n",
      "  FN: Xinhua\n",
      "Sentence: German July car registrations up 14.2 pct yr / yr .\n",
      "  FP: German July\n",
      "  FP: 14.2\n",
      "  FN: German\n",
      "Sentence: FRANKFURT 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "  FN: FRANKFURT\n",
      "Sentence: German first-time registrations of motor vehicles jumped 14.2 percent in July this year from the year-earlier period , the Federal office for motor vehicles said on Thursday .\n",
      "  FP: July this year\n",
      "  FP: 14.2 percent\n",
      "  FP: Thursday\n",
      "  FN: Federal office for motor vehicles\n",
      "Sentence: Volkswagen AG won 77,719 registrations , slightly more than a quarter of the total .\n",
      "  FP: more than a quarter\n",
      "  FP: 77,719\n",
      "Sentence: Opel AG together with General Motors came in second place with 49,269 registrations , 16.4 percent of the overall figure .\n",
      "  FP: 16.4 percent\n",
      "  FP: 49,269\n",
      "  FP: second\n",
      "Sentence: Third was Ford with 35,563 registrations , or 11.7 percent .\n",
      "  FP: 11.7 percent\n",
      "  FP: Third\n",
      "  FP: 35,563\n",
      "Sentence: Only Seat and Porsche had fewer registrations in July 1996 compared to last year 's July .\n",
      "  FP: Only Seat and\n",
      "  FP: last year 's July\n",
      "  FP: July 1996\n",
      "  FN: Seat\n",
      "Sentence: Seat posted 3,420 registrations compared with 5522 registrations in July a year earlier .\n",
      "  FP: July a year earlier\n",
      "  FP: 5522\n",
      "  FP: 3,420\n",
      "  FN: Seat\n",
      "Sentence: Porsche 's registrations fell to 554 from 643 .\n",
      "  FP: 643\n",
      "  FP: 554\n",
      "Sentence: GREEK SOCIALISTS GIVE GREEN LIGHT TO PM FOR ELECTIONS .\n",
      "  FP: SOCIALISTS\n",
      "Sentence: ATHENS 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: Prime Minister Costas Simitis is going to make an official announcement after a cabinet meeting later on Thursday , said Skandalidis .\n",
      "  FP: Thursday\n",
      "Sentence: -- Dimitris Kontogiannis , Athens Newsroom +301 3311812-4\n",
      "  FP: 3311812-4\n",
      "  FN: Dimitris Kontogiannis\n",
      "Sentence: BayerVB sets C$ 100 million six-year bond .\n",
      "  FP: C$ 100 million\n",
      "  FN: C$\n",
      "  FN: BayerVB\n",
      "Sentence: LONDON 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: BORROWER BAYERISCHE VEREINSBANK\n",
      "  FP: BORROWER BAYERISCHE\n",
      "  FN: BAYERISCHE VEREINSBANK\n",
      "Sentence: AMT C$ 100 MLN COUPON 6.625 MATURITY 24.SEP.02\n",
      "  FP: 100\n",
      "  FN: C$\n",
      "Sentence: S&P = DENOMS ( K ) 1-10-100 SALE LIMITS US / UK / CA\n",
      "  FP: 1-10-100\n",
      "Sentence: GOV LAW GERMAN HOME CTRY = TAX PROVS STANDARD\n",
      "  FP: GOV LAW GERMAN HOME CTRY =\n",
      "  FN: GERMAN\n",
      "Sentence: NOTES BAYERISCHE VEREINSBANK IS JOINT LEAD MANAGER\n",
      "  FN: BAYERISCHE VEREINSBANK\n",
      "Sentence: -- London Newsroom +44 171 542 7658\n",
      "  FP: 171 542 7658\n",
      "Sentence: Venantius sets $ 300 million January 1999 FRN .\n",
      "  FP: $ 300 million\n",
      "  FP: January 1999\n",
      "  FN: Venantius\n",
      "Sentence: LONDON 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: BORROWER VENANTIUS AB ( SWEDISH NATIONAL MORTGAGE AGENCY )\n",
      "  FP: SWEDISH NATIONAL MORTGAGE AGENCY\n",
      "  FP: BORROWER VENANTIUS AB\n",
      "  FN: VENANTIUS AB\n",
      "  FN: SWEDISH\n",
      "Sentence: TYPE FRN BASE 3M LIBOR PAY DATE S23.SEP.96\n",
      "  FN: 3M\n",
      "Sentence: LISTING LONDON DENOMS ( K ) 1-10-100 SALE LIMITS US / UK / JP / FR\n",
      "  FP: 1-10-100\n",
      "  FN: JP\n",
      "  FN: FR\n",
      "Sentence: GOV LAW ENGLISH HOME CTRY SWEDEN TAX PROVS STANDARD\n",
      "  FP: GOV LAW ENGLISH HOME CTRY\n",
      "  FN: SWEDEN\n",
      "  FN: ENGLISH\n",
      "Sentence: -- London Newsroom +44 171 542 8863\n",
      "  FP: 8863\n",
      "  FP: 171\n",
      "Sentence: Port conditions update - Syria - Lloyds Shipping .\n",
      "  FP: Syria - Lloyds Shipping\n",
      "  FN: Lloyds Shipping\n",
      "  FN: Syria\n",
      "Sentence: LATTAKIA , Aug 10 - waiting time at Lattakia and Tartous presently 24 hours .\n",
      "  FP: 10\n",
      "  FP: 24 hours\n",
      "  FN: LATTAKIA\n",
      "Sentence: JERUSALEM 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: Israel 's outgoing peace negotiator with Syria said on Thursday current tensions between the two countries appeared to be a storm in a teacup .\n",
      "  FP: Thursday\n",
      "  FP: two\n",
      "Sentence: Rabinovich is winding up his term as ambassador .\n",
      "  FN: Rabinovich\n",
      "Sentence: Israel on Wednesday sent Syria a message , via Washington , saying it was committed to peace and wanted to open negotiations without preconditions .\n",
      "  FP: Wednesday\n",
      "Sentence: Syria accused Israel on Wednesday of launching a hysterical campaign against it after Israeli television reported that Damascus had recently test fired a missile .\n",
      "  FP: Wednesday\n",
      "Sentence: \" The message that we sent to ( Syrian President Hafez al- ) Assad is that Israel is ready at any time without preconditions to enter peace negotiations , \" Israeli Foreign Minister David Levy told Israel Radio in an interview .\n",
      "  FP: Hafez\n",
      "  FN: Hafez al-\n",
      "Sentence: Tension has mounted since Israeli Prime Minister Benjamin Netanyahu took office in June vowing to retain the Golan Heights Israel captured from Syria in the 1967 Middle East war .\n",
      "  FP: June\n",
      "  FP: the Golan Heights\n",
      "  FN: Golan Heights\n",
      "Sentence: Israeli-Syrian peace talks have been deadlocked over the Golan since 1991 despite the previous government 's willingness to make Golan concessions .\n",
      "  FP: 1991\n",
      "Sentence: We do not want a war , God forbid .\n",
      "  FN: God\n",
      "Sentence: The television also said that Netanyahu had sent messages to reassure Syria via Cairo , the United States and Moscow .\n",
      "  FP: the United States\n",
      "  FN: United States\n",
      "Sentence: TUNIS 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "  FN: TUNIS\n",
      "Sentence: A Polish diplomat on Thursday denied a Polish tabloid report this week that Libya was refusing exit visas to 100 Polish nurses trying to return home after working in the North African country .\n",
      "  FP: 100\n",
      "  FP: this week\n",
      "  FP: Thursday\n",
      "Sentence: Poland 's labour ministry said this week it would send a team to Libya to investigate , but Awdankiewicz said the probe was prompted by some nurses complaining about their work conditions such as non-payment of their salaries .\n",
      "  FP: this week\n",
      "  FP: labour ministry\n",
      "Sentence: He said that there are an estimated 800 Polish nurses working in Libya .\n",
      "  FP: an estimated 800\n",
      "Sentence: Two Iranian opposition leaders meet in Baghdad .\n",
      "  FP: Two\n",
      "Sentence: BAGHDAD 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: An Iranian exile group based in Iraq vowed on Thursday to extend support to Iran 's Kurdish rebels after they were attacked by Iranian troops deep inside Iraq last month .\n",
      "  FP: last month\n",
      "  FP: Thursday\n",
      "Sentence: A Mujahideen Khalq statement said its leader Massoud Rajavi met in Baghdad the Secretary-General of the Kurdistan Democratic Party of Iran ( KDPI ) Hassan Rastegar on Wednesday and voiced his support to Iran 's rebel Kurds .\n",
      "  FP: Wednesday\n",
      "  FP: the Kurdistan Democratic Party of Iran\n",
      "  FN: KDPI\n",
      "  FN: Kurdistan Democratic Party of Iran\n",
      "Sentence: \" Rajavi emphasised that the Iranian Resistance would continue to stand side by side with their Kurdish compatriots and the resistance movement in Iranian Kurdistan , \" it said .\n",
      "  FP: Iranian\n",
      "  FP: Kurdistan\n",
      "  FP: the Iranian Resistance\n",
      "  FN: Iranian\n",
      "  FN: Rajavi\n",
      "  FN: Resistance\n",
      "  FN: Iranian Kurdistan\n",
      "Sentence: A spokesman for the group said the meeting \" signals a new level of cooperation between Mujahideen Khalq and the Iranian Kurdish oppositions \" .\n",
      "  FP: Kurdish\n",
      "  FP: Iranian\n",
      "  FN: Iranian Kurdish\n",
      "Sentence: Iran heavily bombarded targets in northern Iraq in July in pursuit of KDPI guerrillas based in Iraqi Kurdish areas outside the control of the government in Baghdad .\n",
      "  FP: July\n",
      "  FP: Iraqi\n",
      "  FP: Kurdish\n",
      "  FN: Iraqi Kurdish\n",
      "Sentence: Iraqi Kurdish areas bordering Iran are under the control of guerrillas of the Iraqi Kurdish Patriotic Union of Kurdistan ( PUK ) group .\n",
      "  FP: Kurdish\n",
      "  FP: Iraqi\n",
      "  FP: Iraqi\n",
      "  FN: Iraqi Kurdish\n",
      "  FN: Iraqi Kurdish Patriotic Union of Kurdistan\n",
      "Sentence: PUK and Iraq 's Kurdistan Democratic Party ( KDP ) the two main Iraqi Kurdish factions , have had northern Iraq under their control since Iraqi forces were ousted from Kuwait in the 1991 Gulf War .\n",
      "  FP: 1991\n",
      "  FP: Iraqi\n",
      "  FP: Kurdish\n",
      "  FP: two\n",
      "  FN: Iraqi Kurdish\n",
      "Sentence: Clashes between the two parties broke out at the weekend in the most serious fighting since a U.S.-sponsored ceasefire last year .\n",
      "  FP: the weekend\n",
      "  FP: two\n",
      "  FP: last year\n",
      "  FN: U.S.-sponsored\n",
      "Sentence: Mujahideen Khalq said Iranian troops had also been shelling KDP positions in Qasri region in Suleimaniya province near the Iranian border over the last two days .\n",
      "  FP: the last two days\n",
      "  FP: Suleimaniya province\n",
      "  FN: Suleimaniya\n",
      "Sentence: It said about 100 Iraqi Kurds were killed or wounded in the attack .\n",
      "  FP: Iraqi\n",
      "  FP: Kurds\n",
      "  FP: about 100\n",
      "  FN: Iraqi Kurds\n",
      "Sentence: A U.S.-led air force in southern Turkey protects Iraqi Kurds from possible attacks by Baghdad troops .\n",
      "  FP: Iraqi\n",
      "  FP: Kurds\n",
      "  FN: Iraqi Kurds\n",
      "  FN: U.S.-led\n",
      "Sentence: Saudi riyal rates steady in quiet summer trade .\n",
      "  FP: summer\n",
      "Sentence: MANAMA 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "  FN: MANAMA\n",
      "Sentence: The spot Saudi riyal against the dollar and riyal interbank deposit rates were mainly steady this week in quiet summer trade , dealers in the kingdom said .\n",
      "  FP: this week\n",
      "  FP: summer\n",
      "Sentence: One-month interbank deposits were at 5-1/2 , 3/8 percent , three months were 5-5/8 , 1/2 percent and six months were 5-3/4 , 5/8 percent .\n",
      "  FP: six months\n",
      "  FP: 5-1/2\n",
      "  FP: 1/2 percent\n",
      "  FP: 5/8 percent\n",
      "  FP: 5-5/8\n",
      "  FP: 5-3/4\n",
      "  FP: three months\n",
      "  FN: One-month\n",
      "Sentence: One-year funds were at six , 5-7/8 percent .\n",
      "  FP: 5-7/8 percent\n",
      "  FP: six\n",
      "  FN: One-year\n",
      "Sentence: JERUSALEM 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: Israel gave Palestinian President Yasser Arafat permission on Thursday to fly over its territory to the West Bank , ending a brief Israeli-PLO crisis , an Arafat adviser said .\n",
      "  FP: Thursday\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "  FN: Israeli-PLO\n",
      "Sentence: The president 's aircraft has received permission to pass through Israeli airspace but the president is not expected to travel to the West Bank before Monday , \" Nabil Abu Rdainah told Reuters .\n",
      "  FP: the West Bank\n",
      "  FP: Monday\n",
      "  FN: West Bank\n",
      "Sentence: Arafat had been scheduled to meet former Israeli prime minister Shimon Peres in the West Bank town of Ramallah on Thursday but the venue was changed to Gaza after Israel denied flight clearance to the Palestinian leader 's helicopters .\n",
      "  FP: Thursday\n",
      "Sentence: Arafat subsequently cancelled a meeting between Israeli and PLO officials , on civilian affairs , at the Allenby Bridge crossing between Jordan and the West Bank .\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: Abu Rdainah said Arafat had decided against flying to the West Bank on Thursday , after Israel lifted the ban , because he had a busy schedule in Gaza and would not be free until Monday .\n",
      "  FP: Thursday\n",
      "  FP: Monday\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: JERUSALEM 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: Yasser Arafat will meet Shimon Peres in Gaza on Thursday after Palestinians said the right-wing Israeli government had barred the Palestinian leader from flying to the West Bank for talks with the former prime minister .\n",
      "  FP: Thursday\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: Palestinian officials said the Israeli government had barred Arafat from overflying Israel in a Palestinian helicopter to the West Bank in an attempt to bar the meeting with Peres .\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: Israeli Prime Minister Benjamin Netanyahu has accused opposition leader Peres , who he defeated in May elections , of trying to undermine his Likud government 's authority to conduct peace talks .\n",
      "  FP: May\n",
      "Sentence: Afghan UAE embassy says Taleban guards going home .\n",
      "  FN: UAE\n",
      "Sentence: DUBAI 1996-08-22\n",
      "  FP: DUBAI 1996-08-22\n",
      "  FN: DUBAI\n",
      "Sentence: Three Afghan guards brought to the United Arab Emirates last week by Russian hostages who escaped from the Taleban militia will return to Afghanistan in a few days , the Afghan embassy in Abu Dhabi said on Thursday .\n",
      "  FP: a few days\n",
      "  FP: the United Arab Emirates\n",
      "  FP: last week\n",
      "  FP: Three\n",
      "  FP: Thursday\n",
      "  FN: United Arab Emirates\n",
      "Sentence: \" Our ambassador is in touch with the UAE foreign ministry .\n",
      "  FN: UAE\n",
      "Sentence: Their return to Afghanistan will take place in two or three days , \" an embassy official said .\n",
      "  FP: two or three days\n",
      "Sentence: The three Islamic Taleban guards were overpowered by seven Russian aircrew who escaped to UAE state Sharjah last Friday on board their own aircraft after a year in the captivity of Taleban militia in Kandahar in southern Afghanistan .\n",
      "  FP: last Friday\n",
      "  FP: seven\n",
      "  FP: a year\n",
      "  FP: three\n",
      "  FP: Islamic\n",
      "  FN: UAE\n",
      "  FN: Islamic Taleban\n",
      "  FN: Sharjah\n",
      "Sentence: The UAE said on Monday it would hand over the three to the International Red Crescent , possibly last Tuesday .\n",
      "  FP: last Tuesday\n",
      "  FP: the International Red Crescent\n",
      "  FP: Monday\n",
      "  FP: three\n",
      "  FN: International Red Crescent\n",
      "Sentence: When asked whether the three guards would travel back to Kandahar or the Afghan capital Kabul , the embassy official said : \" That has not been decided , but possibly Kandahar . \"\n",
      "  FP: three\n",
      "Sentence: The embassy official said the three men , believed to be in their 20s , were currently in Abu Dhabi .\n",
      "  FP: three\n",
      "  FP: 20s\n",
      "Sentence: The Russians , working for the Aerostan firm in the Russian republic of Tatarstan , were taken hostage after a Taleban MiG-19 fighter forced their cargo plane to land in August 1995 .\n",
      "  FP: August 1995\n",
      "  FN: MiG-19\n",
      "Sentence: The Russians , who said they overpowered the guards -- two armed with Kalashnikov automatic rifles -- while doing regular maintenance work on their Ilyushin 76 cargo plane last Friday , left the UAE capital Abu Dhabi for home on Sunday .\n",
      "  FP: Sunday\n",
      "  FP: two\n",
      "  FP: last Friday\n",
      "Sentence: BAGHDAD 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: Iraqi President Saddam Hussein has told visiting Russian ultra-nationalist Vladimir Zhirinovsky that Baghdad wanted to maintain \" friendship and cooperation \" with Moscow , official Iraqi newspapers said on Thursday .\n",
      "  FP: Thursday\n",
      "Sentence: They said Zhirinovsky told Saddam before he left Baghdad on Wednesday that his Liberal Democratic party and the Russian Duma ( parliament ) \" are calling for an immediate lifting of the embargo \" imposed on Iraq after its 1990 invasion of Kuwait .\n",
      "  FP: the Russian Duma\n",
      "  FP: Wednesday\n",
      "  FP: 1990\n",
      "  FN: Duma\n",
      "  FN: Russian\n",
      "Sentence: Zhirinovsky said on Tuesday he would press the Russian government to help end U.N. trade sanctions on Iraq and blamed Moscow for delaying establishment of good ties with Baghdad .\n",
      "  FP: Tuesday\n",
      "Sentence: Zhirinovsky visited Iraq twice in 1995 .\n",
      "  FP: 1995\n",
      "Sentence: Last October he was invited to attend the referendum held on Iraq 's presidency , which extended Saddam 's term for seven more years .\n",
      "  FP: Last October\n",
      "  FP: seven more years\n",
      "Sentence: PRESS DIGEST - Iraq - Aug 22 .\n",
      "  FP: 22\n",
      "  FN: Iraq\n",
      "Sentence: BAGHDAD 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "Sentence: These are some of the leading stories in the official Iraqi press on Thursday .\n",
      "  FP: Thursday\n",
      "Sentence: - Turkish foreign minister says Turkey will take part in the Baghdad trade fair that will be held in November .\n",
      "  FP: November\n",
      "Sentence: - A shipload of 12 tonnes of rice arrives in Umm Qasr port in the Gulf .\n",
      "  FP: 12\n",
      "Sentence: PRESS DIGEST - Lebanon - Aug 22 .\n",
      "  FP: 22\n",
      "Sentence: BEIRUT 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "  FN: BEIRUT\n",
      "Sentence: These are the leading stories in the Beirut press on Thursday .\n",
      "  FP: Thursday\n",
      "Sentence: AS-SAFIR\n",
      "  FN: AS-SAFIR\n",
      "Sentence: AL-ANWAR\n",
      "  FN: AL-ANWAR\n",
      "Sentence: - Continued criticism of law violation incidents -- which occurred in the Mount Lebanon elections last Sunday .\n",
      "  FP: last Sunday\n",
      "Sentence: - Hariri to step into the election battle with an incomplete list .\n",
      "  FN: Hariri\n",
      "Sentence: NIDA'A AL-WATAN\n",
      "  FN: NIDA'A AL-WATAN\n",
      "Sentence: - Maronite Patriarch Sfeir expressed sorrow over the violations in Sunday ' elections .\n",
      "  FP: Sunday\n",
      "  FN: Maronite\n",
      "Sentence: CHICAGO 1996-08-22\n",
      "  FP: 1996-08-22\n",
      "  FN: CHICAGO\n",
      "Sentence: Early calls on CME live and feeder cattle futures ranged from 0.200 cent higher to 0.100 lower , livestock analysts said .\n",
      "  FP: 0.100\n",
      "  FP: 0.200 cent\n",
      "Sentence: MONTGOMERY , Ala .\n",
      "  FN: MONTGOMERY\n",
      "  FN: Ala\n",
      "Sentence: KinderCare Learning Centers Inc said on Thursday that a debt buyback would mean an extraordinary loss of $ 1.2 million in its fiscal 1997 first quarter .\n",
      "  FP: Thursday\n",
      "  FP: fiscal 1997 first quarter\n",
      "  FP: $ 1.2 million\n",
      "Sentence: RESEARCH ALERT - Lehman starts SNET .\n",
      "  FP: RESEARCH ALERT - Lehman\n",
      "  FN: Lehman\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write code here to do your analysis\n",
    "error_report(df_train[:500], \n",
    "             set(gold_spans(df_train[:500])),\n",
    "             set(spans(df_train[:500])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 65.22%, Recall: 81.0%, F1 score: 72.26%\n"
     ]
    }
   ],
   "source": [
    "evaluation_report(set(gold_spans(df_train[:500])),\n",
    "                  set(spans(df_train[:500])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Most errors were observed with DATES & NUMBERS. Preprocessing these out gave us an improvement of about 10% in the precision. The next biggest error label we removed was MONEY and PERCENT, which gave us a further 12% improvement in precision. Finally, we saw a lot of errors due to nationality, which we tried to correct by preprocessing NORP & LOC, but it didnt yield any improvement in the precision and also didn't seem to remove the nationality related errors. So, we skipped that preprocessing step. In the end to achieve a minor improvement and get $\\sim$15% improvement in F1 score vs problem 2 we also preprocessed QUANTITY.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the insights from your error analysis to improve the automated prediction that you implemented in Problem&nbsp;2. While the best way to do this would be to [update spaCy&rsquo;s NER model](https://spacy.io/usage/linguistic-features#updating) using domain-specific training data, for this lab it suffices to write code to post-process the output produced by spaCy. To filter out specific labels it is useful to know the named entity label scheme, which can be found in the [model's documentation](https://spacy.io/models/en#en_core_web_sm). You should be able to improve the F1 score from Problem&nbsp;2 by at last 15 percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep .\n",
      "  FP: The European Commission\n",
      "  FN: European Commission\n",
      "Sentence: Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .\n",
      "  FP: the European Union 's\n",
      "  FN: European Union\n",
      "Sentence: He said further scientific study was required and if it was found that action was needed it should be taken by the European Union .\n",
      "  FP: the European Union\n",
      "  FN: European Union\n",
      "Sentence: He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health .\n",
      "  FP: EU Farm\n",
      "  FN: EU\n",
      "Sentence: Fischler proposed EU-wide measures after reports from Britain and France that under laboratory conditions sheep could contract Bovine Spongiform Encephalopathy ( BSE ) -- mad cow disease .\n",
      "  FN: EU-wide\n",
      "Sentence: Spanish Farm Minister Loyola de Palacio had earlier accused Fischler at an EU farm ministers ' meeting of causing unjustified alarm through \" dangerous generalisation . \"\n",
      "  FP: Spanish Farm\n",
      "  FN: Spanish\n",
      "Sentence: \" What we have to be extremely careful of is how other countries are going to take Germany 's lead , \" Welsh National Farmers ' Union ( NFU ) chairman John Lloyd Jones said on BBC radio .\n",
      "  FP: BBC\n",
      "  FN: Welsh National Farmers ' Union\n",
      "  FN: BBC radio\n",
      "  FN: NFU\n",
      "Sentence: Rare Hendrix song draft sells for almost $ 17,000 .\n",
      "  FP: Rare Hendrix\n",
      "  FN: Hendrix\n",
      "Sentence: A Florida restaurant paid 10,925 pounds ( $ 16,935 ) for the draft of \" Ai n't no telling \" , which Hendrix penned on a piece of London hotel stationery in late 1966 .\n",
      "  FN: Ai n't no telling\n",
      "Sentence: BEIJING 1996-08-22\n",
      "  FN: BEIJING\n",
      "Sentence: China on Thursday accused Taipei of spoiling the atmosphere for a resumption of talks across the Taiwan Strait with a visit to Ukraine by Taiwanese Vice President Lien Chan this week that infuriated Beijing .\n",
      "  FP: the Taiwan Strait\n",
      "  FN: Taiwan Strait\n",
      "Sentence: Speaking only hours after Chinese state media said the time was right to engage in political talks with Taiwan , Foreign Ministry spokesman Shen Guofang told Reuters : \" The necessary atmosphere for the opening of the talks has been disrupted by the Taiwan authorities . \"\n",
      "  FP: only hours\n",
      "Sentence: that is to end the state of hostility , \" Thursday 's overseas edition of the People 's Daily quoted Tang as saying .\n",
      "  FP: the People 's Daily\n",
      "  FN: People 's Daily\n",
      "Sentence: The foreign ministry 's Shen told Reuters Television in an interview he had read reports of Tang 's comments but gave no details of why the negotiator had considered the time right for talks with Taiwan , which Beijing considers a renegade province .\n",
      "  FN: Shen\n",
      "Sentence: BEIJING 1996-08-22\n",
      "  FN: BEIJING\n",
      "Sentence: Consultations should be held to set the time and format of the talks , the official Xinhua news agency quoted Tang Shubei , executive vice chairman of the Association for Relations Across the Taiwan Straits , as saying late on Wednesday .\n",
      "  FP: the Association for Relations Across\n",
      "  FP: Xinhua news agency\n",
      "  FP: the Taiwan Straits\n",
      "  FN: Association for Relations Across the Taiwan Straits\n",
      "  FN: Xinhua\n",
      "Sentence: German July car registrations up 14.2 pct yr / yr .\n",
      "  FN: German\n",
      "Sentence: FRANKFURT 1996-08-22\n",
      "  FN: FRANKFURT\n",
      "Sentence: German first-time registrations of motor vehicles jumped 14.2 percent in July this year from the year-earlier period , the Federal office for motor vehicles said on Thursday .\n",
      "  FN: Federal office for motor vehicles\n",
      "Sentence: Opel AG together with General Motors came in second place with 49,269 registrations , 16.4 percent of the overall figure .\n",
      "  FP: second\n",
      "Sentence: Third was Ford with 35,563 registrations , or 11.7 percent .\n",
      "  FP: Third\n",
      "Sentence: Only Seat and Porsche had fewer registrations in July 1996 compared to last year 's July .\n",
      "  FP: Only Seat and\n",
      "  FN: Seat\n",
      "Sentence: Seat posted 3,420 registrations compared with 5522 registrations in July a year earlier .\n",
      "  FN: Seat\n",
      "Sentence: GREEK SOCIALISTS GIVE GREEN LIGHT TO PM FOR ELECTIONS .\n",
      "  FP: SOCIALISTS\n",
      "Sentence: -- Dimitris Kontogiannis , Athens Newsroom +301 3311812-4\n",
      "  FN: Dimitris Kontogiannis\n",
      "Sentence: BayerVB sets C$ 100 million six-year bond .\n",
      "  FN: C$\n",
      "  FN: BayerVB\n",
      "Sentence: BORROWER BAYERISCHE VEREINSBANK\n",
      "  FP: BORROWER BAYERISCHE\n",
      "  FN: BAYERISCHE VEREINSBANK\n",
      "Sentence: AMT C$ 100 MLN COUPON 6.625 MATURITY 24.SEP.02\n",
      "  FN: C$\n",
      "Sentence: GOV LAW GERMAN HOME CTRY = TAX PROVS STANDARD\n",
      "  FP: GOV LAW GERMAN HOME CTRY =\n",
      "  FN: GERMAN\n",
      "Sentence: NOTES BAYERISCHE VEREINSBANK IS JOINT LEAD MANAGER\n",
      "  FN: BAYERISCHE VEREINSBANK\n",
      "Sentence: Venantius sets $ 300 million January 1999 FRN .\n",
      "  FN: Venantius\n",
      "Sentence: BORROWER VENANTIUS AB ( SWEDISH NATIONAL MORTGAGE AGENCY )\n",
      "  FP: SWEDISH NATIONAL MORTGAGE AGENCY\n",
      "  FP: BORROWER VENANTIUS AB\n",
      "  FN: VENANTIUS AB\n",
      "  FN: SWEDISH\n",
      "Sentence: TYPE FRN BASE 3M LIBOR PAY DATE S23.SEP.96\n",
      "  FN: 3M\n",
      "Sentence: LISTING LONDON DENOMS ( K ) 1-10-100 SALE LIMITS US / UK / JP / FR\n",
      "  FN: JP\n",
      "  FN: FR\n",
      "Sentence: GOV LAW ENGLISH HOME CTRY SWEDEN TAX PROVS STANDARD\n",
      "  FP: GOV LAW ENGLISH HOME CTRY\n",
      "  FN: SWEDEN\n",
      "  FN: ENGLISH\n",
      "Sentence: Port conditions update - Syria - Lloyds Shipping .\n",
      "  FP: Syria - Lloyds Shipping\n",
      "  FN: Lloyds Shipping\n",
      "  FN: Syria\n",
      "Sentence: LATTAKIA , Aug 10 - waiting time at Lattakia and Tartous presently 24 hours .\n",
      "  FP: 24 hours\n",
      "  FN: LATTAKIA\n",
      "Sentence: Rabinovich is winding up his term as ambassador .\n",
      "  FN: Rabinovich\n",
      "Sentence: \" The message that we sent to ( Syrian President Hafez al- ) Assad is that Israel is ready at any time without preconditions to enter peace negotiations , \" Israeli Foreign Minister David Levy told Israel Radio in an interview .\n",
      "  FP: Hafez\n",
      "  FN: Hafez al-\n",
      "Sentence: Tension has mounted since Israeli Prime Minister Benjamin Netanyahu took office in June vowing to retain the Golan Heights Israel captured from Syria in the 1967 Middle East war .\n",
      "  FP: the Golan Heights\n",
      "  FN: Golan Heights\n",
      "Sentence: We do not want a war , God forbid .\n",
      "  FN: God\n",
      "Sentence: The television also said that Netanyahu had sent messages to reassure Syria via Cairo , the United States and Moscow .\n",
      "  FP: the United States\n",
      "  FN: United States\n",
      "Sentence: TUNIS 1996-08-22\n",
      "  FN: TUNIS\n",
      "Sentence: Poland 's labour ministry said this week it would send a team to Libya to investigate , but Awdankiewicz said the probe was prompted by some nurses complaining about their work conditions such as non-payment of their salaries .\n",
      "  FP: labour ministry\n",
      "Sentence: A Mujahideen Khalq statement said its leader Massoud Rajavi met in Baghdad the Secretary-General of the Kurdistan Democratic Party of Iran ( KDPI ) Hassan Rastegar on Wednesday and voiced his support to Iran 's rebel Kurds .\n",
      "  FP: the Kurdistan Democratic Party of Iran\n",
      "  FN: KDPI\n",
      "  FN: Kurdistan Democratic Party of Iran\n",
      "Sentence: \" Rajavi emphasised that the Iranian Resistance would continue to stand side by side with their Kurdish compatriots and the resistance movement in Iranian Kurdistan , \" it said .\n",
      "  FP: Kurdistan\n",
      "  FP: the Iranian Resistance\n",
      "  FP: Iranian\n",
      "  FN: Iranian\n",
      "  FN: Rajavi\n",
      "  FN: Resistance\n",
      "  FN: Iranian Kurdistan\n",
      "Sentence: A spokesman for the group said the meeting \" signals a new level of cooperation between Mujahideen Khalq and the Iranian Kurdish oppositions \" .\n",
      "  FP: Kurdish\n",
      "  FP: Iranian\n",
      "  FN: Iranian Kurdish\n",
      "Sentence: Iran heavily bombarded targets in northern Iraq in July in pursuit of KDPI guerrillas based in Iraqi Kurdish areas outside the control of the government in Baghdad .\n",
      "  FP: Kurdish\n",
      "  FP: Iraqi\n",
      "  FN: Iraqi Kurdish\n",
      "Sentence: Iraqi Kurdish areas bordering Iran are under the control of guerrillas of the Iraqi Kurdish Patriotic Union of Kurdistan ( PUK ) group .\n",
      "  FP: Iraqi\n",
      "  FP: Iraqi\n",
      "  FP: Kurdish\n",
      "  FN: Iraqi Kurdish\n",
      "  FN: Iraqi Kurdish Patriotic Union of Kurdistan\n",
      "Sentence: PUK and Iraq 's Kurdistan Democratic Party ( KDP ) the two main Iraqi Kurdish factions , have had northern Iraq under their control since Iraqi forces were ousted from Kuwait in the 1991 Gulf War .\n",
      "  FP: Iraqi\n",
      "  FP: Kurdish\n",
      "  FN: Iraqi Kurdish\n",
      "Sentence: Clashes between the two parties broke out at the weekend in the most serious fighting since a U.S.-sponsored ceasefire last year .\n",
      "  FN: U.S.-sponsored\n",
      "Sentence: Mujahideen Khalq said Iranian troops had also been shelling KDP positions in Qasri region in Suleimaniya province near the Iranian border over the last two days .\n",
      "  FP: Suleimaniya province\n",
      "  FN: Suleimaniya\n",
      "Sentence: It said about 100 Iraqi Kurds were killed or wounded in the attack .\n",
      "  FP: Iraqi\n",
      "  FP: Kurds\n",
      "  FN: Iraqi Kurds\n",
      "Sentence: A U.S.-led air force in southern Turkey protects Iraqi Kurds from possible attacks by Baghdad troops .\n",
      "  FP: Kurds\n",
      "  FP: Iraqi\n",
      "  FN: Iraqi Kurds\n",
      "  FN: U.S.-led\n",
      "Sentence: MANAMA 1996-08-22\n",
      "  FN: MANAMA\n",
      "Sentence: One-month interbank deposits were at 5-1/2 , 3/8 percent , three months were 5-5/8 , 1/2 percent and six months were 5-3/4 , 5/8 percent .\n",
      "  FN: One-month\n",
      "Sentence: One-year funds were at six , 5-7/8 percent .\n",
      "  FN: One-year\n",
      "Sentence: Israel gave Palestinian President Yasser Arafat permission on Thursday to fly over its territory to the West Bank , ending a brief Israeli-PLO crisis , an Arafat adviser said .\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "  FN: Israeli-PLO\n",
      "Sentence: The president 's aircraft has received permission to pass through Israeli airspace but the president is not expected to travel to the West Bank before Monday , \" Nabil Abu Rdainah told Reuters .\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: Arafat subsequently cancelled a meeting between Israeli and PLO officials , on civilian affairs , at the Allenby Bridge crossing between Jordan and the West Bank .\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: Abu Rdainah said Arafat had decided against flying to the West Bank on Thursday , after Israel lifted the ban , because he had a busy schedule in Gaza and would not be free until Monday .\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: Yasser Arafat will meet Shimon Peres in Gaza on Thursday after Palestinians said the right-wing Israeli government had barred the Palestinian leader from flying to the West Bank for talks with the former prime minister .\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: Palestinian officials said the Israeli government had barred Arafat from overflying Israel in a Palestinian helicopter to the West Bank in an attempt to bar the meeting with Peres .\n",
      "  FP: the West Bank\n",
      "  FN: West Bank\n",
      "Sentence: Afghan UAE embassy says Taleban guards going home .\n",
      "  FN: UAE\n",
      "Sentence: DUBAI 1996-08-22\n",
      "  FP: DUBAI 1996-08-22\n",
      "  FN: DUBAI\n",
      "Sentence: Three Afghan guards brought to the United Arab Emirates last week by Russian hostages who escaped from the Taleban militia will return to Afghanistan in a few days , the Afghan embassy in Abu Dhabi said on Thursday .\n",
      "  FP: the United Arab Emirates\n",
      "  FN: United Arab Emirates\n",
      "Sentence: \" Our ambassador is in touch with the UAE foreign ministry .\n",
      "  FN: UAE\n",
      "Sentence: The three Islamic Taleban guards were overpowered by seven Russian aircrew who escaped to UAE state Sharjah last Friday on board their own aircraft after a year in the captivity of Taleban militia in Kandahar in southern Afghanistan .\n",
      "  FP: Islamic\n",
      "  FN: UAE\n",
      "  FN: Islamic Taleban\n",
      "  FN: Sharjah\n",
      "Sentence: The UAE said on Monday it would hand over the three to the International Red Crescent , possibly last Tuesday .\n",
      "  FP: the International Red Crescent\n",
      "  FN: International Red Crescent\n",
      "Sentence: The Russians , working for the Aerostan firm in the Russian republic of Tatarstan , were taken hostage after a Taleban MiG-19 fighter forced their cargo plane to land in August 1995 .\n",
      "  FN: MiG-19\n",
      "Sentence: They said Zhirinovsky told Saddam before he left Baghdad on Wednesday that his Liberal Democratic party and the Russian Duma ( parliament ) \" are calling for an immediate lifting of the embargo \" imposed on Iraq after its 1990 invasion of Kuwait .\n",
      "  FP: the Russian Duma\n",
      "  FN: Duma\n",
      "  FN: Russian\n",
      "Sentence: PRESS DIGEST - Iraq - Aug 22 .\n",
      "  FN: Iraq\n",
      "Sentence: BEIRUT 1996-08-22\n",
      "  FN: BEIRUT\n",
      "Sentence: AS-SAFIR\n",
      "  FN: AS-SAFIR\n",
      "Sentence: AL-ANWAR\n",
      "  FN: AL-ANWAR\n",
      "Sentence: - Hariri to step into the election battle with an incomplete list .\n",
      "  FN: Hariri\n",
      "Sentence: NIDA'A AL-WATAN\n",
      "  FN: NIDA'A AL-WATAN\n",
      "Sentence: - Maronite Patriarch Sfeir expressed sorrow over the violations in Sunday ' elections .\n",
      "  FN: Maronite\n",
      "Sentence: CHICAGO 1996-08-22\n",
      "  FN: CHICAGO\n",
      "Sentence: MONTGOMERY , Ala .\n",
      "  FN: MONTGOMERY\n",
      "  FN: Ala\n",
      "Sentence: RESEARCH ALERT - Lehman starts SNET .\n",
      "  FP: RESEARCH ALERT - Lehman\n",
      "  FN: Lehman\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write code here to improve the span prediction from Problem 2\n",
    "def spans_improved(df):\n",
    "    for row_id in df.sentence_id.unique():\n",
    "        sent_doc = nlp(df.sentence[df.sentence_id == row_id].values[0])\n",
    "        for entity in sent_doc.ents:\n",
    "            if entity.label_ not in ['DATE', 'CARDINAL', 'MONEY', 'PERCENT', 'QUANTITY']:\n",
    "                yield (row_id, entity.start, entity.end)\n",
    "            \n",
    "error_report(df_train[:500], \n",
    "             set(gold_spans(df_train[:500])),\n",
    "             set(spans_improved(df_train[:500])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe(\"ner\").labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"first\", \"second\", etc.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('ORDINAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that you achieve the performance goal by reporting the evaluation measures that you implemented in Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 87.47%, Recall: 81.0%, F1 score: 84.11%\n"
     ]
    }
   ],
   "source": [
    "evaluation_report(set(gold_spans(df_train[:500])),\n",
    "                  set(spans_improved(df_train[:500])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 79.79%, Recall: 70.14%, F1 score: 74.65%\n"
     ]
    }
   ],
   "source": [
    "evaluation_report(spans_dev_gold, set(spans_improved(df_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going on, we ask you to store the outputs of the improved named entity recognizer on the development data in a new data frame. This new frame should have the same layout as the original data frame for the development data that you loaded above, but should contain the *predicted* start and end positions for each token span, rather than the gold positions. As the `label` of each span, you can use the special value `--NME--`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code here to store the predicted spans in a new data frame\n",
    "\n",
    "NER_dev = set(spans_improved(df_dev))\n",
    "\n",
    "df_dev_NER = pd.DataFrame(NER_dev, columns = ['sentence_id', 'beg', 'end'])\n",
    "df_dev_NER.sort_values(by=['sentence_id','beg']).reset_index(drop=True)\n",
    "df_dev_sent = df_dev[['sentence_id','sentence']].drop_duplicates()\n",
    "df_dev_NER = pd.merge(df_dev_sent, df_dev_NER, on = 'sentence_id', how = 'inner')\n",
    "df_dev_NER['label'] = '--NME--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0946-001</td>\n",
       "      <td>LONDON 1996-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>1161-007</td>\n",
       "      <td>Brokers said blue chips like IDLC , Bangladesh...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>1161-007</td>\n",
       "      <td>Brokers said blue chips like IDLC , Bangladesh...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>1161-007</td>\n",
       "      <td>Brokers said blue chips like IDLC , Bangladesh...</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>1161-009</td>\n",
       "      <td>The DSE all share price index closed 2.73 poin...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>1161-010</td>\n",
       "      <td>-- Dhaka Newsroom 880-2-506363</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5201 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id                                           sentence  beg  end  \\\n",
       "0       0946-001                                  LONDON 1996-08-30    0    1   \n",
       "1       0946-002  West Indian all-rounder Phil Simmons took four...    0    2   \n",
       "2       0946-002  West Indian all-rounder Phil Simmons took four...   14   15   \n",
       "3       0946-002  West Indian all-rounder Phil Simmons took four...    3    5   \n",
       "4       0946-002  West Indian all-rounder Phil Simmons took four...   12   13   \n",
       "...          ...                                                ...  ...  ...   \n",
       "5196    1161-007  Brokers said blue chips like IDLC , Bangladesh...   10   12   \n",
       "5197    1161-007  Brokers said blue chips like IDLC , Bangladesh...    7    9   \n",
       "5198    1161-007  Brokers said blue chips like IDLC , Bangladesh...   13   15   \n",
       "5199    1161-009  The DSE all share price index closed 2.73 poin...    1    2   \n",
       "5200    1161-010                     -- Dhaka Newsroom 880-2-506363    1    3   \n",
       "\n",
       "        label  \n",
       "0     --NME--  \n",
       "1     --NME--  \n",
       "2     --NME--  \n",
       "3     --NME--  \n",
       "4     --NME--  \n",
       "...       ...  \n",
       "5196  --NME--  \n",
       "5197  --NME--  \n",
       "5198  --NME--  \n",
       "5199  --NME--  \n",
       "5200  --NME--  \n",
       "\n",
       "[5201 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Entity linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a method for predicting mention spans, we turn to the task of **entity linking**, which amounts to predicting the knowledge base entity that is referenced by a given mention. In our case, for each span we want to predict the Wikipedia page that this mention references.\n",
    "\n",
    "Start by extending the generator function that you implemented in Problem&nbsp;2 to labelled spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_mentions(df):\n",
    "    \"\"\"Yield the gold-standard mentions in a data frame.\n",
    "\n",
    "    Args:\n",
    "        df: A data frame.\n",
    "\n",
    "    Yields:\n",
    "        The gold-standard mention spans in the specified data frame as\n",
    "        quadruples consisting of the sentence id, start position, end\n",
    "        position and entity label of each span.\n",
    "    \"\"\"\n",
    "    # TODO: Replace the next line with your own code\n",
    "    for rows in df.itertuples():\n",
    "        yield (rows.sentence_id, rows.beg, rows.end, rows.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive baseline for entity linking on our data set is to link each mention span to the Wikipedia page name that we get when we join the tokens in the span by underscores, as is standard in Wikipedia page names. Suppose, for example, that a span contains the two tokens\n",
    "\n",
    "    Jimi Hendrix\n",
    "\n",
    "The baseline Wikipedia page name for this span would be\n",
    "\n",
    "    Jimi_Hendrix\n",
    "\n",
    "Implement this naive baseline and evaluate its performance. Print the evaluation measures that you implemented in Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here and in the remainder of this lab, you should base your entity predictions on the predicted spans that you computed in Problem&nbsp;3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code here to implement the baseline\n",
    "\n",
    "df_dev_NBL = df_dev_NER.copy()\n",
    "labels = []\n",
    "for rows in df_dev_NBL.itertuples():\n",
    "    labels.append(\"_\".join(rows.sentence.split()[rows.beg:rows.end]))\n",
    "df_dev_NBL.label = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0946-001</td>\n",
       "      <td>LONDON 1996-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>LONDON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>West_Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Phil_Simmons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Leicestershire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                           sentence  beg  end  \\\n",
       "0    0946-001                                  LONDON 1996-08-30    0    1   \n",
       "1    0946-002  West Indian all-rounder Phil Simmons took four...    0    2   \n",
       "2    0946-002  West Indian all-rounder Phil Simmons took four...   14   15   \n",
       "3    0946-002  West Indian all-rounder Phil Simmons took four...    3    5   \n",
       "4    0946-002  West Indian all-rounder Phil Simmons took four...   12   13   \n",
       "\n",
       "            label  \n",
       "0          LONDON  \n",
       "1     West_Indian  \n",
       "2        Somerset  \n",
       "3    Phil_Simmons  \n",
       "4  Leicestershire  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_NBL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 29.57%, Recall: 25.99%, F1 score: 27.67%\n"
     ]
    }
   ],
   "source": [
    "evaluation_report(set(gold_mentions(df_dev)),\n",
    "                  set(gold_mentions(df_dev_NBL)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Extending the training data using the knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State-of-the-art approaches to entity linking exploit information in knowledge bases. In our case, where Wikipedia is the knowledge base, one particularly useful type of information are links to other Wikipedia pages. In particular, we can interpret the anchor texts (the highlighted texts that you click on) as mentions of the entities (pages) that they link to. This allows us to harvest long lists of mention–entity pairings.\n",
    "\n",
    "The following cell loads a data frame summarizing anchor texts and page references harvested from the first paragraphs of the English Wikipedia. The data frame also contains all entity mentions in the training data (but not the development or the test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open('kb.tsv.bz2', 'rt', encoding = 'utf8') as source:\n",
    "    df_kb = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what information is available in this data, the following cell shows the entry for the anchor text `Sweden`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>entity</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17436</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>0.985768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden_national_football_team</td>\n",
       "      <td>0.014173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17438</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden_men's_national_ice_hockey_team</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mention                                 entity      prob\n",
       "17436  Sweden                                 Sweden  0.985768\n",
       "17437  Sweden          Sweden_national_football_team  0.014173\n",
       "17438  Sweden  Sweden_men's_national_ice_hockey_team  0.000059"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kb.loc[df_kb.mention == 'Sweden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each row of the data frame contains a pair $(m, e)$ of a mention $m$ and an entity $e$, as well as the conditional probability $P(e|m)$ for mention $m$ referring to entity $e$. These probabilities were estimated based on the frequencies of mention–entity pairs in the knowledge base. The example shows that the anchor text &lsquo;Sweden&rsquo; is most often used to refer to the entity [Sweden](http://en.wikipedia.org/wiki/Sweden), but in a few cases also to refer to Sweden&rsquo;s national football and ice hockey teams. Note that references are sorted in decreasing order of probability, so that the most probable pairing come first.\n",
    "\n",
    "Implement an entity linking method that resolves each mention to the most probable entity in the data frame. If the mention is not included in the data frame, you can predict the generic label `--NME--`. Print the precision, recall, and F1 of your method using the function that you implemented for Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 61.18%, Recall: 53.78%, F1 score: 57.24%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write code here to implement the \"most probable entity\" method.\n",
    "\n",
    "def MPE(df, entity):\n",
    "    mentions = df.loc[df.mention == entity]\n",
    "    if len(mentions) > 0:\n",
    "        return mentions.entity.values[0]\n",
    "    else:\n",
    "        return '--NME--'\n",
    "    \n",
    "df_dev_KB = df_dev_NER.copy()\n",
    "#entity = [\"_\".join(rows.sentence.split()[rows.beg:rows.end]) for rows in df_dev_KB.itertuples()]\n",
    "entity = [\" \".join(rows.sentence.split()[rows.beg:rows.end]) for rows in df_dev_KB.itertuples()]\n",
    "KB_entity = [MPE(df_kb, e) for e in entity]\n",
    "df_dev_KB.label = KB_entity\n",
    "\n",
    "evaluation_report(set(gold_mentions(df_dev)),\n",
    "                  set(gold_mentions(df_dev_KB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0946-001</td>\n",
       "      <td>LONDON 1996-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>West_Indies_cricket_team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>Somerset_County_Cricket_Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Phil_Simmons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Leicestershire_County_Cricket_Club</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                           sentence  beg  end  \\\n",
       "0    0946-001                                  LONDON 1996-08-30    0    1   \n",
       "1    0946-002  West Indian all-rounder Phil Simmons took four...    0    2   \n",
       "2    0946-002  West Indian all-rounder Phil Simmons took four...   14   15   \n",
       "3    0946-002  West Indian all-rounder Phil Simmons took four...    3    5   \n",
       "4    0946-002  West Indian all-rounder Phil Simmons took four...   12   13   \n",
       "\n",
       "                                label  \n",
       "0                              London  \n",
       "1            West_Indies_cricket_team  \n",
       "2        Somerset_County_Cricket_Club  \n",
       "3                        Phil_Simmons  \n",
       "4  Leicestershire_County_Cricket_Club  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_KB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Context-sensitive disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the entity mention &lsquo;Lincoln&rsquo;. The most probable entity for this mention turns out to be [Lincoln, Nebraska](http://en.wikipedia.org/Lincoln,_Nebraska); but in pages about American history, we would be better off to predict [Abraham Lincoln](http://en.wikipedia.org/Abraham_Lincoln). This suggests that we should try to disambiguate between different entity references based on the textual context on the page from which the mention was taken. Your task in this last problem is to implement this idea.\n",
    "\n",
    "Set up a dictionary that contains, for each mention $m$ that can refer to more than one entity $e$, a separate Naive Bayes classifier that is trained to predict the correct entity $e$, given the textual context of the mention. As the prior probabilities of the classifier, choose the probabilities $P(e|m)$ that you used in Problem&nbsp;5. To let you estimate the context-specific probabilities, we have compiled a data set with mention contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open('contexts.tsv.bz2') as source:\n",
    "    df_contexts = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame contains, for each ambiguous mention $m$ and each knowledge base entity $e$ to which this mention can refer, up to 100 randomly selected contexts in which $m$ is used to refer to $e$. For this data, a **context** is defined as the 5 tokens to the left and the 5 tokens to the right of the mention. Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>entity</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>UEFA_Champions_League</td>\n",
       "      <td>Cup twice the first in @ and the second in 1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>FIFA_World_Cup</td>\n",
       "      <td>America 1975 and during the @ and 1978 World C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>Manolo represented Spain at the @</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>Hašek represented Czechoslovakia at the @ and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>renovations in 1989 for the @ The present capa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mention                 entity  \\\n",
       "0            1970  UEFA_Champions_League   \n",
       "1            1970         FIFA_World_Cup   \n",
       "2  1990 World Cup    1990_FIFA_World_Cup   \n",
       "3  1990 World Cup    1990_FIFA_World_Cup   \n",
       "4  1990 World Cup    1990_FIFA_World_Cup   \n",
       "\n",
       "                                             context  \n",
       "0    Cup twice the first in @ and the second in 1983  \n",
       "1  America 1975 and during the @ and 1978 World C...  \n",
       "2                 Manolo represented Spain at the @   \n",
       "3  Hašek represented Czechoslovakia at the @ and ...  \n",
       "4  renovations in 1989 for the @ The present capa...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in each context, the position of the mention is indicated by the `@` symbol.\n",
    "\n",
    "From this data frame, it is easy to select the data that you need to train the classifiers – the contexts and corresponding entities for all mentions. To illustrate this, the following cell shows how to select all contexts that belong to the mention &lsquo;Lincoln&rsquo;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41465    Nebraska Concealed Handgun Permit In @ municip...\n",
       "41466    Lazlo restaurants are located in @ and Omaha C...\n",
       "41467    California Washington Overland Park Kansas @ N...\n",
       "41468    City Missouri Omaha Nebraska and @ Nebraska It...\n",
       "41469    by Sandhills Publishing Company in @ Nebraska USA\n",
       "                               ...                        \n",
       "41609                                      @ Leyton Orient\n",
       "41610                    English division three Swansea @ \n",
       "41611    league membership narrowly edging out @ on goa...\n",
       "41612                                          @ Cambridge\n",
       "41613                                                   @ \n",
       "Name: context, Length: 149, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.context[df_contexts.mention == 'Lincoln']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the context-sensitive disambiguation method and evaluate its performance. Here are some more hints that may help you along the way:\n",
    "\n",
    "**Hint 1:** The prior probabilities for a Naive Bayes classifier can be specified using the `class_prior` option. You will have to provide the probabilities in the same order as the alphabetically sorted class (entity) names.\n",
    "\n",
    "**Hint 2:** Not all mentions in the knowledge base are ambiguous, and therefore not all mentions have context data. If a mention has only one possible entity, pick that one. If a mention has no entity at all, predict the `--NME--` label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code here to implement the context-sensitive disambiguation method\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "mentions = df_contexts.mention.unique()\n",
    "\n",
    "clf_dict = {}\n",
    "\n",
    "for i in mentions:\n",
    "    prior = df_kb.loc[df_kb.mention == i].sort_values('entity').prob.values\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('vec', CountVectorizer()),\n",
    "        ('clf', MultinomialNB(class_prior=prior)),\n",
    "    ])\n",
    "    \n",
    "    clf_dict[i] = pipe.fit(df_contexts.context[df_contexts.mention == i],\n",
    "                           df_contexts.entity[df_contexts.mention == i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1970': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " '1990 World Cup': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97916667, 0.02083333])))]),\n",
       " '1992': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98571429, 0.01428571])))]),\n",
       " '1996': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94100295, 0.00294985, 0.0560472 ])))]),\n",
       " '2000 Summer Olympics': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99696878e-01, 3.03122158e-04])))]),\n",
       " '95': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'ABC': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00397803, 0.99602197])))]),\n",
       " 'AFL': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99361022, 0.00638978])))]),\n",
       " 'AL': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.48780488, 0.51219512])))]),\n",
       " 'AL East Division': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'AR': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.03225806, 0.96774194])))]),\n",
       " 'ATLANTA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.13636364, 0.86363636])))]),\n",
       " 'AUSTRALIA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'AUSTRALIANS': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'AUSTRIA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'AZ': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.64444444, 0.35555556])))]),\n",
       " 'Abu Dhabi': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99695122, 0.00304878])))]),\n",
       " 'Academy Award': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01592357, 0.98407643])))]),\n",
       " 'Academy Awards': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.002849, 0.997151])))]),\n",
       " 'Africa': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.98714157e-01, 1.15725858e-03, 1.28584287e-04])))]),\n",
       " 'African': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99270073, 0.00729927])))]),\n",
       " 'African American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.28, 0.72])))]),\n",
       " 'Afrikaans': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99864682, 0.00135318])))]),\n",
       " 'Air Force': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00271739, 0.99728261])))]),\n",
       " 'Airport': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Alaska': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99374870e-01, 6.25130235e-04])))]),\n",
       " 'Albania': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99494055e-01, 2.52972426e-04, 2.52972426e-04])))]),\n",
       " 'Albanian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.75144813e-01, 5.03422854e-01, 2.21169036e-01, 2.63296472e-04])))]),\n",
       " 'Albanians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.03267974, 0.96732026])))]),\n",
       " 'Algeria': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99812664e-01, 1.87336081e-04])))]),\n",
       " 'Algerian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99320190e-01, 6.79809653e-04])))]),\n",
       " 'Algiers': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00212089, 0.99787911])))]),\n",
       " 'All Blacks': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.01, 0.98, 0.01])))]),\n",
       " 'Am': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'America': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00122699, 0.00245399, 0.0208589 , 0.97546012])))]),\n",
       " 'American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.10765732e-05, 1.18460955e-05, 3.19844579e-04, 1.18460955e-05,\n",
       "        1.18460955e-05, 2.81700152e-02, 1.18460955e-05, 2.36921911e-05,\n",
       "        2.36921911e-05, 1.18460955e-05, 4.26459439e-04, 1.18460955e-05,\n",
       "        9.70491376e-01, 2.36921911e-05, 1.30307051e-04, 2.25075815e-04,\n",
       "        1.18460955e-05, 1.18460955e-05])))]),\n",
       " 'American Indian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.23195876, 0.76804124])))]),\n",
       " 'American Indians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.2761194, 0.7238806])))]),\n",
       " 'American League': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99565406e-01, 4.34593655e-04])))]),\n",
       " 'American actor': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'American born': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02777778, 0.97222222])))]),\n",
       " 'Americans': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.54506438, 0.45493562])))]),\n",
       " 'Americas': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Ancient Roman': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Ancient Rome': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Andersson': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Andy': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Anglo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00862069, 0.56034483, 0.00862069, 0.06896552, 0.35344828])))]),\n",
       " 'Anglo Irish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.33333333, 0.33333333])))]),\n",
       " 'Anglo Welsh': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Angola': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99370208, 0.00629792])))]),\n",
       " 'Antwerp': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99006796, 0.00993204])))]),\n",
       " 'Arab': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.40462428, 0.1849711 , 0.01734104, 0.39306358])))]),\n",
       " 'Arabian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Arabian Gulf': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Arabic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.45665962e-04, 9.95771670e-01, 3.38266385e-03])))]),\n",
       " 'Arabs': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01136364, 0.98863636])))]),\n",
       " 'Armed Forces': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Armenia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99577227, 0.00422773])))]),\n",
       " 'Army': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.85356455e-03, 9.63391137e-04, 9.95183044e-01])))]),\n",
       " 'Arrows': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Asia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.49566258e-04, 9.99850434e-01])))]),\n",
       " 'Athens': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.35739466e-04, 9.99664261e-01])))]),\n",
       " 'Atlanta': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00609385, 0.99116392, 0.00274223])))]),\n",
       " 'Atlanta Georgia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01041667, 0.98958333])))]),\n",
       " 'Auckland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99776119, 0.00223881])))]),\n",
       " 'Australia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.79969034e-01, 1.66924715e-03, 9.38649119e-03, 8.83007548e-03,\n",
       "        2.41919876e-05, 9.67679505e-05, 2.41919876e-05])))]),\n",
       " 'Australia national rugby union team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.03174603, 0.96825397])))]),\n",
       " 'Australian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.60891591e-01, 6.75447484e-05, 2.70178994e-03, 8.78081729e-04,\n",
       "        4.05268490e-04, 3.50557244e-02])))]),\n",
       " 'Australian Football League': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99651568e-01, 3.48432056e-04])))]),\n",
       " 'Australian Rules Football': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Australian national side': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.875, 0.125])))]),\n",
       " 'Australian national team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.6])))]),\n",
       " 'Australian rules football': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.76364321e-04, 9.99623636e-01])))]),\n",
       " 'Australians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.1761658 , 0.00518135, 0.66839378, 0.15025907])))]),\n",
       " 'Austria': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.73848950e-01, 7.06785137e-04, 1.51453958e-02, 8.07754443e-04,\n",
       "        9.28917609e-03, 2.01938611e-04])))]),\n",
       " 'Austrian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.95478417e-01, 5.12360702e-04, 1.75483540e-02, 8.64608685e-02])))]),\n",
       " 'Austrian American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Austrian born': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.77777778, 0.22222222])))]),\n",
       " 'Austrians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.53658537, 0.12195122, 0.34146341])))]),\n",
       " 'Austro': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.70588235, 0.11764706, 0.17647059])))]),\n",
       " 'Azerbaijan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99668705, 0.00331295])))]),\n",
       " 'BALTIMORE': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.85714286])))]),\n",
       " 'BARCELONA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'BOSTON': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'BSE': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96551724, 0.03448276])))]),\n",
       " 'Baghdad': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99728445, 0.00271555])))]),\n",
       " 'Baltimore': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99031477, 0.00968523])))]),\n",
       " 'Baltimore Orioles': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96811398, 0.03188602])))]),\n",
       " 'Barcelona': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00287301, 0.9254932 , 0.07163379])))]),\n",
       " 'Barry': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.99, 0.01])))]),\n",
       " 'Basque': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.6185567, 0.3814433])))]),\n",
       " 'Basque Country': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.86926829, 0.13073171])))]),\n",
       " 'Basque Region': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Basque country': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Beijing': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99074217e-01, 4.62891529e-04, 4.62891529e-04])))]),\n",
       " 'Belarus': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99258649, 0.00741351])))]),\n",
       " 'Belarusian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99285204e-01, 7.14796283e-04])))]),\n",
       " 'Belgian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.83654729e-04, 9.99081726e-01, 3.67309458e-04, 1.83654729e-04,\n",
       "        1.83654729e-04])))]),\n",
       " 'Belgium': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.75729712e-01, 9.62258099e-04, 2.30941944e-02, 1.06917567e-04,\n",
       "        1.06917567e-04])))]),\n",
       " 'Benetton': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97540984, 0.02459016])))]),\n",
       " 'Bengal': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.85714286])))]),\n",
       " 'Berlin': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.06826194e-04, 9.99679521e-01, 2.13652388e-04])))]),\n",
       " 'Biblical': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99421965, 0.00578035])))]),\n",
       " 'Birmingham': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.91388692, 0.08516678, 0.0009463 ])))]),\n",
       " 'Bohemian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Bordeaux': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.90081893, 0.09918107])))]),\n",
       " 'Bosnia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.36713287, 0.63286713])))]),\n",
       " 'Bosnia and Herzegovina': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99849579e-01, 1.50421179e-04])))]),\n",
       " 'Bosnian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01978417, 0.98021583])))]),\n",
       " 'Bosnian Serb': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.9375, 0.0625])))]),\n",
       " 'Boston': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99761526, 0.00238474])))]),\n",
       " 'Botham': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Botswana': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98998498, 0.01001502])))]),\n",
       " 'Bradford': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.84782609, 0.15217391])))]),\n",
       " 'Brady': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.71428571, 0.28571429])))]),\n",
       " 'Brazil': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.85236473e-01, 1.44704546e-02, 3.66340624e-05, 2.56438436e-04])))]),\n",
       " 'Brazilian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.98534881e-01, 1.12701454e-03, 3.38104362e-04])))]),\n",
       " 'Bremen': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Brisbane': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99120412, 0.00242645, 0.00636943])))]),\n",
       " 'Bristol': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99614049e-01, 3.85951370e-04])))]),\n",
       " 'Britain': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.59301443e-04, 2.27790433e-03, 9.96962794e-01])))]),\n",
       " 'British': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.80126962e-05, 3.80126962e-05, 1.02938381e-01, 3.80126962e-05,\n",
       "        5.16972669e-03, 7.60253925e-05, 7.60253925e-05, 7.60253925e-05,\n",
       "        3.80126962e-05, 3.80126962e-05, 3.80126962e-05, 8.91245676e-01,\n",
       "        1.52050785e-04, 3.80126962e-05])))]),\n",
       " 'British Columbia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99917594e-01, 8.24062629e-05])))]),\n",
       " 'British India': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.33333333, 0.33333333])))]),\n",
       " 'British Open': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01449275, 0.98550725])))]),\n",
       " 'British born': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.15384615, 0.15384615, 0.69230769])))]),\n",
       " 'Britishers': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Briton': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.65217391, 0.34782609])))]),\n",
       " 'Britons': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.06666667, 0.26666667])))]),\n",
       " 'Brooklyn Bridegrooms': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02564103, 0.97435897])))]),\n",
       " 'Buenos Aires': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94967856, 0.05032144])))]),\n",
       " 'Bulgaria': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.83032360e-01, 1.62404557e-02, 7.27184584e-04])))]),\n",
       " 'Bulgarian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.98415393e-01, 5.65930956e-04, 1.01018676e-01])))]),\n",
       " 'Bulgarians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04945055, 0.95054945])))]),\n",
       " 'Bulldogs': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.84, 0.16])))]),\n",
       " 'Burundi': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99435737, 0.00564263])))]),\n",
       " 'CHICAGO': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.37288136, 0.03389831, 0.59322034])))]),\n",
       " 'CLEVELAND': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.1, 0.9])))]),\n",
       " 'CSKA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.1, 0.9])))]),\n",
       " 'Cabinet': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98780488, 0.01219512])))]),\n",
       " 'Cairo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99500250e-01, 4.99750125e-04])))]),\n",
       " 'California': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99736634e-01, 1.64603634e-04, 9.87621807e-05])))]),\n",
       " 'Cambodia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99628253e-01, 3.71747212e-04])))]),\n",
       " 'Cambodian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95800525, 0.04199475])))]),\n",
       " 'Cambodians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.77777778, 0.22222222])))]),\n",
       " 'Cambridge': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97586207, 0.02413793])))]),\n",
       " 'Cameroon': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98333038, 0.01666962])))]),\n",
       " 'Cameroonian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99570815, 0.00429185])))]),\n",
       " 'Canadian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99891087e-01, 3.63042294e-05, 3.63042294e-05, 3.63042294e-05])))]),\n",
       " 'Canadian province': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Canberra': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([6.67111408e-04, 9.93328886e-01, 6.00400267e-03])))]),\n",
       " 'Canton': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.09917355, 0.90082645])))]),\n",
       " 'Cantonese': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.33333333, 0.33333333])))]),\n",
       " 'Cardiff': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.9397482 , 0.00494604, 0.05530576])))]),\n",
       " 'Caribbean island': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Celtic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99042146e-01, 9.57854406e-04])))]),\n",
       " 'Central': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.25862069, 0.70689655, 0.01724138, 0.01724138])))]),\n",
       " 'Central African Republic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99630314, 0.00369686])))]),\n",
       " 'Central Division': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.46428571, 0.53571429])))]),\n",
       " 'Ceylon': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.88157895, 0.11842105])))]),\n",
       " 'Champions League': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00858369, 0.99141631])))]),\n",
       " 'Championship': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.875, 0.125])))]),\n",
       " 'Charleroi': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.75572519, 0.24427481])))]),\n",
       " 'Charles': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.84615385, 0.15384615])))]),\n",
       " 'Charleston': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.70699433, 0.29300567])))]),\n",
       " 'Chechen': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.20792079, 0.79207921])))]),\n",
       " 'Chechens': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.78378378, 0.21621622])))]),\n",
       " 'Chelsea': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00580833, 0.99419167])))]),\n",
       " 'Chester le Street': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98165138, 0.01834862])))]),\n",
       " 'Chesterfield': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.38636364, 0.61237374, 0.00126263])))]),\n",
       " 'Chicago': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.98935377e-01, 2.12924518e-04, 1.06462259e-04, 7.45235814e-04])))]),\n",
       " 'Chicago White Stockings': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94202899, 0.05797101])))]),\n",
       " 'Chile': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97850189, 0.02149811])))]),\n",
       " 'China': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99605086e-01, 3.15930811e-04, 7.89827028e-05])))]),\n",
       " 'Chinese': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.32596154e-01, 7.86394231e-01, 8.08173077e-02, 4.80769231e-05,\n",
       "        1.44230769e-04])))]),\n",
       " 'Chinese government': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Chinese national': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Christian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.71428571, 0.28571429])))]),\n",
       " 'Christianity': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Church': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02040816, 0.97959184])))]),\n",
       " 'Church of Rome': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Cincinnati': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98510972, 0.01489028])))]),\n",
       " 'City': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.0625, 0.0625, 0.125 , 0.25  , 0.0625, 0.1875, 0.0625, 0.0625,\n",
       "        0.0625, 0.0625])))]),\n",
       " 'City of Charleston': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Cleveland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98842018, 0.01157982])))]),\n",
       " 'Club': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Colchester': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00680272, 0.96825397, 0.02494331])))]),\n",
       " 'Collins': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.91666667, 0.08333333])))]),\n",
       " 'Cologne': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00480513, 0.99519487])))]),\n",
       " 'Colombo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.42459983e-04, 9.99157540e-01])))]),\n",
       " 'Colorado': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99329646e-01, 6.70353612e-04])))]),\n",
       " 'Commission on Human Rights': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.09090909, 0.90909091])))]),\n",
       " 'Common Market': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Commonwealth': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.51438667e-03, 9.59111560e-03, 9.86370520e-01, 1.00959112e-03,\n",
       "        5.04795558e-04, 1.00959112e-03])))]),\n",
       " 'Commonwealth Games': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99867198, 0.00132802])))]),\n",
       " 'Communist': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.9047619, 0.0952381])))]),\n",
       " 'Communist China': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Communist government': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Communist party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.03571429, 0.96428571])))]),\n",
       " 'Communist regime': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Communists': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95238095, 0.04761905])))]),\n",
       " 'Congo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.07964602, 0.61946903, 0.30088496])))]),\n",
       " 'Congolese': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.54011742, 0.45988258])))]),\n",
       " 'Congress': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00726392, 0.00363196, 0.98910412])))]),\n",
       " 'Congressman': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.015625, 0.984375])))]),\n",
       " 'Continental': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.08333333, 0.75      , 0.16666667])))]),\n",
       " 'Costa Rica': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98624564, 0.01375436])))]),\n",
       " 'Council': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.1, 0.9])))]),\n",
       " 'Country': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.33333333, 0.33333333])))]),\n",
       " 'Crawley': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99069767, 0.00930233])))]),\n",
       " 'Croat': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.90909091, 0.09090909])))]),\n",
       " 'Croatia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.984525  , 0.00128958, 0.01303912, 0.0011463 ])))]),\n",
       " 'Croatian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99534451, 0.00217256, 0.00248293])))]),\n",
       " 'Croatian team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Crvena Zvezda': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Crvena zvezda': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.95, 0.05])))]),\n",
       " 'Crystal Palace': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00143062, 0.0472103 , 0.95135908])))]),\n",
       " 'Cuba': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99190939, 0.00809061])))]),\n",
       " 'Cuban': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99329759e-01, 6.70241287e-04])))]),\n",
       " 'Cup': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.6])))]),\n",
       " 'Cyprus': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98717566, 0.01282434])))]),\n",
       " 'Czech': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.95857988e-04, 9.99112426e-01, 5.91715976e-04])))]),\n",
       " 'Czech Republic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.84934946e-01, 1.25542114e-03, 3.42387583e-04, 1.34672449e-02])))]),\n",
       " 'Czechoslovakia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.125, 0.75 , 0.125])))]),\n",
       " 'DR Congo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.21568627, 0.78431373])))]),\n",
       " 'DUTCH': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92857143, 0.07142857])))]),\n",
       " 'Dakotas': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Damascus': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99539595, 0.00460405])))]),\n",
       " 'David': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99603175, 0.00396825])))]),\n",
       " 'Davis Cup': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00234192, 0.99765808])))]),\n",
       " 'Dayton': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97610922, 0.02389078])))]),\n",
       " 'Dean': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Democrat': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00220913, 0.99779087])))]),\n",
       " 'Democratic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.57548675e-04, 9.98563677e-01, 3.19182892e-04, 1.59591446e-04])))]),\n",
       " 'Democratic Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02222222, 0.97777778])))]),\n",
       " 'Democratic Republic of the Congo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.72257011e-04, 9.99727743e-01])))]),\n",
       " 'Democrats': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02474227, 0.97525773])))]),\n",
       " 'Denver': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.69565217e-04, 9.99130435e-01])))]),\n",
       " 'Detroit': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99358974, 0.00641026])))]),\n",
       " 'Dhaka': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99709302, 0.00290698])))]),\n",
       " 'Dow': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Dresden': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99389126e-01, 6.10873549e-04])))]),\n",
       " 'Ducati': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.53333333, 0.46666667])))]),\n",
       " 'Dundee': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99593496, 0.00406504])))]),\n",
       " 'Durban': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99891658, 0.00108342])))]),\n",
       " 'Dutch': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.13934560e-05, 1.02718541e-01, 2.44180368e-04, 8.96630311e-01,\n",
       "        3.25573824e-04])))]),\n",
       " 'Dutch born': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.125, 0.875])))]),\n",
       " 'Dutch football team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Dutchman': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.47368421, 0.52631579])))]),\n",
       " 'Dynamo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.22222222, 0.66666667, 0.11111111])))]),\n",
       " 'Dynamo Moscow': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04477612, 0.95522388])))]),\n",
       " 'EC': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.38461538, 0.61538462])))]),\n",
       " 'ECOMOG': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.2, 0.8])))]),\n",
       " 'ENG': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'ENGLAND': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.28571429, 0.61904762, 0.04761905, 0.04761905])))]),\n",
       " 'ESSEX': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'EU': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00601504, 0.99398496])))]),\n",
       " 'East': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.12121212, 0.66666667, 0.06060606, 0.03030303, 0.09090909,\n",
       "        0.03030303])))]),\n",
       " 'East Division': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.71428571, 0.28571429])))]),\n",
       " 'East German': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98446069, 0.01553931])))]),\n",
       " 'Eastern': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Eastern Division': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.06451613, 0.93548387])))]),\n",
       " 'Edgbaston': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.47265625, 0.52734375])))]),\n",
       " 'Egyptian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.75241313, 0.24758687])))]),\n",
       " 'Egyptian born': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Egyptians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.26136364, 0.73863636])))]),\n",
       " 'Eight years later': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.33333333, 0.16666667, 0.16666667])))]),\n",
       " 'Elizabeth': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.1862069, 0.8137931])))]),\n",
       " 'Emirate': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Emperor': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Emperor Napoleon': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.8, 0.2])))]),\n",
       " 'Empire': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02597403, 0.02597403, 0.92207792, 0.01298701, 0.01298701])))]),\n",
       " 'England': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.91703090e-05, 9.33018940e-01, 1.47036270e-02, 2.69342842e-02,\n",
       "        1.91511387e-02, 1.91703090e-05, 5.17598344e-03, 1.53362472e-04,\n",
       "        1.91703090e-05, 8.05152979e-04])))]),\n",
       " 'England International': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.8, 0.2])))]),\n",
       " 'England and Wales': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'England international': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92592593, 0.07407407])))]),\n",
       " 'England national cricket team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'England national rugby union team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01162791, 0.98837209])))]),\n",
       " 'England national side': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'England national team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92481203, 0.07518797])))]),\n",
       " 'England squad': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.4, 0.2])))]),\n",
       " 'England team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.19354839, 0.74193548, 0.06451613])))]),\n",
       " 'English': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.37568370e-04, 6.46913580e-01, 6.25097672e-04, 5.00078137e-04,\n",
       "        2.18784185e-04, 3.28926395e-01, 3.12548836e-05, 3.12548836e-05,\n",
       "        1.13767776e-02, 3.12548836e-05, 6.25097672e-05, 1.07516799e-02,\n",
       "        6.25097672e-05, 3.12548836e-05])))]),\n",
       " 'English Crown': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'English footballer': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'English international': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.71428571, 0.28571429])))]),\n",
       " 'English national side': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.96, 0.04])))]),\n",
       " 'English national team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.0625, 0.875 , 0.0625])))]),\n",
       " 'English side': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.25, 0.5 ])))]),\n",
       " 'Englishman': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02222222, 0.86666667, 0.02222222, 0.06666667, 0.02222222])))]),\n",
       " 'Englishmen': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.71428571, 0.28571429])))]),\n",
       " 'Español': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83333333, 0.16666667])))]),\n",
       " 'Essex': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.75569155, 0.24430845])))]),\n",
       " 'Estonia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.90526458e-01, 9.33820544e-03, 1.35336311e-04])))]),\n",
       " 'Estonia national football team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01428571, 0.98571429])))]),\n",
       " 'Estonian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99397953e-01, 6.02046960e-04])))]),\n",
       " 'Ethiopia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99486969, 0.00513031])))]),\n",
       " 'Ethiopian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99848024, 0.00151976])))]),\n",
       " 'Eugene': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Euro': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Europe': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.96015192e-01, 1.99240396e-03, 1.05846460e-03, 9.33939356e-04])))]),\n",
       " 'European': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.88350634e-04, 9.80680507e-01, 8.65051903e-03, 1.44175317e-03,\n",
       "        2.88350634e-04, 7.78546713e-03, 5.76701269e-04, 2.88350634e-04])))]),\n",
       " 'European Championship': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01587302, 0.98412698])))]),\n",
       " 'European Championships': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01639344, 0.98360656])))]),\n",
       " 'European Community': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'European Cup': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.11084337, 0.88915663])))]),\n",
       " 'European Cups': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.03846154, 0.96153846])))]),\n",
       " 'European Economic Community': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97512438, 0.02487562])))]),\n",
       " 'European Union': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.46426811e-04, 9.99753573e-01])))]),\n",
       " 'European football': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'European level': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'FIFA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99347258e-01, 6.52741514e-04])))]),\n",
       " 'FIFA World Cup': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00271739, 0.99728261])))]),\n",
       " 'FRENCH': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92307692, 0.07692308])))]),\n",
       " 'Faroe Islands': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95022124, 0.04977876])))]),\n",
       " 'Fed Cup': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99570815, 0.00214592, 0.00214592])))]),\n",
       " 'Federal': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Federal Republic of Germany': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99065421, 0.00934579])))]),\n",
       " 'Ferrari': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.38854296, 0.61145704])))]),\n",
       " 'Ferraris': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.80645161, 0.19354839])))]),\n",
       " 'Finland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99672561e-01, 3.27439424e-04])))]),\n",
       " 'Five Nations': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.0754717, 0.9245283])))]),\n",
       " 'Flamengo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.9950495, 0.0049505])))]),\n",
       " 'Flemish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.9375, 0.0625])))]),\n",
       " 'Florence': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.38868180e-04, 9.99661132e-01])))]),\n",
       " 'Flushing Meadows': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.33333333, 0.33333333])))]),\n",
       " 'Football': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Ford': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97241379, 0.02758621])))]),\n",
       " 'Ford Escort': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.075, 0.925])))]),\n",
       " 'Ford Motor Co': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Foreign Minister': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83333333, 0.16666667])))]),\n",
       " 'Foreign Ministry': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.11111111, 0.33333333, 0.22222222, 0.22222222, 0.11111111])))]),\n",
       " 'Four years later': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.13846154, 0.32307692, 0.26153846, 0.27692308])))]),\n",
       " 'Fox': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99765258, 0.00234742])))]),\n",
       " 'France': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.50308132e-05, 9.94333383e-01, 1.80369758e-04, 5.17059973e-03,\n",
       "        1.50308132e-05, 1.50308132e-05, 2.55523824e-04, 1.50308132e-05])))]),\n",
       " 'Frankfort': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.9, 0.1])))]),\n",
       " 'Frankfurt': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00158856, 0.99205719, 0.00397141, 0.00238284])))]),\n",
       " 'Frankfurt Stock Exchange': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01724138, 0.98275862])))]),\n",
       " 'Freiburg': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.68852459, 0.04918033, 0.26229508])))]),\n",
       " 'French': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.00150225e-04, 9.97646470e-01, 1.45217827e-03, 1.50225338e-04,\n",
       "        6.50976465e-04])))]),\n",
       " 'French Guianan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.0625, 0.9375])))]),\n",
       " 'French government': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Fulham': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99534884, 0.00465116])))]),\n",
       " 'GB': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'GENOA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'GER': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Gabon': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98888889, 0.01111111])))]),\n",
       " 'Gabonese': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99450549, 0.00549451])))]),\n",
       " 'Games': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Gaza': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05405405, 0.94594595])))]),\n",
       " 'Genoa': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.89547482, 0.10452518])))]),\n",
       " 'Georgia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.10083664e-04, 6.91875826e-01, 3.08014091e-01])))]),\n",
       " 'Georgian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00238806, 0.99761194])))]),\n",
       " 'Georgians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'German': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.65036777e-05, 2.55525744e-04, 1.82518389e-05, 5.34778879e-01,\n",
       "        4.53740714e-02, 4.02745077e-01, 2.37273905e-04, 1.64996623e-02,\n",
       "        3.65036777e-05, 1.82518389e-05])))]),\n",
       " 'German American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'German Democratic Republic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98734177, 0.01265823])))]),\n",
       " 'German Nazi': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.90909091, 0.09090909])))]),\n",
       " 'German Nazis': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.875, 0.125])))]),\n",
       " 'German Reich': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'German Studies': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'German born': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05714286, 0.94285714])))]),\n",
       " 'German descent': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'German government': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'German team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'Germanic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.375 , 0.1875, 0.4375])))]),\n",
       " 'Germans': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00229358, 0.59633028, 0.21788991, 0.18348624])))]),\n",
       " 'Germany': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.93644585e-05, 1.93644585e-05, 3.87289169e-05, 3.87289169e-05,\n",
       "        1.93644585e-05, 9.89291454e-01, 2.32373502e-04, 7.74578339e-05,\n",
       "        1.93644585e-05, 5.57696404e-03, 4.66683449e-03])))]),\n",
       " 'Globo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.46153846, 0.53846154])))]),\n",
       " 'Gloucester': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99130435, 0.00869565])))]),\n",
       " 'God': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01240458, 0.98759542])))]),\n",
       " 'Gold Coast': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.25      , 0.41666667, 0.25      , 0.08333333])))]),\n",
       " 'Grand Slam': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99894848, 0.00105152])))]),\n",
       " 'Great Britain': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00103199, 0.00103199, 0.00103199, 0.8255934 , 0.17131063])))]),\n",
       " 'Greece': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.92936869e-05, 9.99910706e-01])))]),\n",
       " 'Greek': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.75938190e-04, 9.99724062e-01])))]),\n",
       " 'Greens': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.1372549, 0.8627451])))]),\n",
       " 'Groningen': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.13664596, 0.86335404])))]),\n",
       " 'Group': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Haitian American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Hakkari': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Hamburg': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([5.48395942e-04, 9.82999726e-01, 8.22593913e-04, 1.56292843e-02])))]),\n",
       " 'Hamburger': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Hamilton': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92405063, 0.07278481, 0.00316456])))]),\n",
       " 'Hampshire': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.72353371, 0.27646629])))]),\n",
       " 'Hanson': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Hapoel': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.55555556, 0.44444444])))]),\n",
       " 'Harlequins': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96341463, 0.03658537])))]),\n",
       " 'Hawaiian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99590164, 0.00409836])))]),\n",
       " 'Headingley': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.31632653, 0.68367347])))]),\n",
       " 'Henry': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'High Court': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.08333333, 0.91666667])))]),\n",
       " 'Highlanders': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.6])))]),\n",
       " 'Himalayan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01526718, 0.98473282])))]),\n",
       " 'Hispanic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Holland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.84848485, 0.15151515])))]),\n",
       " 'Honda': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98727735, 0.01272265])))]),\n",
       " 'Honduran': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99460432, 0.00539568])))]),\n",
       " 'Honduras': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97420147, 0.02579853])))]),\n",
       " 'Hong Kong': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99887044e-01, 1.12956060e-04])))]),\n",
       " 'House of Representatives': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.9 , 0.05, 0.05])))]),\n",
       " 'Houston': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99767117, 0.00232883])))]),\n",
       " 'Hove': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01593625, 0.98406375])))]),\n",
       " 'Hungarian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99744637e-01, 2.55362615e-04])))]),\n",
       " 'Hungary': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.10901630e-04, 9.99889098e-01])))]),\n",
       " 'Hussein': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83333333, 0.16666667])))]),\n",
       " 'Hyderabad': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00934579, 0.99065421])))]),\n",
       " 'IN': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01587302, 0.96825397, 0.01587302])))]),\n",
       " 'INDIA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.2, 0.8])))]),\n",
       " 'IRA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.59701493, 0.40298507])))]),\n",
       " 'Imperial': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.07692308, 0.03846154, 0.03846154, 0.5       , 0.34615385])))]),\n",
       " 'Imperial Court': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Imperial Period': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Imperial era': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04545455, 0.90909091, 0.04545455])))]),\n",
       " 'Imperial period': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92307692, 0.07692308])))]),\n",
       " 'Independent State of Croatia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.0037594, 0.9962406])))]),\n",
       " 'India': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.94704614e-01, 5.25687437e-03, 3.85119002e-05])))]),\n",
       " 'Indian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.88728139e-01, 6.39126140e-04, 3.54424496e-03, 7.08848992e-03])))]),\n",
       " 'Indian tribe': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.2, 0.8])))]),\n",
       " 'Indian tribes': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.42857143, 0.57142857])))]),\n",
       " 'Indians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04815864, 0.18696884, 0.19263456, 0.19830028, 0.37393768])))]),\n",
       " 'Indigenous': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92857143, 0.07142857])))]),\n",
       " 'Indigenous peoples': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.71428571, 0.28571429])))]),\n",
       " 'Indo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.85, 0.15])))]),\n",
       " 'Insein': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Inter': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.85714286, 0.14285714])))]),\n",
       " 'Interior Minister': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.85714286])))]),\n",
       " 'Interior Ministry': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Inverness': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98019802, 0.01782178, 0.0019802 ])))]),\n",
       " 'Iran': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99972106e-01, 2.78943918e-05])))]),\n",
       " 'Irani': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'Iraq': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.05432800e-04, 9.99391851e-01, 2.02716400e-04])))]),\n",
       " 'Ireland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([5.75524646e-01, 1.83016105e-04, 5.49048316e-04, 4.20632016e-01,\n",
       "        3.11127379e-03])))]),\n",
       " 'Ireland international': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Irelands': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Irish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([6.71667381e-01, 3.64337763e-03, 4.28632662e-04, 3.22974711e-01,\n",
       "        1.07158165e-03, 2.14316331e-04])))]),\n",
       " 'Irish Republican Army': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98406375, 0.01593625])))]),\n",
       " 'Irish born': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.93333333, 0.06666667])))]),\n",
       " 'Irish state': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Irishman': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.9, 0.1])))]),\n",
       " 'Islam': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99594978e-01, 4.05022276e-04])))]),\n",
       " 'Islamic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98841699, 0.01158301])))]),\n",
       " 'Islamist': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05660377, 0.94339623])))]),\n",
       " 'Island': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5 , 0.25, 0.25])))]),\n",
       " 'Israel': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.11881853e-04, 9.91161334e-01, 7.83172969e-03, 7.83172969e-04,\n",
       "        1.11881853e-04])))]),\n",
       " 'Israeli': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.13034142e-01, 4.29461026e-04, 8.65363968e-02])))]),\n",
       " 'Israeli citizen': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Israelis': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.32, 0.68])))]),\n",
       " 'Italian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.42556205e-05, 9.99336166e-01, 5.31067446e-04, 8.85112409e-05])))]),\n",
       " 'Italian city': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Italians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96969697, 0.03030303])))]),\n",
       " 'Italy': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.87093765e-01, 1.27507386e-02, 1.16622609e-04, 3.88742031e-05])))]),\n",
       " 'Jack': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Japan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99895460e-01, 1.04539634e-04])))]),\n",
       " 'Jersey': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99609883, 0.00390117])))]),\n",
       " 'Jerusalem': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99753998, 0.00246002])))]),\n",
       " 'Jewish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00225734, 0.00451467, 0.99097065, 0.00225734])))]),\n",
       " 'Jews': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00105597, 0.99894403])))]),\n",
       " 'Johannesburg': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.02527076e-04, 9.99097473e-01])))]),\n",
       " 'Johnson': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.85714286])))]),\n",
       " 'Jordan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95879121, 0.03571429, 0.00549451])))]),\n",
       " 'Jos Verstappen': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96428571, 0.03571429])))]),\n",
       " 'KANSAS CITY': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04347826, 0.95652174])))]),\n",
       " 'Kansas': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99781373e-01, 2.18627022e-04])))]),\n",
       " 'Kansas City': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98305085, 0.00988701, 0.00706215])))]),\n",
       " 'Karachi': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99083410e-01, 9.16590284e-04])))]),\n",
       " 'Kashmir': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01216216, 0.98783784])))]),\n",
       " 'Kashmir Province': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Kassala': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Kawasaki': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.93617021, 0.06382979])))]),\n",
       " 'Kennedy': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Kenya': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.84696748e-01, 1.31652976e-02, 2.02543040e-03, 1.12523911e-04])))]),\n",
       " 'Kenyan national side': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.8, 0.2])))]),\n",
       " 'Khmer': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.11688312, 0.88311688])))]),\n",
       " 'King': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.2, 0.4, 0.2, 0.2])))]),\n",
       " 'Kingdom': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.125, 0.875])))]),\n",
       " 'Kingdom of Portugal': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Kiwi': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Korea': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.21239509e-01, 3.22788896e-04, 7.84377017e-02])))]),\n",
       " 'Korean': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.82397716, 0.00190295, 0.17411989])))]),\n",
       " 'Korean born': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Kremlin': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.07575758, 0.92424242])))]),\n",
       " 'Kurd': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Kurdish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01785714, 0.07142857, 0.07142857, 0.22321429, 0.61607143])))]),\n",
       " 'Kurdistan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00787402, 0.00393701, 0.03149606, 0.95669291])))]),\n",
       " 'Kurdistan Democratic Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02941176, 0.97058824])))]),\n",
       " 'Kurdistan Region': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.9, 0.1])))]),\n",
       " 'Kurds': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.00625, 0.99375])))]),\n",
       " 'Kuwait': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00474308, 0.99525692])))]),\n",
       " 'LEEDS': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'LOS ANGELES': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.2, 0.8])))]),\n",
       " 'Labor': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99429387, 0.00570613])))]),\n",
       " 'Labor Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83109405, 0.16890595])))]),\n",
       " 'Labour': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00825593, 0.00257998, 0.00206398, 0.95562436, 0.03147575])))]),\n",
       " 'Labour Day': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01724138, 0.98275862])))]),\n",
       " 'Labour Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.23140496e-03, 6.88705234e-04, 1.27410468e-02, 9.67975207e-01,\n",
       "        1.13636364e-02])))]),\n",
       " 'Labour party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00342466, 0.98972603, 0.00684932])))]),\n",
       " 'Latin': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.57142857, 0.14285714, 0.14285714])))]),\n",
       " 'Latin American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.997669, 0.002331])))]),\n",
       " 'Latvia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98600845, 0.01399155])))]),\n",
       " 'Leader of the Liberal Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'League': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.28571429, 0.42857143, 0.14285714, 0.14285714])))]),\n",
       " 'Lebanon': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99147485e-01, 8.52514919e-04])))]),\n",
       " 'Leeds': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00196773, 0.85005903, 0.14167651, 0.00629673])))]),\n",
       " 'Leicester': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96569468, 0.0077187 , 0.02658662])))]),\n",
       " 'Lewis': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Liberal': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.96625881e-03, 3.70782351e-04, 6.74823878e-01, 3.21839080e-01])))]),\n",
       " 'Liberal Democrat': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.875, 0.125])))]),\n",
       " 'Liberal Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.03301435, 0.00095694, 0.63684211, 0.3291866 ])))]),\n",
       " 'Liberal party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.59090909, 0.18181818, 0.22727273])))]),\n",
       " 'Liberals': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01449275, 0.76811594, 0.2173913 ])))]),\n",
       " 'Liberia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99516696, 0.00483304])))]),\n",
       " 'Liberian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99373041, 0.00626959])))]),\n",
       " 'Liechenstein': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Liechtenstein': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96708286, 0.03291714])))]),\n",
       " 'Lincoln': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.22051282, 0.74871795, 0.03076923])))]),\n",
       " 'Lions': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.6, 0.4])))]),\n",
       " 'Lithuania': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98501499, 0.01323676, 0.00174825])))]),\n",
       " 'Lithuanian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99306037e-01, 6.93962526e-04])))]),\n",
       " 'Lockerbie': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.984375, 0.015625])))]),\n",
       " 'London': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.22518222e-05, 3.22518222e-05, 9.99161453e-01, 1.29007289e-04,\n",
       "        3.22518222e-05, 3.22518222e-05, 4.51525511e-04, 3.22518222e-05,\n",
       "        3.22518222e-05, 6.45036445e-05])))]),\n",
       " 'Long Island': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([6.15763547e-04, 9.99384236e-01])))]),\n",
       " 'Los Angeles': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.87626487e-05, 9.99201136e-01, 8.87626487e-05, 6.21338541e-04])))]),\n",
       " 'Luxembourg': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99672131, 0.00327869])))]),\n",
       " 'MILAN': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.2, 0.8])))]),\n",
       " 'MN': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00877193, 0.99122807])))]),\n",
       " 'MONTREAL': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Madrid': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02155469, 0.97844531])))]),\n",
       " 'Mainland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Major': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.15151515, 0.15151515, 0.6969697 ])))]),\n",
       " 'Majors': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.8, 0.2])))]),\n",
       " 'Malawi': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99173212, 0.00826788])))]),\n",
       " 'Malay': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.91666667, 0.08333333])))]),\n",
       " 'Malaya': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95652174, 0.04347826])))]),\n",
       " 'Malaysia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99685995e-01, 3.14004605e-04])))]),\n",
       " 'Malaysian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([6.95894224e-04, 9.98608212e-01, 6.95894224e-04])))]),\n",
       " 'Malta': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98057432, 0.01942568])))]),\n",
       " 'Manchester': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99512433e-01, 4.87567040e-04])))]),\n",
       " 'Manchester City': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99038462e-01, 9.61538462e-04])))]),\n",
       " 'Manhattan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.98578873e-01, 2.36854571e-04, 1.18427286e-03])))]),\n",
       " 'Maoist': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.85714286, 0.14285714])))]),\n",
       " 'Maracaibo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01030928, 0.98969072])))]),\n",
       " 'Mark': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.1, 0.3, 0.1, 0.5])))]),\n",
       " 'Marks': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Marseille': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.87034036, 0.12965964])))]),\n",
       " 'Martinez': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.875, 0.125])))]),\n",
       " 'Marxian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.375, 0.625])))]),\n",
       " 'Marxist': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00877193, 0.99122807])))]),\n",
       " 'Massachusetts': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.23502532e-04, 9.99876497e-01])))]),\n",
       " 'Mauritania': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99392888, 0.00607112])))]),\n",
       " 'Mauritanian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98701299, 0.01298701])))]),\n",
       " 'Mauritius': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99009901, 0.00990099])))]),\n",
       " 'McGrath': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Melbourne': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.85985674, 0.14014326])))]),\n",
       " 'Metro': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Mexican': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.89180774e-04, 9.94746060e-01, 4.67016929e-03, 1.94590387e-04])))]),\n",
       " 'Mexican American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Mexican state of the same name': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Mexico': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.86237633e-01, 7.83622294e-04, 1.29787442e-02])))]),\n",
       " 'Mexico national football team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.025, 0.975])))]),\n",
       " 'Michael Collins': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83157895, 0.16842105])))]),\n",
       " 'Michigan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99671169, 0.00328831])))]),\n",
       " 'Middle': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83333333, 0.16666667])))]),\n",
       " 'Middle East': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.24569945e-04, 9.99675430e-01])))]),\n",
       " 'Middle Kingdom': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02061856, 0.97938144])))]),\n",
       " 'Middlesex': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99892357, 0.00107643])))]),\n",
       " 'Milan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.09821586, 0.90178414])))]),\n",
       " 'Milano': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.85714286])))]),\n",
       " 'Milwaukee': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00252951, 0.98988196, 0.00758853])))]),\n",
       " 'Milwaukee Brewers': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.02, 0.98])))]),\n",
       " 'Minister of Foreign Affairs': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.9       , 0.03333333, 0.06666667])))]),\n",
       " 'Minister of the Interior': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.12, 0.88])))]),\n",
       " 'Ministry of Finance': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05263158, 0.94736842])))]),\n",
       " 'Ministry of Foreign Affairs': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.5       , 0.07142857, 0.42857143])))]),\n",
       " 'Minnesota': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99350720e-01, 6.49280381e-04])))]),\n",
       " 'Moldova': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98563583, 0.01436417])))]),\n",
       " 'Monaco': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.08408408, 0.91591592])))]),\n",
       " 'Montenegrin': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.11228814, 0.88771186])))]),\n",
       " 'Montreal': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.30327121e-04, 9.98436075e-01, 1.43359833e-03])))]),\n",
       " 'Morelia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.20610687, 0.79389313])))]),\n",
       " 'Morris': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.88888889, 0.11111111])))]),\n",
       " 'Moscow': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.21891760e-04, 9.98293515e-01, 1.21891760e-03, 1.21891760e-04,\n",
       "        2.43783520e-04])))]),\n",
       " 'Moscow Dynamo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Mozambican': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99285714, 0.00714286])))]),\n",
       " 'Mozambique': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99413107, 0.00586893])))]),\n",
       " 'Mumbai': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.77932185e-04, 9.99722068e-01])))]),\n",
       " 'Munich': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.86922035e-04, 9.98839234e-01, 7.73844070e-04])))]),\n",
       " 'Munich West Germany': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'México': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.8, 0.2])))]),\n",
       " 'NATO': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99472296e-01, 5.27704485e-04])))]),\n",
       " 'NBA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99348958e-01, 6.51041667e-04])))]),\n",
       " 'ND': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02803738, 0.97196262])))]),\n",
       " 'NEC World Series of Golf': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.7, 0.3])))]),\n",
       " 'NEW YORK': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.08421053, 0.63157895, 0.28421053])))]),\n",
       " 'NFL Hall of Fame': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'NICE': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'NL': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.88235294, 0.11764706])))]),\n",
       " 'NT': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.78571429, 0.21428571])))]),\n",
       " 'NY': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.93902439, 0.06097561])))]),\n",
       " 'NYC': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02777778, 0.97222222])))]),\n",
       " 'NZ': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.23684211, 0.76315789])))]),\n",
       " 'Namibia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.9958132, 0.0041868])))]),\n",
       " 'Namibian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98916968, 0.01083032])))]),\n",
       " 'Nancy': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.91428571, 0.08571429])))]),\n",
       " 'Napoli': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00858369, 0.99141631])))]),\n",
       " 'National': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04166667, 0.91666667, 0.04166667])))]),\n",
       " 'National Bank': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'National League West': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00598802, 0.99401198])))]),\n",
       " 'National League West Division': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'National Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.9924812, 0.0075188])))]),\n",
       " 'National Socialism': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.03571429, 0.92857143, 0.03571429])))]),\n",
       " 'National Socialist': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05128205, 0.05128205, 0.82051282, 0.07692308])))]),\n",
       " 'National Socialist Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.875, 0.125])))]),\n",
       " 'National Socialists': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.08333333, 0.33333333, 0.58333333])))]),\n",
       " 'Native': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.6])))]),\n",
       " 'Native American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.25587828, 0.74412172])))]),\n",
       " 'Native American Indian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Native American groups': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83333333, 0.16666667])))]),\n",
       " 'Native American tribes': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.13333333, 0.86666667])))]),\n",
       " 'Native Americans': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.26996528, 0.73003472])))]),\n",
       " 'Native North American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Natives': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Navy': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00138504, 0.99861496])))]),\n",
       " 'Nazi': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.20989305, 0.07085561, 0.71925134])))]),\n",
       " 'Nazi German': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99115044, 0.00884956])))]),\n",
       " 'Nazi Germany': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.24499230e-04, 9.98151002e-01, 9.24499230e-04])))]),\n",
       " 'Nazi Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99713467, 0.00286533])))]),\n",
       " 'Nazi Regime': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Nazi era': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.90909091, 0.04545455, 0.04545455])))]),\n",
       " 'Nazi government': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.875, 0.125])))]),\n",
       " 'Nazi movement': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Nazi party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Nazi period': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.875, 0.125])))]),\n",
       " 'Nazi regime': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.90697674, 0.09302326])))]),\n",
       " 'Nazi rule': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.77777778, 0.22222222])))]),\n",
       " 'Naziism': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Nazis': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.22097378, 0.09737828, 0.67790262, 0.00374532])))]),\n",
       " 'Neapolis': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'Nebraska': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99701314e-01, 2.98685783e-04])))]),\n",
       " 'Nelson': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99615385, 0.00384615])))]),\n",
       " 'Nepal': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.10803324e-04, 9.99889197e-01])))]),\n",
       " 'Netherlandish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.85714286])))]),\n",
       " 'Netherlands': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.83981205e-01, 3.55973231e-04, 1.56628222e-02])))]),\n",
       " 'New Jersey': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.13325418e-05, 9.99634670e-01, 1.82665084e-04, 9.13325418e-05])))]),\n",
       " 'New York': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.71900826e-04, 8.99917355e-01, 9.85123967e-02, 4.13223140e-05,\n",
       "        4.13223140e-05, 4.13223140e-05, 3.30578512e-04, 4.13223140e-04,\n",
       "        3.30578512e-04])))]),\n",
       " 'New York City': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.07744723e-04, 5.40136281e-04, 9.99252119e-01])))]),\n",
       " 'New York Giants': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.001002, 0.998998])))]),\n",
       " 'New York NY': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.17391304, 0.82608696])))]),\n",
       " 'New York USA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'New York Yankees': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.14937759e-04, 9.99585062e-01])))]),\n",
       " 'New Yorker': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.42307692, 0.57692308])))]),\n",
       " 'New Yorkers': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.64285714, 0.35714286])))]),\n",
       " 'New Zealand': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.16111851e-05, 9.77238682e-01, 1.24833555e-04, 9.07123835e-03,\n",
       "        1.01115180e-02, 3.37050599e-03, 4.16111851e-05])))]),\n",
       " 'New Zealand national side': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'New Zealand national team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.375, 0.625])))]),\n",
       " 'New Zealander': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.72164948, 0.01030928, 0.26804124])))]),\n",
       " 'New Zealanders': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.13986014, 0.59440559, 0.02097902, 0.24475524])))]),\n",
       " 'Newcastle': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.17948718, 0.82051282])))]),\n",
       " 'Nicaraguan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95305164, 0.04694836])))]),\n",
       " 'Nicaraguans': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Nice': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92359551, 0.07640449])))]),\n",
       " 'Nigerian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00181159, 0.99818841])))]),\n",
       " 'Nobel Laureate': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'Nobel Laureates': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'Nobel Peace Prize': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99568966, 0.00431034])))]),\n",
       " 'Nobel laureate': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.85714286])))]),\n",
       " 'North': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00228833, 0.69107551, 0.00915332, 0.04576659, 0.09382151,\n",
       "        0.00686499, 0.14187643, 0.00228833, 0.00457666, 0.00228833])))]),\n",
       " 'North America': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.09978941e-05, 9.99595011e-01, 3.23991576e-04])))]),\n",
       " 'North American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.66871166e-04, 7.66871166e-04, 9.92331288e-01, 6.13496933e-03])))]),\n",
       " 'North American Indian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'North Queensland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83333333, 0.16666667])))]),\n",
       " 'Northampton': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.93304221, 0.04803493, 0.01892285])))]),\n",
       " 'Northamptonshire': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.0010846, 0.9989154])))]),\n",
       " 'Northern': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'Northern Ireland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.35336311e-04, 9.61564488e-01, 3.81648396e-02, 1.35336311e-04])))]),\n",
       " 'Northern Irish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98989899, 0.01010101])))]),\n",
       " 'Nottingham': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.98679868e-01, 6.60066007e-04, 6.60066007e-04])))]),\n",
       " 'Nottinghamshire': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.89119683e-04, 9.99010880e-01])))]),\n",
       " 'Nuremberg': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99888143, 0.00111857])))]),\n",
       " 'OLYMPIC': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Oakland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95188285, 0.04811715])))]),\n",
       " 'Oklahoma': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99423077, 0.00576923])))]),\n",
       " 'Old Testament': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00134409, 0.99865591])))]),\n",
       " 'Old Trafford': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.63787375, 0.36212625])))]),\n",
       " 'Oldham': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.85, 0.15])))]),\n",
       " 'Olympiads': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.9, 0.1])))]),\n",
       " 'Olympic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04545455, 0.13636364, 0.01515152, 0.13636364, 0.66666667])))]),\n",
       " 'Olympic Games': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.19230769, 0.03846154, 0.11538462, 0.07692308, 0.07692308,\n",
       "        0.5       ])))]),\n",
       " 'Olympic sport': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.91666667, 0.08333333])))]),\n",
       " 'Olympics': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.09615385, 0.05769231, 0.13461538, 0.01923077, 0.69230769])))]),\n",
       " 'Open': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00589391, 0.92927308, 0.06483301])))]),\n",
       " 'Open Championship': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94117647, 0.05882353])))]),\n",
       " 'Oscar': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02880658, 0.97119342])))]),\n",
       " 'Oscar nominated': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Oscar winning': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'Oxford': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.76247906, 0.00368509, 0.23383585])))]),\n",
       " 'Oxford University': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01869159, 0.98130841])))]),\n",
       " 'PA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01129944, 0.98305085, 0.00564972])))]),\n",
       " 'PAKISTAN': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.3, 0.7])))]),\n",
       " 'PHILADELPHIA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.11764706, 0.88235294])))]),\n",
       " 'PORTUGUESE': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Pakistan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98310311, 0.01689689])))]),\n",
       " 'Pakistani': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.90982867e-01, 8.56627592e-03, 4.50856628e-04])))]),\n",
       " 'Pakistanis': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.09259259, 0.90740741])))]),\n",
       " 'Palestine': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00138122, 0.92955801, 0.00414365, 0.01104972, 0.0538674 ])))]),\n",
       " 'Palestinian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00191571, 0.37547893, 0.01724138, 0.50574713, 0.09961686])))]),\n",
       " 'Palestinians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.47826087, 0.52173913])))]),\n",
       " 'Panama': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.92937541e-01, 4.41403664e-04, 6.62105495e-03])))]),\n",
       " 'Panamá': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.91666667, 0.08333333])))]),\n",
       " 'Papal': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Para': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Paramount': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.07048458, 0.92951542])))]),\n",
       " 'Paris': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([6.26644943e-05, 1.87993483e-04, 1.25328989e-04, 9.98621381e-01,\n",
       "        7.51973932e-04, 2.50657977e-04])))]),\n",
       " 'Paris Saint Germain': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92090395, 0.07909605])))]),\n",
       " 'Partizan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.82758621, 0.17241379])))]),\n",
       " 'Partizan Belgrade': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.69047619, 0.30952381])))]),\n",
       " 'Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.55555556, 0.11111111, 0.33333333])))]),\n",
       " 'Paul Johnson': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.42857143, 0.57142857])))]),\n",
       " 'Peace': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.85714286, 0.14285714])))]),\n",
       " 'Pedro': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04761905, 0.95238095])))]),\n",
       " 'Peninsula': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Pennsylvania': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99168e-01, 6.40000e-05, 7.68000e-04])))]),\n",
       " 'Pentagon': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.9266055, 0.0733945])))]),\n",
       " 'Perry': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'Persian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98387097, 0.01612903])))]),\n",
       " 'Persian Gulf': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00365854, 0.99634146])))]),\n",
       " 'Perth': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.09918107e-04, 9.96360328e-01, 2.72975432e-03])))]),\n",
       " 'Philadelphia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.01568154e-04, 6.03136309e-04, 9.96381182e-01, 1.20627262e-03,\n",
       "        1.50784077e-03])))]),\n",
       " 'Philippines': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([6.78334012e-05, 1.35666802e-04, 9.99796500e-01])))]),\n",
       " 'Pittsburgh': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99271949, 0.00728051])))]),\n",
       " 'Plymouth': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Poland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.91030881e-01, 8.91235241e-03, 5.67665758e-05])))]),\n",
       " 'Pole': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.45454545, 0.54545455])))]),\n",
       " 'Poles': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00626468, 0.99373532])))]),\n",
       " 'Polish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.75272569e-01, 3.27082425e-04, 1.24400349e-01])))]),\n",
       " 'Portsmouth': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.59236068, 0.40763932])))]),\n",
       " 'Portugal': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97551433, 0.02246624, 0.00201944])))]),\n",
       " 'Portuguese': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.78387567e-01, 2.42836328e-04, 2.11267606e-02, 2.42836328e-04])))]),\n",
       " 'Portuguese Empire': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00645161, 0.99354839])))]),\n",
       " 'Portuguese territory': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Post': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'President': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'President Roosevelt': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92307692, 0.07692308])))]),\n",
       " 'Preston': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.06666667, 0.93333333])))]),\n",
       " 'Prime Minister': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Puerto Rican American': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'RBI': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.55555556, 0.44444444])))]),\n",
       " 'RUGBY LEAGUE': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Rabobank': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.81395349, 0.18604651])))]),\n",
       " 'Rangers': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98572628, 0.01427372])))]),\n",
       " 'Red': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.85714286, 0.14285714])))]),\n",
       " 'Red Star': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.04, 0.96])))]),\n",
       " 'Red Star Belgrade': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05300353, 0.94699647])))]),\n",
       " 'Reds': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.04, 0.96])))]),\n",
       " 'Reform Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.2, 0.8])))]),\n",
       " 'Rennes': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.81113801, 0.18886199])))]),\n",
       " 'Representative': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Republic': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05263158, 0.84210526, 0.10526316])))]),\n",
       " 'Republic of China': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01960784, 0.98039216])))]),\n",
       " 'Republic of Ireland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([5.60224090e-04, 8.43697479e-01, 1.55742297e-01])))]),\n",
       " 'Republic of Korea': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01639344, 0.98360656])))]),\n",
       " 'Republican': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.48766603e-05, 5.69259962e-04, 9.99335863e-01])))]),\n",
       " 'Reserve Bank': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Rhodesia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83333333, 0.08333333, 0.08333333])))]),\n",
       " 'Richard': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Richmond': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.36967156, 0.63032844])))]),\n",
       " 'Roma': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.90594059, 0.09405941])))]),\n",
       " 'Roman': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00171674, 0.87811159, 0.12017167])))]),\n",
       " 'Roman Church': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Romania': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([5.18941360e-05, 5.18941360e-05, 9.90918526e-01, 8.45874416e-03,\n",
       "        4.67047224e-04, 5.18941360e-05])))]),\n",
       " 'Romanian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.98570294e-04, 9.25138999e-01, 7.94281176e-04, 7.38681493e-02])))]),\n",
       " 'Romanians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02657807, 0.97342193])))]),\n",
       " 'Romans': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.91566265, 0.08433735])))]),\n",
       " 'Rome': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.30414747e-04, 2.53456221e-03, 5.41474654e-03, 9.91820276e-01])))]),\n",
       " 'Roosevelt': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.76086957, 0.10869565, 0.13043478])))]),\n",
       " 'Rubin': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'Rudar': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Rugby': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.58823529, 0.01470588, 0.39705882])))]),\n",
       " 'Rugby Football Union': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99285714, 0.00714286])))]),\n",
       " 'Rugby Union': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'Rumanian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Russia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.13924417e-05, 9.86837204e-01, 2.98025581e-03, 9.97557846e-03,\n",
       "        1.65569767e-04])))]),\n",
       " 'Russian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.73690932e-01, 3.19284802e-04, 2.49680715e-02, 1.02171137e-03])))]),\n",
       " 'Russian government': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94117647, 0.05882353])))]),\n",
       " 'Russians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.65168539, 0.3258427 , 0.02247191])))]),\n",
       " 'Russo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.46666667, 0.53333333])))]),\n",
       " 'SAN DIEGO': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05555556, 0.94444444])))]),\n",
       " 'SAN FRANCISCO': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04166667, 0.95833333])))]),\n",
       " 'SAN MARINO': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'SCOTTISH': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.8, 0.2])))]),\n",
       " 'SDP': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'SEATTLE': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.13043478, 0.86956522])))]),\n",
       " 'SK': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'SRI LANKA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.6])))]),\n",
       " 'ST HELENS': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Saints': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.23076923, 0.07692308, 0.69230769])))]),\n",
       " 'Salisbury': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94791667, 0.05208333])))]),\n",
       " 'San Diego': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99694812, 0.00305188])))]),\n",
       " 'San Francisco': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99145883e-01, 8.54116843e-04])))]),\n",
       " 'San Jose': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99601594, 0.00199203, 0.00199203])))]),\n",
       " 'San Marino': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95566502, 0.04433498])))]),\n",
       " 'Santiago': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96610169, 0.03389831])))]),\n",
       " 'Santos': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94957983, 0.05042017])))]),\n",
       " 'Sao Paulo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.38888889, 0.33333333, 0.27777778])))]),\n",
       " 'Saxon': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01388889, 0.98611111])))]),\n",
       " 'Scotland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.13906598e-01, 4.70118696e-02, 3.83040481e-02, 6.21987249e-04,\n",
       "        1.55496812e-04])))]),\n",
       " 'Scotland international': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.92857143, 0.07142857])))]),\n",
       " 'Scotland national rugby union team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02040816, 0.97959184])))]),\n",
       " 'Scotland national team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98449612, 0.01550388])))]),\n",
       " 'Scotland team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Scots': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02083333, 0.83333333, 0.14583333])))]),\n",
       " 'Scottish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.93461000e-01, 3.73657170e-03, 8.17375058e-04, 1.16767865e-04,\n",
       "        1.86828585e-03])))]),\n",
       " 'Scottish international': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94444444, 0.05555556])))]),\n",
       " 'Scottish national side': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.72222222, 0.27777778])))]),\n",
       " 'Scottish national team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.82926829, 0.17073171])))]),\n",
       " 'Seattle': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99545602, 0.00454398])))]),\n",
       " 'Second': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02857143, 0.97142857])))]),\n",
       " 'Security Council': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05681818, 0.94318182])))]),\n",
       " 'Senate': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.75, 0.25])))]),\n",
       " 'Senators': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'Seoul Korea': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.1, 0.9])))]),\n",
       " 'Serb': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16483516, 0.83516484])))]),\n",
       " 'Serbia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.07123728e-04, 9.99892876e-01])))]),\n",
       " 'Serbian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.08855472e-04, 7.34126984e-01, 2.65664160e-01])))]),\n",
       " 'Serbians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.6])))]),\n",
       " 'Serbs': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01777778, 0.98222222])))]),\n",
       " 'Seychelles': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99085366, 0.00914634])))]),\n",
       " 'Sharjah': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.28571429, 0.71428571])))]),\n",
       " 'Sharks': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Sheffield': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.44049734e-04, 9.96003552e-01, 3.55239787e-03])))]),\n",
       " 'Shell': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.72, 0.28])))]),\n",
       " 'Sierra Leone': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99395567, 0.00604433])))]),\n",
       " 'Sierra Leonean': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98837209, 0.01162791])))]),\n",
       " 'Slovak': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99898683, 0.00101317])))]),\n",
       " 'Slovakia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99186511, 0.00813489])))]),\n",
       " 'Social Democratic Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.104, 0.356, 0.54 ])))]),\n",
       " 'Socialist Party': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.625, 0.375])))]),\n",
       " 'Socialists': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'South': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05660377, 0.00943396, 0.00471698, 0.00471698, 0.78773585,\n",
       "        0.08018868, 0.05188679, 0.00471698])))]),\n",
       " 'South Africa': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.68916619e-01, 1.21951220e-02, 5.67214974e-05, 1.88315372e-02])))]),\n",
       " 'South Africa national team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'South African': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.34246896e-04, 9.89927383e-01, 4.68493792e-03, 5.15343172e-03])))]),\n",
       " 'South African national side': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.83333333, 0.16666667])))]),\n",
       " 'South African national team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.6])))]),\n",
       " 'South African team': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'South Africans': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.13402062, 0.80412371, 0.06185567])))]),\n",
       " 'South Korea': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.11944476e-04, 9.99888056e-01])))]),\n",
       " 'South Korean': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.27686703e-04, 9.99772313e-01])))]),\n",
       " 'South Melbourne': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00176056, 0.99823944])))]),\n",
       " 'South Queensland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'South east Asia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Southampton': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.54081066, 0.45918934])))]),\n",
       " 'Southern California': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Soviet': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.62919518e-04, 1.62919518e-04, 9.99674161e-01])))]),\n",
       " 'Soviet Union': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.07457554e-04, 1.07457554e-04, 9.99785085e-01])))]),\n",
       " 'Soviet republics': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Spa': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04545455, 0.95454545])))]),\n",
       " 'Spain': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.50384572e-05, 9.98911942e-01, 9.75499944e-04, 3.75192286e-05])))]),\n",
       " 'Spaniard': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.85714286, 0.14285714])))]),\n",
       " 'Spaniards': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.35802469, 0.64197531])))]),\n",
       " 'Spanish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.68471845e-05, 3.55476436e-01, 4.21624660e-04, 6.44008245e-01,\n",
       "        4.68471845e-05])))]),\n",
       " 'Sparta': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.18181818, 0.81818182])))]),\n",
       " 'Spartak': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.4, 0.2, 0.4])))]),\n",
       " 'Springboks': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00943396, 0.00943396, 0.98113208])))]),\n",
       " 'Sri Lanka': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97600319, 0.02399681])))]),\n",
       " 'Sri Lankan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98692033, 0.01307967])))]),\n",
       " 'Sri Lankans': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.11320755, 0.88679245])))]),\n",
       " 'St Gallen': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.09638554, 0.90361446])))]),\n",
       " 'St George': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97560976, 0.02439024])))]),\n",
       " 'St Helens': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95774648, 0.04225352])))]),\n",
       " 'St Louis': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99280576, 0.00719424])))]),\n",
       " 'St Louis Browns': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.79435484, 0.20564516])))]),\n",
       " 'Stansted': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.93103448, 0.06896552])))]),\n",
       " 'State': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04166667, 0.04166667, 0.08333333, 0.04166667, 0.04166667,\n",
       "        0.04166667, 0.125     , 0.58333333])))]),\n",
       " 'State Department': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00628931, 0.99371069])))]),\n",
       " 'State of Palestine': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01030928, 0.98969072])))]),\n",
       " 'Stirling': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99122807, 0.00877193])))]),\n",
       " 'Stranraer': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.43171806, 0.56828194])))]),\n",
       " 'Strasbourg': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01207057, 0.98792943])))]),\n",
       " 'Streak': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Stuttgart': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98241501, 0.00234467, 0.01524033])))]),\n",
       " 'Subaru': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.89781022, 0.10218978])))]),\n",
       " 'Sudan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99079972, 0.00920028])))]),\n",
       " 'Summer': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04545455, 0.95454545])))]),\n",
       " 'Summer Games': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.14285714, 0.14285714, 0.57142857])))]),\n",
       " 'Summer Olympic Games': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00182815, 0.00182815, 0.99634369])))]),\n",
       " 'Summer Olympics': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04761905, 0.04761905, 0.02380952, 0.11904762, 0.0952381 ,\n",
       "        0.66666667])))]),\n",
       " 'Sun': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.88888889, 0.11111111])))]),\n",
       " 'Supreme Court': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00551471, 0.00551471, 0.98897059])))]),\n",
       " 'Surrey': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.18705716e-01, 2.80821918e-01, 4.72366556e-04])))]),\n",
       " 'Sussex': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.59878419e-04, 9.99240122e-01])))]),\n",
       " 'Sutjeska': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Swansea': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.09803922, 0.90196078])))]),\n",
       " 'Swede': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.96666667, 0.03333333])))]),\n",
       " 'Sweden': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.85767657e-01, 5.93014292e-05, 1.41730416e-02])))]),\n",
       " 'Swedish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99662105e-01, 3.37894915e-04])))]),\n",
       " 'Swiss': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99613900e-01, 3.86100386e-04])))]),\n",
       " 'Swiss national': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Switzerland': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([6.97495989e-05, 9.84794587e-01, 1.51356630e-02])))]),\n",
       " 'Sydney': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.10128178e-03, 5.25320445e-04, 9.82664425e-01, 1.47089725e-02])))]),\n",
       " 'TORONTO': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.57142857, 0.42857143])))]),\n",
       " 'Tajik': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.07142857, 0.92857143])))]),\n",
       " 'Tamil': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.46666667, 0.46666667, 0.06666667])))]),\n",
       " 'Tamil people': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Tamils': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.25806452, 0.74193548])))]),\n",
       " 'Tanzania': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99757004, 0.00242996])))]),\n",
       " 'Tehran': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00223614, 0.99776386])))]),\n",
       " 'Tel Aviv': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.46268657e-04, 9.99253731e-01])))]),\n",
       " 'Telfer': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'Texas': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([5.58846541e-05, 9.99329384e-01, 5.58846541e-05, 5.58846541e-04])))]),\n",
       " 'The City': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'The Netherlands': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98113208, 0.01886792])))]),\n",
       " 'The Oval': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00292398, 0.99707602])))]),\n",
       " 'The Telegraph': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'The Vatican': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.85714286, 0.14285714])))]),\n",
       " 'Tigers': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04761905, 0.26190476, 0.02380952, 0.66666667])))]),\n",
       " 'Times': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02222222, 0.97777778])))]),\n",
       " 'Togo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98515326, 0.01484674])))]),\n",
       " 'Togolese': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.9954955, 0.0045045])))]),\n",
       " 'Tokyo': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99878641, 0.00121359])))]),\n",
       " 'Tony': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.6, 0.2, 0.2])))]),\n",
       " 'Torino': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.94674556, 0.05325444])))]),\n",
       " 'Toronto': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99051633e-01, 9.48366702e-04])))]),\n",
       " 'Tour': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.81818182, 0.18181818])))]),\n",
       " 'Toyota': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99722222, 0.00277778])))]),\n",
       " 'Treasury': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97368421, 0.02631579])))]),\n",
       " 'Tunbridge Wells': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02564103, 0.97435897])))]),\n",
       " 'Tunis': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99853587, 0.00146413])))]),\n",
       " 'Tunisia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97129784, 0.02870216])))]),\n",
       " 'Tunisian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01070336, 0.97400612, 0.01529052])))]),\n",
       " 'Turkey': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00775194, 0.99224806])))]),\n",
       " 'Turkish': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.42857143, 0.42857143])))]),\n",
       " 'Turkish Cypriot': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05555556, 0.94444444])))]),\n",
       " 'U21': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'UEFA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99005964e-01, 9.94035785e-04])))]),\n",
       " 'UEFA Cup': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00680272, 0.99319728])))]),\n",
       " 'UK': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.80192077e-04, 1.20048019e-03, 2.40096038e-04, 9.98079232e-01])))]),\n",
       " 'US': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([3.75657400e-04, 3.75657400e-04, 6.66791886e-01, 3.75657400e-04,\n",
       "        3.75657400e-04, 3.31329827e-01, 3.75657400e-04])))]),\n",
       " 'US Open': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00378788, 0.00378788, 0.99242424])))]),\n",
       " 'US President': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'US state': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.14285714, 0.85714286])))]),\n",
       " 'USA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.25770343e-04, 9.93837253e-01, 6.03697648e-03])))]),\n",
       " 'USN': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01111111, 0.98888889])))]),\n",
       " 'Uganda': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99379845, 0.00620155])))]),\n",
       " 'Ukraine': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99289645, 0.00710355])))]),\n",
       " 'Ukrainian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99399580e-01, 6.00420294e-04])))]),\n",
       " 'Ulsan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.98445596, 0.01554404])))]),\n",
       " 'Under 21': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.1, 0.3, 0.6])))]),\n",
       " 'Union': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.03225806, 0.01612903, 0.01612903, 0.90322581, 0.01612903,\n",
       "        0.00806452, 0.00806452])))]),\n",
       " 'United': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05882353, 0.35294118, 0.05882353, 0.52941176])))]),\n",
       " 'United Kingdom': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([4.25224306e-05, 4.25224306e-05, 4.25224306e-05, 9.99872433e-01])))]),\n",
       " 'United Nations': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99809124e-01, 1.90876121e-04])))]),\n",
       " 'United States': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([7.85478081e-06, 3.14191232e-05, 7.85478081e-06, 1.57095616e-05,\n",
       "        7.85478081e-06, 7.85478081e-06, 9.99355908e-01, 2.35643424e-05,\n",
       "        7.85478081e-05, 7.85478081e-06, 7.85478081e-06, 3.53465137e-04,\n",
       "        7.85478081e-05, 1.57095616e-05])))]),\n",
       " 'United States Army': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.45243282e-04, 9.99854757e-01])))]),\n",
       " 'United States of America': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99806202, 0.00193798])))]),\n",
       " 'University of Oxford': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([8.44238075e-04, 9.99155762e-01])))]),\n",
       " 'Va': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.8, 0.2])))]),\n",
       " 'Vaduz': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.20930233, 0.01162791, 0.77906977])))]),\n",
       " 'Valletta': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.87460815, 0.12539185])))]),\n",
       " 'Vasco da Gama': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.01041667, 0.98958333])))]),\n",
       " 'Vatican': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00308642, 0.96296296, 0.03395062])))]),\n",
       " 'Venice': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99710669, 0.00289331])))]),\n",
       " 'Verona': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.06056701, 0.93943299])))]),\n",
       " 'Victoria': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([2.91885581e-04, 9.99708114e-01])))]),\n",
       " 'Victorian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00914634, 0.99085366])))]),\n",
       " 'Vienna': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.49925037e-04, 9.99850075e-01])))]),\n",
       " 'Vietnam': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.97619674, 0.02380326])))]),\n",
       " 'Virginia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.99796996e-01, 2.03004466e-04])))]),\n",
       " 'Volkswagen': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.99259259, 0.00740741])))]),\n",
       " 'Volkswagen AG': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.16666667, 0.83333333])))]),\n",
       " 'WA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.7037037, 0.2962963])))]),\n",
       " 'WBA': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Wales': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.95077039, 0.04763247, 0.00159714])))]),\n",
       " 'Wales Under 21': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.25, 0.75])))]),\n",
       " 'Wall': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Wall Street': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02099738, 0.97900262])))]),\n",
       " 'War': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05263158, 0.10526316, 0.84210526])))]),\n",
       " 'Warrior': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Washington': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([9.05633037e-05, 3.62253215e-04, 4.52816519e-04, 4.52816519e-04,\n",
       "        6.33943126e-04, 7.76942583e-01, 2.21065024e-01])))]),\n",
       " 'Washington Senators': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.81576535, 0.18423465])))]),\n",
       " 'Welsh': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00157828, 0.98705808, 0.01136364])))]),\n",
       " 'Wembley': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.05405405, 0.94594595])))]),\n",
       " 'West': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.2866242 , 0.00636943, 0.02547771, 0.00636943, 0.67515924])))]),\n",
       " 'West Division': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.47368421, 0.52631579])))]),\n",
       " 'West German': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04347826, 0.39130435, 0.04347826, 0.52173913])))]),\n",
       " 'West Germany': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.07638889, 0.05555556, 0.03472222, 0.83333333])))]),\n",
       " 'West Indian': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02255639, 0.09022556, 0.88721805])))]),\n",
       " 'West Indians': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00990099, 0.99009901])))]),\n",
       " 'West Indies': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.02008032, 0.07630522, 0.90361446])))]),\n",
       " 'West division': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.42857143, 0.57142857])))]),\n",
       " 'Western': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.00425532, 0.00851064, 0.00425532, 0.04255319, 0.01276596,\n",
       "        0.92765957])))]),\n",
       " 'Western Australia': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([1.40508641e-04, 9.99859491e-01])))]),\n",
       " 'Western Division': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.38888889, 0.61111111])))]),\n",
       " 'Western Divisions': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf', MultinomialNB(class_prior=array([0.5, 0.5])))]),\n",
       " 'Western Europe': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.66666667, 0.33333333])))]),\n",
       " 'Weston super Mare': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.04522613, 0.95477387])))]),\n",
       " 'Wien': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.33333333, 0.66666667])))]),\n",
       " 'Wigan': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.48172043, 0.00967742, 0.50860215])))]),\n",
       " 'Williams': Pipeline(steps=[('vec', CountVectorizer()),\n",
       "                 ('clf',\n",
       "                  MultinomialNB(class_prior=array([0.06666667, 0.93333333])))]),\n",
       " ...}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_context = df_dev_NER.copy()\n",
    "\n",
    "labels = []\n",
    "\n",
    "for rows in df_dev_context.itertuples():\n",
    "    context =' '.join(rows.sentence.split()[rows.beg:rows.end])\n",
    "    \n",
    "    if context in clf_dict:\n",
    "        MNB_clf = clf_dict[context]\n",
    "        labels.append(MNB_clf.predict([rows.sentence])[0])\n",
    "    elif context in df_kb.mention.values:\n",
    "        labels.append(df_kb.loc[df_kb.mention == context, 'entity'].values[0])\n",
    "    else:\n",
    "        labels.append('--NME--')\n",
    "        \n",
    "df_dev_context.label = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0946-001</td>\n",
       "      <td>LONDON 1996-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>Somerset_County_Cricket_Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Phil_Simmons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0946-002</td>\n",
       "      <td>West Indian all-rounder Phil Simmons took four...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Leicestershire_County_Cricket_Club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>1161-007</td>\n",
       "      <td>Brokers said blue chips like IDLC , Bangladesh...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>1161-007</td>\n",
       "      <td>Brokers said blue chips like IDLC , Bangladesh...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>1161-007</td>\n",
       "      <td>Brokers said blue chips like IDLC , Bangladesh...</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>1161-009</td>\n",
       "      <td>The DSE all share price index closed 2.73 poin...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Dhaka_Stock_Exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>1161-010</td>\n",
       "      <td>-- Dhaka Newsroom 880-2-506363</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5201 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id                                           sentence  beg  end  \\\n",
       "0       0946-001                                  LONDON 1996-08-30    0    1   \n",
       "1       0946-002  West Indian all-rounder Phil Simmons took four...    0    2   \n",
       "2       0946-002  West Indian all-rounder Phil Simmons took four...   14   15   \n",
       "3       0946-002  West Indian all-rounder Phil Simmons took four...    3    5   \n",
       "4       0946-002  West Indian all-rounder Phil Simmons took four...   12   13   \n",
       "...          ...                                                ...  ...  ...   \n",
       "5196    1161-007  Brokers said blue chips like IDLC , Bangladesh...   10   12   \n",
       "5197    1161-007  Brokers said blue chips like IDLC , Bangladesh...    7    9   \n",
       "5198    1161-007  Brokers said blue chips like IDLC , Bangladesh...   13   15   \n",
       "5199    1161-009  The DSE all share price index closed 2.73 poin...    1    2   \n",
       "5200    1161-010                     -- Dhaka Newsroom 880-2-506363    1    3   \n",
       "\n",
       "                                   label  \n",
       "0                                 London  \n",
       "1                              Caribbean  \n",
       "2           Somerset_County_Cricket_Club  \n",
       "3                           Phil_Simmons  \n",
       "4     Leicestershire_County_Cricket_Club  \n",
       "...                                  ...  \n",
       "5196                             --NME--  \n",
       "5197                             --NME--  \n",
       "5198                             --NME--  \n",
       "5199                Dhaka_Stock_Exchange  \n",
       "5200                             --NME--  \n",
       "\n",
       "[5201 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 62.62%, Recall: 55.04%, F1 score: 58.59%\n"
     ]
    }
   ],
   "source": [
    "evaluation_report(set(gold_mentions(df_dev)),\n",
    "                  set(gold_mentions(df_dev_context)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect to see a small (around 1&nbsp;unit) increase in both precision, recall, and F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following reflection questions will help you prepare for the diagnostic test. Answer each of them in the form of a short text and put your answers in the cell below. You will get feedback on your answers from your lab assistant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RQ 5.1:** In Problem&nbsp;3, you did an error analysis on the task of recognizing text spans mentioning named entities. Summarize your results. Pick one type of error that you observed. How could you improve the model&rsquo;s performance on this type of error? What resources (such as domain knowledge, data, compute) would you need to implement this improvement?\n",
    "\n",
    "*We summarized this a bit during the analysis but we recall here that the biggest source of FPs and FNs seemed to be DATES & NUMBERS. We preprocessed them out, and saw a significant jump in the model's precision. The preprocessing approach was made by observing the FPs & FNs and figure out a logical pattern. So essentially, we needed enough data to recognise a pattern. Domain knowledge wasnt the most important factor here because we are not bringing in context for this exercise.*\n",
    "\n",
    "**RQ 5.2:** Thinking back about Problem&nbsp;6, explain what the word *context* refers to in the task addressed there, and how context can help to disambiguate between different entities. Suggest other types of context that you could use for disambiguation.\n",
    "\n",
    "*In this task context was a combination of 5 tokens to the left and right of the mention. This approach can help to classify the entity relationship by not just using the mention as the insput but also the surrounding text. In this exercise we were able to create a dictionary that assigns probabilities to different entities connected to a mention based on context surrounding said mention. To suggest an improvement, why only use the 5 surrounding words, we can also use word clusters to define context. For eg, if the document I am looking to classify has historical references to American history, then Lincoln would be linked to Abraham Lincoln. On the other hand, if it were a geographical text then maybe Lincoln, NB would be a better classification.*\n",
    "\n",
    "**RQ 5.3:** One type of entity mentions that we did not cover explicitly in this lab are pronouns. As an example, consider the sentence pair *Ruth Bader Ginsburg was an American jurist*. *She served as an associate justice of the Supreme Court from 1993 until her death in 2020*. What facts would you want to extract from this sentence pair? How do pronouns make fact extraction hard?\n",
    "\n",
    "*Facts from sentence pair:* \n",
    "- *Ruth Bader Ginsburg was the full name of 1 person*\n",
    "- *Ruth Bader Ginsburg was female*\n",
    "- *Ruth Bader Ginsburg's profession was a jurist*\n",
    "- *Ruth Bader Ginsburg was an American* \n",
    "- *From 1993-2020 Ruth Bader Ginsburg was serving at the Supreme Court*\n",
    "- *During her time at the Supreme Court she was an associate justice*\n",
    "- *Ruth Bader Ginsburg died in 2020*\n",
    "\n",
    "*Pronouns make it hard because they are used generically to describe any person according to their gender/identity. This creates a lot of ambiguity in linking named entities to information linked to their pronoun in the document. It is very challenging to create a separate contextual gold standard that assigns facts to the same entity. In this example, Ruth Bader Ginsburg is the mention and her name, first name, last name, pronoun, nick-name etc can all be clustered together as different entities.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This was the last lab in the Text Mining course. Congratulations! 🥳**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
